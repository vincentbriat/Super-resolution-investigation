{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQtreeTdoeliDD7O9Kw23/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vincentbriat/Super-resolution-investigation/blob/main/Discriminator_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JmqGDR8CNiU7"
      },
      "outputs": [],
      "source": [
        "# Checks if the code is in a colab notebook\n",
        "\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run on Colab notebook"
      ],
      "metadata": {
        "id": "5voJ6roJN27A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if IN_COLAB:\n",
        "  !pip install basicsr\n",
        "  drive.mount('/content/drive/')\n",
        "  !unzip /content/drive/MyDrive/Datasets/DIV2K_valid_HR.zip\n",
        "  !unzip /content/drive/MyDrive/Datasets/DIV2K_valid_LR_clean.zip\n",
        "  !unzip /content/drive/MyDrive/Datasets/DIV2K_train_HR.zip\n",
        "  !unzip /content/drive/MyDrive/Datasets/DIV2K_train_LR_clean.zip\n",
        "  FOLDER_LR_TEST = 'DIV2K_valid_LR_clean'\n",
        "  FOLDER_HR_TEST = 'DIV2K_valid_HR'\n",
        "  FOLDER_LR_TRAIN = 'DIV2K_train_LR_clean'\n",
        "  FOLDER_HR_TRAIN = 'DIV2K_train_HR'\n",
        "\n",
        "  STUDENT_MODEL_PATH = 'drive/MyDrive/ML/Indiv_Project/Second_Year/KD/Models/student.pth'\n",
        "  STUDENT_RECORDS_PATH = 'drive/MyDrive/ML/Indiv_Project/Second_Year/KD/Models/student.csv'\n",
        "  GENERATOR_MODEL_PATH = 'drive/MyDrive/ML/Indiv_Project/Second_Year/KD/Models/generator.pth'\n",
        "  GENERATOR_RECORDS_PATH = 'drive/MyDrive/ML/Indiv_Project/Second_Year/KD/Models/generator.csv'\n",
        "\n",
        "  TEACHER_MODEL_PATH = 'drive/MyDrive/ML/Indiv_Project/Second_Year/KD/ESRGAN_models/RealESRGAN_x4plus.pth'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB4gYxJZN31Q",
        "outputId": "263e96fb-32c7-42ca-e794-00665dc2b8fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting basicsr\n",
            "  Downloading basicsr-1.4.2.tar.gz (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from basicsr) (0.18.3)\n",
            "Collecting lmdb\n",
            "  Downloading lmdb-1.4.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (305 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.9/305.9 KB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from basicsr) (1.22.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.9/dist-packages (from basicsr) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from basicsr) (8.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from basicsr) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from basicsr) (2.27.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (from basicsr) (0.19.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from basicsr) (1.10.1)\n",
            "Collecting tb-nightly\n",
            "  Downloading tb_nightly-2.13.0a20230321-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.9/dist-packages (from basicsr) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from basicsr) (0.14.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from basicsr) (4.65.0)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.2/190.2 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->basicsr) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->basicsr) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->basicsr) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->basicsr) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->basicsr) (3.4)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->basicsr) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image->basicsr) (23.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image->basicsr) (3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image->basicsr) (2023.3.15)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->basicsr) (1.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tb-nightly->basicsr) (2.2.3)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
            "  Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tb-nightly->basicsr) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tb-nightly->basicsr) (2.16.2)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.9/dist-packages (from tb-nightly->basicsr) (1.51.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tb-nightly->basicsr) (63.4.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tb-nightly->basicsr) (1.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tb-nightly->basicsr) (1.8.1)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.9/dist-packages (from tb-nightly->basicsr) (3.19.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tb-nightly->basicsr) (0.40.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (1.16.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tb-nightly->basicsr) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tb-nightly->basicsr) (6.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tb-nightly->basicsr) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly->basicsr) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly->basicsr) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tb-nightly->basicsr) (3.2.2)\n",
            "Building wheels for collected packages: basicsr\n",
            "  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for basicsr: filename=basicsr-1.4.2-py3-none-any.whl size=214838 sha256=fcdc3a6bd204a9efa64458735bb0206806b17982dc06cb57c8cc1314a5d2f635\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/d6/3d/6d8c4b8fabeb93dd442eb255f133e8928c75d903fe20e9472c\n",
            "Successfully built basicsr\n",
            "Installing collected packages: yapf, lmdb, addict, tensorboard-data-server, google-auth-oauthlib, tb-nightly, basicsr\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.6.1\n",
            "    Uninstalling tensorboard-data-server-0.6.1:\n",
            "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 0.4.6\n",
            "    Uninstalling google-auth-oauthlib-0.4.6:\n",
            "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorboard 2.11.2 requires google-auth-oauthlib<0.5,>=0.4.1, but you have google-auth-oauthlib 1.0.0 which is incompatible.\n",
            "tensorboard 2.11.2 requires tensorboard-data-server<0.7.0,>=0.6.0, but you have tensorboard-data-server 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed addict-2.4.0 basicsr-1.4.2 google-auth-oauthlib-1.0.0 lmdb-1.4.0 tb-nightly-2.13.0a20230321 tensorboard-data-server-0.7.0 yapf-0.32.0\n",
            "Mounted at /content/drive/\n",
            "Archive:  /content/drive/MyDrive/Datasets/DIV2K_valid_HR.zip\n",
            "   creating: DIV2K_valid_HR/\n",
            "  inflating: DIV2K_valid_HR/0897.png  \n",
            "  inflating: DIV2K_valid_HR/0887.png  \n",
            "  inflating: DIV2K_valid_HR/0806.png  \n",
            "  inflating: DIV2K_valid_HR/0834.png  \n",
            "  inflating: DIV2K_valid_HR/0896.png  \n",
            "  inflating: DIV2K_valid_HR/0881.png  \n",
            "  inflating: DIV2K_valid_HR/0828.png  \n",
            "  inflating: DIV2K_valid_HR/0833.png  \n",
            "  inflating: DIV2K_valid_HR/0877.png  \n",
            "  inflating: DIV2K_valid_HR/0826.png  \n",
            "  inflating: DIV2K_valid_HR/0879.png  \n",
            "  inflating: DIV2K_valid_HR/0812.png  \n",
            "  inflating: DIV2K_valid_HR/0809.png  \n",
            "  inflating: DIV2K_valid_HR/0865.png  \n",
            "  inflating: DIV2K_valid_HR/0882.png  \n",
            "  inflating: DIV2K_valid_HR/0830.png  \n",
            "  inflating: DIV2K_valid_HR/0892.png  \n",
            "  inflating: DIV2K_valid_HR/0859.png  \n",
            "  inflating: DIV2K_valid_HR/0858.png  \n",
            "  inflating: DIV2K_valid_HR/0816.png  \n",
            "  inflating: DIV2K_valid_HR/0836.png  \n",
            "  inflating: DIV2K_valid_HR/0857.png  \n",
            "  inflating: DIV2K_valid_HR/0824.png  \n",
            "  inflating: DIV2K_valid_HR/0823.png  \n",
            "  inflating: DIV2K_valid_HR/0810.png  \n",
            "  inflating: DIV2K_valid_HR/0900.png  \n",
            "  inflating: DIV2K_valid_HR/0884.png  \n",
            "  inflating: DIV2K_valid_HR/0890.png  \n",
            "  inflating: DIV2K_valid_HR/0835.png  \n",
            "  inflating: DIV2K_valid_HR/0848.png  \n",
            "  inflating: DIV2K_valid_HR/0869.png  \n",
            "  inflating: DIV2K_valid_HR/0878.png  \n",
            "  inflating: DIV2K_valid_HR/0860.png  \n",
            "  inflating: DIV2K_valid_HR/0851.png  \n",
            "  inflating: DIV2K_valid_HR/0870.png  \n",
            "  inflating: DIV2K_valid_HR/0867.png  \n",
            "  inflating: DIV2K_valid_HR/0898.png  \n",
            "  inflating: DIV2K_valid_HR/0818.png  \n",
            "  inflating: DIV2K_valid_HR/0814.png  \n",
            "  inflating: DIV2K_valid_HR/0895.png  \n",
            "  inflating: DIV2K_valid_HR/0856.png  \n",
            "  inflating: DIV2K_valid_HR/0891.png  \n",
            "  inflating: DIV2K_valid_HR/0829.png  \n",
            "  inflating: DIV2K_valid_HR/0825.png  \n",
            "  inflating: DIV2K_valid_HR/0853.png  \n",
            "  inflating: DIV2K_valid_HR/0894.png  \n",
            "  inflating: DIV2K_valid_HR/0863.png  \n",
            "  inflating: DIV2K_valid_HR/0883.png  \n",
            "  inflating: DIV2K_valid_HR/0822.png  \n",
            "  inflating: DIV2K_valid_HR/0837.png  \n",
            "  inflating: DIV2K_valid_HR/0849.png  \n",
            "  inflating: DIV2K_valid_HR/0899.png  \n",
            "  inflating: DIV2K_valid_HR/0807.png  \n",
            "  inflating: DIV2K_valid_HR/0864.png  \n",
            "  inflating: DIV2K_valid_HR/0845.png  \n",
            "  inflating: DIV2K_valid_HR/0871.png  \n",
            "  inflating: DIV2K_valid_HR/0804.png  \n",
            "  inflating: DIV2K_valid_HR/0815.png  \n",
            "  inflating: DIV2K_valid_HR/0813.png  \n",
            "  inflating: DIV2K_valid_HR/0868.png  \n",
            "  inflating: DIV2K_valid_HR/0893.png  \n",
            "  inflating: DIV2K_valid_HR/0876.png  \n",
            "  inflating: DIV2K_valid_HR/0889.png  \n",
            "  inflating: DIV2K_valid_HR/0843.png  \n",
            "  inflating: DIV2K_valid_HR/0862.png  \n",
            "  inflating: DIV2K_valid_HR/0875.png  \n",
            "  inflating: DIV2K_valid_HR/0885.png  \n",
            "  inflating: DIV2K_valid_HR/0866.png  \n",
            "  inflating: DIV2K_valid_HR/0839.png  \n",
            "  inflating: DIV2K_valid_HR/0873.png  \n",
            "  inflating: DIV2K_valid_HR/0820.png  \n",
            "  inflating: DIV2K_valid_HR/0852.png  \n",
            "  inflating: DIV2K_valid_HR/0819.png  \n",
            "  inflating: DIV2K_valid_HR/0808.png  \n",
            "  inflating: DIV2K_valid_HR/0802.png  \n",
            "  inflating: DIV2K_valid_HR/0821.png  \n",
            "  inflating: DIV2K_valid_HR/0811.png  \n",
            "  inflating: DIV2K_valid_HR/0847.png  \n",
            "  inflating: DIV2K_valid_HR/0838.png  \n",
            "  inflating: DIV2K_valid_HR/0827.png  \n",
            "  inflating: DIV2K_valid_HR/0844.png  \n",
            "  inflating: DIV2K_valid_HR/0872.png  \n",
            "  inflating: DIV2K_valid_HR/0880.png  \n",
            "  inflating: DIV2K_valid_HR/0854.png  \n",
            "  inflating: DIV2K_valid_HR/0831.png  \n",
            "  inflating: DIV2K_valid_HR/0841.png  \n",
            "  inflating: DIV2K_valid_HR/0832.png  \n",
            "  inflating: DIV2K_valid_HR/0801.png  \n",
            "  inflating: DIV2K_valid_HR/0805.png  \n",
            "  inflating: DIV2K_valid_HR/0888.png  \n",
            "  inflating: DIV2K_valid_HR/0861.png  \n",
            "  inflating: DIV2K_valid_HR/0817.png  \n",
            "  inflating: DIV2K_valid_HR/0803.png  \n",
            "  inflating: DIV2K_valid_HR/0842.png  \n",
            "  inflating: DIV2K_valid_HR/0855.png  \n",
            "  inflating: DIV2K_valid_HR/0840.png  \n",
            "  inflating: DIV2K_valid_HR/0874.png  \n",
            "  inflating: DIV2K_valid_HR/0846.png  \n",
            "  inflating: DIV2K_valid_HR/0886.png  \n",
            "  inflating: DIV2K_valid_HR/0850.png  \n",
            "Archive:  /content/drive/MyDrive/Datasets/DIV2K_valid_LR_clean.zip\n",
            "   creating: DIV2K_valid_LR_clean/\n",
            "  inflating: DIV2K_valid_LR_clean/0801.png  \n",
            " extracting: DIV2K_valid_LR_clean/0802.png  \n",
            " extracting: DIV2K_valid_LR_clean/0803.png  \n",
            " extracting: DIV2K_valid_LR_clean/0804.png  \n",
            "  inflating: DIV2K_valid_LR_clean/0805.png  \n",
            " extracting: DIV2K_valid_LR_clean/0806.png  \n",
            " extracting: DIV2K_valid_LR_clean/0807.png  \n",
            " extracting: DIV2K_valid_LR_clean/0808.png  \n",
            "  inflating: DIV2K_valid_LR_clean/0809.png  \n",
            "  inflating: DIV2K_valid_LR_clean/0810.png  \n",
            "  inflating: DIV2K_valid_LR_clean/0811.png  \n",
            " extracting: DIV2K_valid_LR_clean/0812.png  \n",
            " extracting: DIV2K_valid_LR_clean/0813.png  \n",
            " extracting: DIV2K_valid_LR_clean/0814.png  \n",
            " extracting: DIV2K_valid_LR_clean/0815.png  \n",
            "  inflating: DIV2K_valid_LR_clean/0816.png  \n",
            " extracting: DIV2K_valid_LR_clean/0817.png  \n",
            " extracting: DIV2K_valid_LR_clean/0818.png  \n",
            " extracting: DIV2K_valid_LR_clean/0819.png  \n",
            " extracting: DIV2K_valid_LR_clean/0820.png  \n",
            " extracting: DIV2K_valid_LR_clean/0821.png  \n",
            " extracting: DIV2K_valid_LR_clean/0822.png  \n",
            " extracting: DIV2K_valid_LR_clean/0823.png  \n",
            " extracting: DIV2K_valid_LR_clean/0824.png  \n",
            " extracting: DIV2K_valid_LR_clean/0825.png  \n",
            " extracting: DIV2K_valid_LR_clean/0826.png  \n",
            " extracting: DIV2K_valid_LR_clean/0827.png  \n",
            " extracting: DIV2K_valid_LR_clean/0828.png  \n",
            " extracting: DIV2K_valid_LR_clean/0829.png  \n",
            "  inflating: DIV2K_valid_LR_clean/0830.png  \n",
            " extracting: DIV2K_valid_LR_clean/0831.png  \n",
            " extracting: DIV2K_valid_LR_clean/0832.png  \n",
            " extracting: DIV2K_valid_LR_clean/0833.png  \n",
            " extracting: DIV2K_valid_LR_clean/0834.png  \n",
            "  inflating: DIV2K_valid_LR_clean/0835.png  \n",
            " extracting: DIV2K_valid_LR_clean/0836.png  \n",
            " extracting: DIV2K_valid_LR_clean/0837.png  \n",
            " extracting: DIV2K_valid_LR_clean/0838.png  \n",
            "  inflating: DIV2K_valid_LR_clean/0839.png  \n",
            "  inflating: DIV2K_valid_LR_clean/0840.png  \n",
            " extracting: DIV2K_valid_LR_clean/0841.png  \n",
            "  inflating: DIV2K_valid_LR_clean/0842.png  \n",
            "  inflating: DIV2K_valid_LR_clean/0843.png  \n",
            " extracting: DIV2K_valid_LR_clean/0844.png  \n",
            " extracting: DIV2K_valid_LR_clean/0845.png  \n",
            "  inflating: DIV2K_valid_LR_clean/0846.png  \n",
            " extracting: DIV2K_valid_LR_clean/0847.png  \n",
            " extracting: DIV2K_valid_LR_clean/0848.png  \n",
            " extracting: DIV2K_valid_LR_clean/0849.png  \n",
            " extracting: DIV2K_valid_LR_clean/0850.png  \n",
            " extracting: DIV2K_valid_LR_clean/0851.png  \n",
            " extracting: DIV2K_valid_LR_clean/0852.png  \n",
            " extracting: DIV2K_valid_LR_clean/0853.png  \n",
            " extracting: DIV2K_valid_LR_clean/0854.png  \n",
            "  inflating: DIV2K_valid_LR_clean/0855.png  \n",
            " extracting: DIV2K_valid_LR_clean/0856.png  \n",
            " extracting: DIV2K_valid_LR_clean/0857.png  \n",
            " extracting: DIV2K_valid_LR_clean/0858.png  \n",
            " extracting: DIV2K_valid_LR_clean/0859.png  \n",
            " extracting: DIV2K_valid_LR_clean/0860.png  \n",
            " extracting: DIV2K_valid_LR_clean/0861.png  \n",
            " extracting: DIV2K_valid_LR_clean/0862.png  \n",
            " extracting: DIV2K_valid_LR_clean/0863.png  \n",
            "  inflating: DIV2K_valid_LR_clean/0864.png  \n",
            "  inflating: DIV2K_valid_LR_clean/0865.png  \n",
            "  inflating: DIV2K_valid_LR_clean/0866.png  \n",
            " extracting: DIV2K_valid_LR_clean/0867.png  \n",
            " extracting: DIV2K_valid_LR_clean/0868.png  \n",
            " extracting: DIV2K_valid_LR_clean/0869.png  \n",
            " extracting: DIV2K_valid_LR_clean/0870.png  \n",
            " extracting: DIV2K_valid_LR_clean/0871.png  \n",
            " extracting: DIV2K_valid_LR_clean/0872.png  \n",
            " extracting: DIV2K_valid_LR_clean/0873.png  \n",
            "  inflating: DIV2K_valid_LR_clean/0874.png  \n",
            " extracting: DIV2K_valid_LR_clean/0875.png  \n",
            " extracting: DIV2K_valid_LR_clean/0876.png  \n",
            " extracting: DIV2K_valid_LR_clean/0877.png  \n",
            "  inflating: DIV2K_valid_LR_clean/0878.png  \n",
            " extracting: DIV2K_valid_LR_clean/0879.png  \n",
            " extracting: DIV2K_valid_LR_clean/0880.png  \n",
            " extracting: DIV2K_valid_LR_clean/0881.png  \n",
            " extracting: DIV2K_valid_LR_clean/0882.png  \n",
            " extracting: DIV2K_valid_LR_clean/0883.png  \n",
            " extracting: DIV2K_valid_LR_clean/0884.png  \n",
            " extracting: DIV2K_valid_LR_clean/0885.png  \n",
            " extracting: DIV2K_valid_LR_clean/0886.png  \n",
            " extracting: DIV2K_valid_LR_clean/0887.png  \n",
            " extracting: DIV2K_valid_LR_clean/0888.png  \n",
            " extracting: DIV2K_valid_LR_clean/0889.png  \n",
            " extracting: DIV2K_valid_LR_clean/0890.png  \n",
            " extracting: DIV2K_valid_LR_clean/0891.png  \n",
            " extracting: DIV2K_valid_LR_clean/0892.png  \n",
            " extracting: DIV2K_valid_LR_clean/0893.png  \n",
            "  inflating: DIV2K_valid_LR_clean/0894.png  \n",
            " extracting: DIV2K_valid_LR_clean/0895.png  \n",
            " extracting: DIV2K_valid_LR_clean/0896.png  \n",
            " extracting: DIV2K_valid_LR_clean/0897.png  \n",
            " extracting: DIV2K_valid_LR_clean/0898.png  \n",
            " extracting: DIV2K_valid_LR_clean/0899.png  \n",
            " extracting: DIV2K_valid_LR_clean/0900.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run on my Windows desktop"
      ],
      "metadata": {
        "id": "y3keGCgTN5-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not IN_COLAB:\n",
        "  FOLDER_LR_TEST = 'D:\\Downloads\\Div2k\\DIV2K_valid_LR_clean'\n",
        "  FOLDER_HR_TEST = 'D:\\Downloads\\Div2k\\DIV2K_valid_HR'\n",
        "  FOLDER_LR_TRAIN = 'D:\\Downloads\\Div2k\\DIV2K_train_LR_clean'\n",
        "  FOLDER_HR_TRAIN = 'D:\\Downloads\\Div2k\\DIV2K_train_HR'\n",
        "  \n",
        "  STUDENT_MODEL_PATH='D:\\oldDrive\\ML\\Indiv_Project\\Second_Year\\KD\\Models\\student.pth'\n",
        "  STUDENT_RECORDS_PATH='D:\\oldDrive\\ML\\Indiv_Project\\Second_Year\\KD\\Models\\student.csv'\n",
        "  GENERATOR_MODEL_PATH='D:\\oldDrive\\ML\\Indiv_Project\\Second_Year\\KD\\Models\\generator.pth'\n",
        "  GENERATOR_RECORDS_PATH='D:\\oldDrive\\ML\\Indiv_Project\\Second_Year\\KD\\Models\\generator.csv'\n",
        "  \n",
        "  TEACHER_MODEL_PATH = 'D:\\oldDrive\\ML\\Indiv_Project\\Second_Year\\KD\\ESRGAN_models\\RealESRGAN_x4plus.pth'"
      ],
      "metadata": {
        "id": "WnGM39h8N53v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "mxBzg_aBOANA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import cv2\n",
        "import csv\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import queue\n",
        "import threading\n",
        "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "import torchvision\n",
        "from os import listdir, environ, path\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models import vgg19\n",
        "\n",
        "# Making sure to use the gpu, if available\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# torch.cuda.set_device(torch.device(0))"
      ],
      "metadata": {
        "id": "RAnDybsWOAHA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DIV2KLoader(object):\n",
        "  def __init__(self, low_res_folder, high_res_folder = None, preprocessing_input = None, preprocessing_output = None, include_targets = True):\n",
        "    self.low_res_folder = low_res_folder\n",
        "    self.high_res_folder = high_res_folder\n",
        "    self.img_names = sorted(listdir(low_res_folder))\n",
        "    self.include_targets = include_targets\n",
        "    self.len = len(self.img_names)\n",
        "    \n",
        "    if include_targets or high_res_folder is not None:\n",
        "      self.target_names = sorted(listdir(high_res_folder))\n",
        "\n",
        "    if preprocessing_input is None:\n",
        "      self.preprocessing_input = torchvision.transforms.ToTensor()\n",
        "    else:\n",
        "      self.preprocessing_input = preprocessing_input\n",
        "\n",
        "    if preprocessing_output is None:\n",
        "      self.preprocessing_output = torchvision.transforms.ToTensor()\n",
        "    else:\n",
        "      self.preprocessing_output = preprocessing_output\n",
        "  \n",
        "  def __getitem__(self, i):\n",
        "    # Get the right image\n",
        "    img = Image.open(Path(self.low_res_folder).joinpath(self.img_names[i]))\n",
        "    if self.include_targets or self.high_res_folder is not None:\n",
        "      target = Image.open(Path(self.high_res_folder).joinpath(self.target_names[i]))\n",
        "      return self.preprocessing_input(img), self.preprocessing_output(target)\n",
        "    else:\n",
        "      return self.preprocessing_input(img)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "  \n",
        "  def restrict_size(self, size):\n",
        "    if size < len(self.img_names) and size > 0:\n",
        "      self.len = size\n",
        "    else:\n",
        "      self.len = len(self.img_names)\n",
        "      print(f\"Size must be between 0 and {len(self.img_names)}\")"
      ],
      "metadata": {
        "id": "LAlAXNiVOCsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 is resize\n",
        "# 1 is crop center\n",
        "# 2 is crop random (requires finish implementation)\n",
        "\n",
        "MODE = 1\n",
        "IM_SIZE = 50\n",
        "\n",
        "def resize_ratio(img, size=IM_SIZE):\n",
        "  width, height = img.size\n",
        "  if width > height:\n",
        "    width, height = size, int(height * size / width)\n",
        "  else:\n",
        "    width, height = int(width * size / height), size\n",
        "  return width, height\n",
        "\n",
        "def preprocessing_output(img):\n",
        "  im_w, im_h = img.size\n",
        "  if MODE == 1:\n",
        "    img = img.crop(((im_w - 400)/2, (im_h - 400)/2, (im_w + 400)/2, (im_h + 400)/2))\n",
        "  elif MODE == 2:\n",
        "    width, height = resize_ratio(img)\n",
        "    origin_x, origin_y = 0, 0\n",
        "    img = img.crop((origin_x, origin_y, origin_x + width*4, origin_y + height*4))\n",
        "  return torchvision.transforms.ToTensor()(img).to(device)\n",
        "\n",
        "def preprocessing_input(img):\n",
        "  im_w, im_h = img.size\n",
        "  if MODE == 1:\n",
        "    img = img.crop(((im_w - 400)/2, (im_h - 400)/2, (im_w + 400)/2, (im_h + 400)/2)).resize((100, 100))\n",
        "  elif MODE == 2:\n",
        "    width, height = resize_ratio(img)\n",
        "    origin_x, origin_y = 0, 0\n",
        "    img = img.crop((origin_x, origin_y, origin_x + width*4, origin_y + height*4)).resize((width, height))\n",
        "  return torchvision.transforms.ToTensor()(img).to(device)\n",
        "\n",
        "data_test = DIV2KLoader(FOLDER_HR_TEST, FOLDER_HR_TEST, preprocessing_input=preprocessing_input, preprocessing_output=preprocessing_output)\n",
        "data_test.restrict_size(10)\n",
        "dataloader_test = torch.utils.data.DataLoader(data_test, batch_size=1, shuffle=False)\n",
        "\n",
        "data_train = DIV2KLoader(FOLDER_LR_TRAIN_CLEAN, FOLDER_LR_TRAIN_CLEAN, preprocessing_input=preprocessing_input, preprocessing_output=preprocessing_output)\n",
        "data_test.restrict_size(10)\n",
        "dataloader_test = torch.utils.data.DataLoader(data_test, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "zUn-cvdGOF0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminator"
      ],
      "metadata": {
        "id": "vd6trYshOGaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels: int, out_channels: int, kernel_size: int, use_act: bool = True, **kwargs):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, **kwargs)\n",
        "    self.bn = nn.BatchNorm2d(out_channels)\n",
        "    self.activation = nn.ReLU(inplace = True) if use_act else nn.Identity()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.activation(self.conv(x))\n",
        "\n",
        "class ResidualBlock_v1(nn.Module):\n",
        "  def __init__(self, in_channels):\n",
        "    super().__init__()\n",
        "    self.block = nn.Sequential(\n",
        "        ConvBlock(in_channels, in_channels, 3, stride=1, padding=1),\n",
        "        ConvBlock(in_channels, in_channels, 3, stride=1, padding=1))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x + self.block(x)\n",
        "\n",
        "class ResidualBlock_v2(nn.Module):\n",
        "  def __init__(self, in_channels, mid_channels, **kwargs):\n",
        "    self.block = nn.Sequential(ConvBlock(in_channels, mid_channels, 1, padding=0, **kwargs),\n",
        "                               ConvBlock(mid_channels, mid_channels, 3, padding=1, stride=1),\n",
        "                               ConvBlock(mid_channels, mid_channels*4, 1, padding=0, stride=1, use_act = False))\n",
        "    self.residual = nn.Identity() if in_channels*4 == mid_channels*4 else ConvBlock(in_channels, in_channels*4, 1, padding=0, stride=1, use_act = False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.block(x) + self.residual(x)\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    self.head = nn.Sequential(ConvBlock(3, 64, 7, stride=2), nn.MaxPool2d(3, 2))\n",
        "    self.body = nn.Identity()\n",
        "    self.tail = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)),\n",
        "                              nn.Flatten(),\n",
        "                              nn.Linear(1))\n",
        "    \n",
        "    def forward(self, x):\n",
        "      return self.tail(self.body(self.head(x)))\n",
        "\n",
        "class ResNet_18(ResNet):\n",
        "  def __init__(self):\n",
        "    architecture = [64, 128, 256, 512]\n",
        "    self.body = nn.Sequential(*[self._makeBlock(channels) for channels in architecture)]\n",
        "\n",
        "  def _makeBlock(self, in_channels):\n",
        "    return nn.Sequential(ResidualBlock_v1(in_channels), ResidualBlock_v1(in_channels))\n",
        "\n",
        "class Resnet_50(ResNet):\n",
        "  def __init__(self):\n",
        "    architecture = [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3\n",
        "    self.body = self._makeBlock(architecture)\n",
        "  \n",
        "  def _makeBlock(self, architecture):\n",
        "    layers = [ResidualBlock_v2(64, 64, stride=1)]\n",
        "\n",
        "    for i in range(1, len(self.architecture)):\n",
        "      in_channels = mid_channels*4\n",
        "      mid_channels = self.architecture[i]\n",
        "      layers.append(ResidualBlock_v2(in_channels, mid_channels, stride= 2 if self.architecture[i-1] != self.architecture[i] else 1))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# Follows the guidelines of https://github.com/soumith/ganhacks\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, model: nn.Module):\n",
        "    self.model = model\n",
        "    self.loss_fn = nn.BCELOSS()\n",
        "    self.optimizer = torch.optim.Adam(self.parameters())\n",
        "\n",
        "  def run_training(self, dataloader):\n",
        "    cumu_loss = 0\n",
        "    accuracy = 0\n",
        "    # This dataloader outputs (Generator(LR_images), HR_images)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      fake, real = X.to(DEVICE), y.to(DEVICE)\n",
        "      out_real, out_fake = torch.sigmoid(self.model(y.to(DEVICE))), torch.sigmoid(self.model(X.to(DEVICE)))\n",
        "      \n",
        "      out = torch.cat([fake, real], dim=1)\n",
        "      out = torch.sigmoid(self.model(out))\n",
        "      target = torch.cat([torch.zeros_like(fake), torch.ones_like(real)], dim=1)\n",
        "\n",
        "      loss = self.loss_fn(out, target)\n",
        "      cumu_loss += loss.item()\n",
        "      \n",
        "      self.optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      self.optimizer.step()\n",
        "      \n",
        "      accuracy_tmp = torch.count_nonzero(torch.equal(out > .5, target)) / target.shape[0]\n",
        "      accuracy += accuracy_tmp\n",
        "\n",
        "      if batch % 20 == 0:\n",
        "        print(f'Trained batch {batch} with loss {loss.item()}')\n",
        "        print(f'Accuracy: {accuracy_tmp}')\n",
        "\n",
        "    return {'loss': cumu_loss/len(dataloader), 'accuracy': accuracy/len(dataloader)}\n",
        "\n",
        "class VGGLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.vgg = vgg19(pretrained=True).features[:35].eval().to(DEVICE)\n",
        "\n",
        "    for param in self.vgg.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    self.loss = nn.MSELoss()\n",
        "\n",
        "  def forward(self, input, target):\n",
        "    vgg_input_features = self.vgg(input)\n",
        "    vgg_target_features = self.vgg(target)\n",
        "    return self.loss(vgg_input_features, vgg_target_features)\n",
        "\n",
        "class GAN:\n",
        "  def __init__(self, gene, disc):\n",
        "    self.disc = disc\n",
        "    self.gen = gene\n",
        "    self.opt_d = torch.optim.Adam(self.disc.parameters(), lr=2e-5)\n",
        "    self.opt_g = torch.optim.Adam(self.gen.parameters(), lr=2e-5)\n",
        "    self.lmb = 5e-3\n",
        "    self.nu = 1e-2\n",
        "    self.vgg_loss = VGGLoss()\n",
        "    self.l1_loss = nn.L1Loss()\n",
        "    \n",
        "  def run_training(self, dataloader):\n",
        "    cum_loss_d, cum_loss_g = 0, 0\n",
        "    accuracy = 0\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      # Train discriminator\n",
        "      fake = self.gen(X.to(DEVICE))\n",
        "      y_cuda = y.to(DEVICE)\n",
        "\n",
        "      loss_g = self.train_one_model(y_cuda, fake, True)\n",
        "      loss_d = self.train_one_model(y_cuda, fake, False)\n",
        "\n",
        "      cumu_loss_d += loss_d\n",
        "      cumu_loss_g += loss_g\n",
        "\n",
        "      if batch % 20 == 0:\n",
        "        print(f'Training batch {batch} with discriminator loss {loss_d:.2f} and generator loss {loss_g:.2f}')\n",
        "      \n",
        "      out_fake, out_real = torch.sigmoid(fake), torch.sigmoid(y_cuda)\n",
        "      accuracy_tmp = torch.count_nonzero(out_fake < 0.5) / out_fake.shape[0] + torch.count_nonzero(out_real > 0.5) / out_real.shape[0]\n",
        "      accuracy += accuracy_tmp\n",
        "      print(f'Accuracy: {accuracy_tmp}')\n",
        "\n",
        "    return {'discriminator': cumu_loss_d / len(dataloader),'generator': cumu_loss_g / len(dataloader), 'accuracy': accuracy / len(dataloader)}\n",
        "\n",
        "  def train_one_model(self, y_cuda, fake, is_generator: bool):\n",
        "    d_ra_real, d_ra_fake = self.out_ra(self.disc(y_cuda), self.disc(fake if is_generator else fake.detach()))\n",
        "    loss = self.loss_g(d_ra_real, d_ra_fake, fake, y_cuda) if is_generator else self.loss_d(d_ra_real, d_ra_fake)\n",
        "\n",
        "    optimizer = self.opt_g if is_generator else self.opt_d\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "  def out_ra(self, out_real, out_fake):\n",
        "    return torch.sigmoid(out_real - torch.mean(out_fake)),\n",
        "            torch.sigmoid(out_fake - torch.mean(out_real))\n",
        "\n",
        "  def loss_d(self, d_ra_real, d_ra_fake):\n",
        "    return -torch.mean(torch.log(d_ra_real))) - torch.mean(torch.log(1 - d_ra_fake))\n",
        "\n",
        "  def loss_g(self, d_ra_real, d_ra_fake, fake, real):\n",
        "    loss_percep = self.vgg_loss(fake, real)\n",
        "    loss_ra = self.loss_d(d_ra_fake, d_ra_real)\n",
        "    loss_l1 = self.l1_loss(fake, real)\n",
        "\n",
        "    return loss_percep + self.lmb * loss_ra + self.nu * loss_l1"
      ],
      "metadata": {
        "id": "ejsr-lBJOMH3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}