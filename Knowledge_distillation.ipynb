{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vincentbriat/Super-resolution-investigation/blob/main/Knowledge_distillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOWuEn0M1kIK",
        "outputId": "513b5152-2596-4cb3-b61e-89dd9d3bff01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-msssim\n",
            "  Downloading pytorch_msssim-0.2.1-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from pytorch-msssim) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->pytorch-msssim) (4.5.0)\n",
            "Installing collected packages: pytorch-msssim\n",
            "Successfully installed pytorch-msssim-0.2.1\n",
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from os import listdir, environ, path\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torchvision\n",
        "import cv2 as cv \n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import random as rd\n",
        "import csv\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install pytorch-msssim\n",
        "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
        "\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F-esnO4P34rH"
      },
      "outputs": [],
      "source": [
        "# Making sure to use the gpu, if available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# torch.cuda.set_device(torch.device(0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels: int, out_channels: int, kernel_size: int, use_act: bool, **kwargs):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, **kwargs)\n",
        "    self.activation = nn.LeakyReLU(.2, inplace=True) if use_act else nn.Identity()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.activation(self.conv(x))\n",
        "\n",
        "class RDB(nn.Module):\n",
        "  def __init__(self, in_channels, middle_channels = 32, residual_scale = .2):\n",
        "    super().__init__()\n",
        "    self.residual_scale = residual_scale\n",
        "    self.block = nn.ModuleList([ConvBlock(in_channels + i * middle_channels,\n",
        "                                  middle_channels if i<4 else in_channels,\n",
        "                                  3,\n",
        "                                  stride=1,\n",
        "                                  padding=1,\n",
        "                                  use_act=i<4) for i in range(5)])\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    input = x\n",
        "    for conv in self.block:\n",
        "      out = conv(input)\n",
        "      input = torch.cat([input, out], dim=1)\n",
        "    return self.residual_scale * out + x\n",
        "\n",
        "class RRDB(nn.Module):\n",
        "  def __init__(self, in_channels, residual_scale = .2):\n",
        "    super().__init__()\n",
        "    self.residual_scale = residual_scale\n",
        "    self.model = nn.Sequential(*[RDB(in_channels, residual_scale = residual_scale) for _ in range(3)])\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.model(x) * self.residual_scale + x\n",
        "\n",
        "class Head(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "    super().__init__()\n",
        "    self.model = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "class Tail(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(nn.Conv2d(64, 256, 3, stride=1, padding=1),\n",
        "                               nn.Upsample(scale_factor=3, mode='nearest'),\n",
        "                               nn.LeakyReLU(.2, inplace=True),\n",
        "                               nn.Conv2d(256, 3, 3, stride=1, padding=1))\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.model(x)"
      ],
      "metadata": {
        "id": "fL3R7fnPHOqV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "UXeRIcUAHf7j"
      },
      "outputs": [],
      "source": [
        "class Student(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.head = Head()\n",
        "    self.bodies = nn.ModuleList([RRDB(64) for _ in range(16)])\n",
        "    self.post_body_conv = nn.Conv2d(64, 64, 3, stride=1, padding=1)\n",
        "    self.tail = Tail()\n",
        "    self.loss_fn = nn.L1Loss()\n",
        "    self.opt = torch.optim.SGD(self.parameters(), lr=0.1)\n",
        "    self.scheduler = torch.optim.lr_scheduler.StepLR(self.opt, step_size=10, gamma=0.5)\n",
        "    self.nb_of_bodies = 1\n",
        "  \n",
        "  def forward(self, x: torch.Tensor):\n",
        "    output = self.head(x)\n",
        "    for i in range(self.nb_of_bodies):\n",
        "      output = self.bodies[i](output)\n",
        "    output = self.head(x) + self.post_body_conv(output)\n",
        "    return self.tail(output)\n",
        "\n",
        "  def train(self, output_generator: torch.Tensor, output_teacher: torch.Tensor):\n",
        "    super().train()\n",
        "    output_student = self(output_generator)\n",
        "    return self.learn(output_student, output_teacher)\n",
        "    \n",
        "  def learn(self, output_student: torch.Tensor, output_teacher: torch.Tensor):\n",
        "    loss = self.loss_fn(output_student, output_teacher)\n",
        "    self.opt.zero_grad()\n",
        "    loss.backward()\n",
        "    self.opt.step()\n",
        "    return loss\n",
        "\n",
        "  def initialize_csv(self, path, loss):\n",
        "    self.record(path, ['epoch', 'loss'])\n",
        "    self.record(path, [self.cur_epoch, loss])\n",
        "\n",
        "  def record(self, path, row):\n",
        "    with open(path, 'a', newline='') as f:\n",
        "      csv.writer(f).writerow(row)\n",
        "    print(\"Recorded Successfully!\")\n",
        "  \n",
        "  def load(self, path):\n",
        "    saved_info = torch.load(path)\n",
        "    self.load_state_dict(saved_info['model_state_dict'])\n",
        "    self.opt.load_state_dict(saved_info['optimizer_state_dict'])\n",
        "    self.scheduler.load_state_dict(saved_info['lr_scheduler_state_dict'])\n",
        "    self.cur_epoch = saved_info['epochs'] + 1\n",
        "    self.loss_fn = saved_info['loss_fn']\n",
        "\n",
        "  def save(self,path):\n",
        "    torch.save({'epochs': self.cur_epoch, 'model_state_dict': self.state_dict(), 'optimizer_state_dict': self.opt.state_dict(), 'loss_fn': self.loss_fn, 'lr_scheduler_state_dict': self.scheduler.state_dict()}, path)\n",
        "    print(\"Saved Successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "sZW_0IcST1lO"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(nn.Conv2d(1,64,3), nn.Conv2d(64, 3, 5))\n",
        "    self.loss_fn = nn.L1Loss()\n",
        "    self.opt = torch.optim.SGD(self.parameters(), lr=1e-5)\n",
        "    self.scheduler = torch.optim.lr_scheduler.StepLR(self.opt, step_size=10, gamma=0.5)\n",
        "    self.weight_r = 1.\n",
        "  \n",
        "  def forward(self, x: torch.Tensor):\n",
        "    return self.model(x)\n",
        "\n",
        "  def train(self, output_generator: torch.Tensor, output_teacher: torch.Tensor, output_student: torch.Tensor):\n",
        "    super().train()\n",
        "\n",
        "    loss_gen = -torch.log(self.loss_fn(output_student, output_teacher) + 1)\n",
        "    loss_r = self.loss_fn(output_generator, torchvision.transforms.Resize(output_generator.shape[-2:])(output_teacher))\n",
        "\n",
        "    loss = loss_gen + self.weight_r * loss_r\n",
        "\n",
        "    self.opt.zero_grad()\n",
        "    loss.backward()\n",
        "    self.opt.step()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50ItaNPJWtzR",
        "outputId": "83ea11a4-02bf-4a76-cbf0-84ac957ec548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 48, 48]           1,792\n",
            "              Head-2           [-1, 64, 48, 48]               0\n",
            "            Conv2d-3           [-1, 32, 48, 48]          18,464\n",
            "         LeakyReLU-4           [-1, 32, 48, 48]               0\n",
            "         ConvBlock-5           [-1, 32, 48, 48]               0\n",
            "            Conv2d-6           [-1, 32, 48, 48]          27,680\n",
            "         LeakyReLU-7           [-1, 32, 48, 48]               0\n",
            "         ConvBlock-8           [-1, 32, 48, 48]               0\n",
            "            Conv2d-9           [-1, 32, 48, 48]          36,896\n",
            "        LeakyReLU-10           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-11           [-1, 32, 48, 48]               0\n",
            "           Conv2d-12           [-1, 32, 48, 48]          46,112\n",
            "        LeakyReLU-13           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-14           [-1, 32, 48, 48]               0\n",
            "           Conv2d-15           [-1, 64, 48, 48]         110,656\n",
            "         Identity-16           [-1, 64, 48, 48]               0\n",
            "        ConvBlock-17           [-1, 64, 48, 48]               0\n",
            "              RDB-18           [-1, 64, 48, 48]               0\n",
            "           Conv2d-19           [-1, 32, 48, 48]          18,464\n",
            "        LeakyReLU-20           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-21           [-1, 32, 48, 48]               0\n",
            "           Conv2d-22           [-1, 32, 48, 48]          27,680\n",
            "        LeakyReLU-23           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-24           [-1, 32, 48, 48]               0\n",
            "           Conv2d-25           [-1, 32, 48, 48]          36,896\n",
            "        LeakyReLU-26           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-27           [-1, 32, 48, 48]               0\n",
            "           Conv2d-28           [-1, 32, 48, 48]          46,112\n",
            "        LeakyReLU-29           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-30           [-1, 32, 48, 48]               0\n",
            "           Conv2d-31           [-1, 64, 48, 48]         110,656\n",
            "         Identity-32           [-1, 64, 48, 48]               0\n",
            "        ConvBlock-33           [-1, 64, 48, 48]               0\n",
            "              RDB-34           [-1, 64, 48, 48]               0\n",
            "           Conv2d-35           [-1, 32, 48, 48]          18,464\n",
            "        LeakyReLU-36           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-37           [-1, 32, 48, 48]               0\n",
            "           Conv2d-38           [-1, 32, 48, 48]          27,680\n",
            "        LeakyReLU-39           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-40           [-1, 32, 48, 48]               0\n",
            "           Conv2d-41           [-1, 32, 48, 48]          36,896\n",
            "        LeakyReLU-42           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-43           [-1, 32, 48, 48]               0\n",
            "           Conv2d-44           [-1, 32, 48, 48]          46,112\n",
            "        LeakyReLU-45           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-46           [-1, 32, 48, 48]               0\n",
            "           Conv2d-47           [-1, 64, 48, 48]         110,656\n",
            "         Identity-48           [-1, 64, 48, 48]               0\n",
            "        ConvBlock-49           [-1, 64, 48, 48]               0\n",
            "              RDB-50           [-1, 64, 48, 48]               0\n",
            "             RRDB-51           [-1, 64, 48, 48]               0\n",
            "           Conv2d-52           [-1, 32, 48, 48]          18,464\n",
            "        LeakyReLU-53           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-54           [-1, 32, 48, 48]               0\n",
            "           Conv2d-55           [-1, 32, 48, 48]          27,680\n",
            "        LeakyReLU-56           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-57           [-1, 32, 48, 48]               0\n",
            "           Conv2d-58           [-1, 32, 48, 48]          36,896\n",
            "        LeakyReLU-59           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-60           [-1, 32, 48, 48]               0\n",
            "           Conv2d-61           [-1, 32, 48, 48]          46,112\n",
            "        LeakyReLU-62           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-63           [-1, 32, 48, 48]               0\n",
            "           Conv2d-64           [-1, 64, 48, 48]         110,656\n",
            "         Identity-65           [-1, 64, 48, 48]               0\n",
            "        ConvBlock-66           [-1, 64, 48, 48]               0\n",
            "              RDB-67           [-1, 64, 48, 48]               0\n",
            "           Conv2d-68           [-1, 32, 48, 48]          18,464\n",
            "        LeakyReLU-69           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-70           [-1, 32, 48, 48]               0\n",
            "           Conv2d-71           [-1, 32, 48, 48]          27,680\n",
            "        LeakyReLU-72           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-73           [-1, 32, 48, 48]               0\n",
            "           Conv2d-74           [-1, 32, 48, 48]          36,896\n",
            "        LeakyReLU-75           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-76           [-1, 32, 48, 48]               0\n",
            "           Conv2d-77           [-1, 32, 48, 48]          46,112\n",
            "        LeakyReLU-78           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-79           [-1, 32, 48, 48]               0\n",
            "           Conv2d-80           [-1, 64, 48, 48]         110,656\n",
            "         Identity-81           [-1, 64, 48, 48]               0\n",
            "        ConvBlock-82           [-1, 64, 48, 48]               0\n",
            "              RDB-83           [-1, 64, 48, 48]               0\n",
            "           Conv2d-84           [-1, 32, 48, 48]          18,464\n",
            "        LeakyReLU-85           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-86           [-1, 32, 48, 48]               0\n",
            "           Conv2d-87           [-1, 32, 48, 48]          27,680\n",
            "        LeakyReLU-88           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-89           [-1, 32, 48, 48]               0\n",
            "           Conv2d-90           [-1, 32, 48, 48]          36,896\n",
            "        LeakyReLU-91           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-92           [-1, 32, 48, 48]               0\n",
            "           Conv2d-93           [-1, 32, 48, 48]          46,112\n",
            "        LeakyReLU-94           [-1, 32, 48, 48]               0\n",
            "        ConvBlock-95           [-1, 32, 48, 48]               0\n",
            "           Conv2d-96           [-1, 64, 48, 48]         110,656\n",
            "         Identity-97           [-1, 64, 48, 48]               0\n",
            "        ConvBlock-98           [-1, 64, 48, 48]               0\n",
            "              RDB-99           [-1, 64, 48, 48]               0\n",
            "            RRDB-100           [-1, 64, 48, 48]               0\n",
            "          Conv2d-101           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-102           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-103           [-1, 32, 48, 48]               0\n",
            "          Conv2d-104           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-105           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-106           [-1, 32, 48, 48]               0\n",
            "          Conv2d-107           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-108           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-109           [-1, 32, 48, 48]               0\n",
            "          Conv2d-110           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-111           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-112           [-1, 32, 48, 48]               0\n",
            "          Conv2d-113           [-1, 64, 48, 48]         110,656\n",
            "        Identity-114           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-115           [-1, 64, 48, 48]               0\n",
            "             RDB-116           [-1, 64, 48, 48]               0\n",
            "          Conv2d-117           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-118           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-119           [-1, 32, 48, 48]               0\n",
            "          Conv2d-120           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-121           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-122           [-1, 32, 48, 48]               0\n",
            "          Conv2d-123           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-124           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-125           [-1, 32, 48, 48]               0\n",
            "          Conv2d-126           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-127           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-128           [-1, 32, 48, 48]               0\n",
            "          Conv2d-129           [-1, 64, 48, 48]         110,656\n",
            "        Identity-130           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-131           [-1, 64, 48, 48]               0\n",
            "             RDB-132           [-1, 64, 48, 48]               0\n",
            "          Conv2d-133           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-134           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-135           [-1, 32, 48, 48]               0\n",
            "          Conv2d-136           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-137           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-138           [-1, 32, 48, 48]               0\n",
            "          Conv2d-139           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-140           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-141           [-1, 32, 48, 48]               0\n",
            "          Conv2d-142           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-143           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-144           [-1, 32, 48, 48]               0\n",
            "          Conv2d-145           [-1, 64, 48, 48]         110,656\n",
            "        Identity-146           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-147           [-1, 64, 48, 48]               0\n",
            "             RDB-148           [-1, 64, 48, 48]               0\n",
            "            RRDB-149           [-1, 64, 48, 48]               0\n",
            "          Conv2d-150           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-151           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-152           [-1, 32, 48, 48]               0\n",
            "          Conv2d-153           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-154           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-155           [-1, 32, 48, 48]               0\n",
            "          Conv2d-156           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-157           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-158           [-1, 32, 48, 48]               0\n",
            "          Conv2d-159           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-160           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-161           [-1, 32, 48, 48]               0\n",
            "          Conv2d-162           [-1, 64, 48, 48]         110,656\n",
            "        Identity-163           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-164           [-1, 64, 48, 48]               0\n",
            "             RDB-165           [-1, 64, 48, 48]               0\n",
            "          Conv2d-166           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-167           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-168           [-1, 32, 48, 48]               0\n",
            "          Conv2d-169           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-170           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-171           [-1, 32, 48, 48]               0\n",
            "          Conv2d-172           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-173           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-174           [-1, 32, 48, 48]               0\n",
            "          Conv2d-175           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-176           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-177           [-1, 32, 48, 48]               0\n",
            "          Conv2d-178           [-1, 64, 48, 48]         110,656\n",
            "        Identity-179           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-180           [-1, 64, 48, 48]               0\n",
            "             RDB-181           [-1, 64, 48, 48]               0\n",
            "          Conv2d-182           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-183           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-184           [-1, 32, 48, 48]               0\n",
            "          Conv2d-185           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-186           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-187           [-1, 32, 48, 48]               0\n",
            "          Conv2d-188           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-189           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-190           [-1, 32, 48, 48]               0\n",
            "          Conv2d-191           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-192           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-193           [-1, 32, 48, 48]               0\n",
            "          Conv2d-194           [-1, 64, 48, 48]         110,656\n",
            "        Identity-195           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-196           [-1, 64, 48, 48]               0\n",
            "             RDB-197           [-1, 64, 48, 48]               0\n",
            "            RRDB-198           [-1, 64, 48, 48]               0\n",
            "          Conv2d-199           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-200           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-201           [-1, 32, 48, 48]               0\n",
            "          Conv2d-202           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-203           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-204           [-1, 32, 48, 48]               0\n",
            "          Conv2d-205           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-206           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-207           [-1, 32, 48, 48]               0\n",
            "          Conv2d-208           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-209           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-210           [-1, 32, 48, 48]               0\n",
            "          Conv2d-211           [-1, 64, 48, 48]         110,656\n",
            "        Identity-212           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-213           [-1, 64, 48, 48]               0\n",
            "             RDB-214           [-1, 64, 48, 48]               0\n",
            "          Conv2d-215           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-216           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-217           [-1, 32, 48, 48]               0\n",
            "          Conv2d-218           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-219           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-220           [-1, 32, 48, 48]               0\n",
            "          Conv2d-221           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-222           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-223           [-1, 32, 48, 48]               0\n",
            "          Conv2d-224           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-225           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-226           [-1, 32, 48, 48]               0\n",
            "          Conv2d-227           [-1, 64, 48, 48]         110,656\n",
            "        Identity-228           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-229           [-1, 64, 48, 48]               0\n",
            "             RDB-230           [-1, 64, 48, 48]               0\n",
            "          Conv2d-231           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-232           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-233           [-1, 32, 48, 48]               0\n",
            "          Conv2d-234           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-235           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-236           [-1, 32, 48, 48]               0\n",
            "          Conv2d-237           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-238           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-239           [-1, 32, 48, 48]               0\n",
            "          Conv2d-240           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-241           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-242           [-1, 32, 48, 48]               0\n",
            "          Conv2d-243           [-1, 64, 48, 48]         110,656\n",
            "        Identity-244           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-245           [-1, 64, 48, 48]               0\n",
            "             RDB-246           [-1, 64, 48, 48]               0\n",
            "            RRDB-247           [-1, 64, 48, 48]               0\n",
            "          Conv2d-248           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-249           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-250           [-1, 32, 48, 48]               0\n",
            "          Conv2d-251           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-252           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-253           [-1, 32, 48, 48]               0\n",
            "          Conv2d-254           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-255           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-256           [-1, 32, 48, 48]               0\n",
            "          Conv2d-257           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-258           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-259           [-1, 32, 48, 48]               0\n",
            "          Conv2d-260           [-1, 64, 48, 48]         110,656\n",
            "        Identity-261           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-262           [-1, 64, 48, 48]               0\n",
            "             RDB-263           [-1, 64, 48, 48]               0\n",
            "          Conv2d-264           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-265           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-266           [-1, 32, 48, 48]               0\n",
            "          Conv2d-267           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-268           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-269           [-1, 32, 48, 48]               0\n",
            "          Conv2d-270           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-271           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-272           [-1, 32, 48, 48]               0\n",
            "          Conv2d-273           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-274           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-275           [-1, 32, 48, 48]               0\n",
            "          Conv2d-276           [-1, 64, 48, 48]         110,656\n",
            "        Identity-277           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-278           [-1, 64, 48, 48]               0\n",
            "             RDB-279           [-1, 64, 48, 48]               0\n",
            "          Conv2d-280           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-281           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-282           [-1, 32, 48, 48]               0\n",
            "          Conv2d-283           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-284           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-285           [-1, 32, 48, 48]               0\n",
            "          Conv2d-286           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-287           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-288           [-1, 32, 48, 48]               0\n",
            "          Conv2d-289           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-290           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-291           [-1, 32, 48, 48]               0\n",
            "          Conv2d-292           [-1, 64, 48, 48]         110,656\n",
            "        Identity-293           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-294           [-1, 64, 48, 48]               0\n",
            "             RDB-295           [-1, 64, 48, 48]               0\n",
            "            RRDB-296           [-1, 64, 48, 48]               0\n",
            "          Conv2d-297           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-298           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-299           [-1, 32, 48, 48]               0\n",
            "          Conv2d-300           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-301           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-302           [-1, 32, 48, 48]               0\n",
            "          Conv2d-303           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-304           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-305           [-1, 32, 48, 48]               0\n",
            "          Conv2d-306           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-307           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-308           [-1, 32, 48, 48]               0\n",
            "          Conv2d-309           [-1, 64, 48, 48]         110,656\n",
            "        Identity-310           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-311           [-1, 64, 48, 48]               0\n",
            "             RDB-312           [-1, 64, 48, 48]               0\n",
            "          Conv2d-313           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-314           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-315           [-1, 32, 48, 48]               0\n",
            "          Conv2d-316           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-317           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-318           [-1, 32, 48, 48]               0\n",
            "          Conv2d-319           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-320           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-321           [-1, 32, 48, 48]               0\n",
            "          Conv2d-322           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-323           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-324           [-1, 32, 48, 48]               0\n",
            "          Conv2d-325           [-1, 64, 48, 48]         110,656\n",
            "        Identity-326           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-327           [-1, 64, 48, 48]               0\n",
            "             RDB-328           [-1, 64, 48, 48]               0\n",
            "          Conv2d-329           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-330           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-331           [-1, 32, 48, 48]               0\n",
            "          Conv2d-332           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-333           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-334           [-1, 32, 48, 48]               0\n",
            "          Conv2d-335           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-336           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-337           [-1, 32, 48, 48]               0\n",
            "          Conv2d-338           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-339           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-340           [-1, 32, 48, 48]               0\n",
            "          Conv2d-341           [-1, 64, 48, 48]         110,656\n",
            "        Identity-342           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-343           [-1, 64, 48, 48]               0\n",
            "             RDB-344           [-1, 64, 48, 48]               0\n",
            "            RRDB-345           [-1, 64, 48, 48]               0\n",
            "          Conv2d-346           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-347           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-348           [-1, 32, 48, 48]               0\n",
            "          Conv2d-349           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-350           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-351           [-1, 32, 48, 48]               0\n",
            "          Conv2d-352           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-353           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-354           [-1, 32, 48, 48]               0\n",
            "          Conv2d-355           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-356           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-357           [-1, 32, 48, 48]               0\n",
            "          Conv2d-358           [-1, 64, 48, 48]         110,656\n",
            "        Identity-359           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-360           [-1, 64, 48, 48]               0\n",
            "             RDB-361           [-1, 64, 48, 48]               0\n",
            "          Conv2d-362           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-363           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-364           [-1, 32, 48, 48]               0\n",
            "          Conv2d-365           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-366           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-367           [-1, 32, 48, 48]               0\n",
            "          Conv2d-368           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-369           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-370           [-1, 32, 48, 48]               0\n",
            "          Conv2d-371           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-372           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-373           [-1, 32, 48, 48]               0\n",
            "          Conv2d-374           [-1, 64, 48, 48]         110,656\n",
            "        Identity-375           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-376           [-1, 64, 48, 48]               0\n",
            "             RDB-377           [-1, 64, 48, 48]               0\n",
            "          Conv2d-378           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-379           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-380           [-1, 32, 48, 48]               0\n",
            "          Conv2d-381           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-382           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-383           [-1, 32, 48, 48]               0\n",
            "          Conv2d-384           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-385           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-386           [-1, 32, 48, 48]               0\n",
            "          Conv2d-387           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-388           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-389           [-1, 32, 48, 48]               0\n",
            "          Conv2d-390           [-1, 64, 48, 48]         110,656\n",
            "        Identity-391           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-392           [-1, 64, 48, 48]               0\n",
            "             RDB-393           [-1, 64, 48, 48]               0\n",
            "            RRDB-394           [-1, 64, 48, 48]               0\n",
            "          Conv2d-395           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-396           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-397           [-1, 32, 48, 48]               0\n",
            "          Conv2d-398           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-399           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-400           [-1, 32, 48, 48]               0\n",
            "          Conv2d-401           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-402           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-403           [-1, 32, 48, 48]               0\n",
            "          Conv2d-404           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-405           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-406           [-1, 32, 48, 48]               0\n",
            "          Conv2d-407           [-1, 64, 48, 48]         110,656\n",
            "        Identity-408           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-409           [-1, 64, 48, 48]               0\n",
            "             RDB-410           [-1, 64, 48, 48]               0\n",
            "          Conv2d-411           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-412           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-413           [-1, 32, 48, 48]               0\n",
            "          Conv2d-414           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-415           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-416           [-1, 32, 48, 48]               0\n",
            "          Conv2d-417           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-418           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-419           [-1, 32, 48, 48]               0\n",
            "          Conv2d-420           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-421           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-422           [-1, 32, 48, 48]               0\n",
            "          Conv2d-423           [-1, 64, 48, 48]         110,656\n",
            "        Identity-424           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-425           [-1, 64, 48, 48]               0\n",
            "             RDB-426           [-1, 64, 48, 48]               0\n",
            "          Conv2d-427           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-428           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-429           [-1, 32, 48, 48]               0\n",
            "          Conv2d-430           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-431           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-432           [-1, 32, 48, 48]               0\n",
            "          Conv2d-433           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-434           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-435           [-1, 32, 48, 48]               0\n",
            "          Conv2d-436           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-437           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-438           [-1, 32, 48, 48]               0\n",
            "          Conv2d-439           [-1, 64, 48, 48]         110,656\n",
            "        Identity-440           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-441           [-1, 64, 48, 48]               0\n",
            "             RDB-442           [-1, 64, 48, 48]               0\n",
            "            RRDB-443           [-1, 64, 48, 48]               0\n",
            "          Conv2d-444           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-445           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-446           [-1, 32, 48, 48]               0\n",
            "          Conv2d-447           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-448           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-449           [-1, 32, 48, 48]               0\n",
            "          Conv2d-450           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-451           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-452           [-1, 32, 48, 48]               0\n",
            "          Conv2d-453           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-454           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-455           [-1, 32, 48, 48]               0\n",
            "          Conv2d-456           [-1, 64, 48, 48]         110,656\n",
            "        Identity-457           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-458           [-1, 64, 48, 48]               0\n",
            "             RDB-459           [-1, 64, 48, 48]               0\n",
            "          Conv2d-460           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-461           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-462           [-1, 32, 48, 48]               0\n",
            "          Conv2d-463           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-464           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-465           [-1, 32, 48, 48]               0\n",
            "          Conv2d-466           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-467           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-468           [-1, 32, 48, 48]               0\n",
            "          Conv2d-469           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-470           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-471           [-1, 32, 48, 48]               0\n",
            "          Conv2d-472           [-1, 64, 48, 48]         110,656\n",
            "        Identity-473           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-474           [-1, 64, 48, 48]               0\n",
            "             RDB-475           [-1, 64, 48, 48]               0\n",
            "          Conv2d-476           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-477           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-478           [-1, 32, 48, 48]               0\n",
            "          Conv2d-479           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-480           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-481           [-1, 32, 48, 48]               0\n",
            "          Conv2d-482           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-483           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-484           [-1, 32, 48, 48]               0\n",
            "          Conv2d-485           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-486           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-487           [-1, 32, 48, 48]               0\n",
            "          Conv2d-488           [-1, 64, 48, 48]         110,656\n",
            "        Identity-489           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-490           [-1, 64, 48, 48]               0\n",
            "             RDB-491           [-1, 64, 48, 48]               0\n",
            "            RRDB-492           [-1, 64, 48, 48]               0\n",
            "          Conv2d-493           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-494           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-495           [-1, 32, 48, 48]               0\n",
            "          Conv2d-496           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-497           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-498           [-1, 32, 48, 48]               0\n",
            "          Conv2d-499           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-500           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-501           [-1, 32, 48, 48]               0\n",
            "          Conv2d-502           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-503           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-504           [-1, 32, 48, 48]               0\n",
            "          Conv2d-505           [-1, 64, 48, 48]         110,656\n",
            "        Identity-506           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-507           [-1, 64, 48, 48]               0\n",
            "             RDB-508           [-1, 64, 48, 48]               0\n",
            "          Conv2d-509           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-510           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-511           [-1, 32, 48, 48]               0\n",
            "          Conv2d-512           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-513           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-514           [-1, 32, 48, 48]               0\n",
            "          Conv2d-515           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-516           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-517           [-1, 32, 48, 48]               0\n",
            "          Conv2d-518           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-519           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-520           [-1, 32, 48, 48]               0\n",
            "          Conv2d-521           [-1, 64, 48, 48]         110,656\n",
            "        Identity-522           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-523           [-1, 64, 48, 48]               0\n",
            "             RDB-524           [-1, 64, 48, 48]               0\n",
            "          Conv2d-525           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-526           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-527           [-1, 32, 48, 48]               0\n",
            "          Conv2d-528           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-529           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-530           [-1, 32, 48, 48]               0\n",
            "          Conv2d-531           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-532           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-533           [-1, 32, 48, 48]               0\n",
            "          Conv2d-534           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-535           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-536           [-1, 32, 48, 48]               0\n",
            "          Conv2d-537           [-1, 64, 48, 48]         110,656\n",
            "        Identity-538           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-539           [-1, 64, 48, 48]               0\n",
            "             RDB-540           [-1, 64, 48, 48]               0\n",
            "            RRDB-541           [-1, 64, 48, 48]               0\n",
            "          Conv2d-542           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-543           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-544           [-1, 32, 48, 48]               0\n",
            "          Conv2d-545           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-546           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-547           [-1, 32, 48, 48]               0\n",
            "          Conv2d-548           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-549           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-550           [-1, 32, 48, 48]               0\n",
            "          Conv2d-551           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-552           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-553           [-1, 32, 48, 48]               0\n",
            "          Conv2d-554           [-1, 64, 48, 48]         110,656\n",
            "        Identity-555           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-556           [-1, 64, 48, 48]               0\n",
            "             RDB-557           [-1, 64, 48, 48]               0\n",
            "          Conv2d-558           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-559           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-560           [-1, 32, 48, 48]               0\n",
            "          Conv2d-561           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-562           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-563           [-1, 32, 48, 48]               0\n",
            "          Conv2d-564           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-565           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-566           [-1, 32, 48, 48]               0\n",
            "          Conv2d-567           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-568           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-569           [-1, 32, 48, 48]               0\n",
            "          Conv2d-570           [-1, 64, 48, 48]         110,656\n",
            "        Identity-571           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-572           [-1, 64, 48, 48]               0\n",
            "             RDB-573           [-1, 64, 48, 48]               0\n",
            "          Conv2d-574           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-575           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-576           [-1, 32, 48, 48]               0\n",
            "          Conv2d-577           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-578           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-579           [-1, 32, 48, 48]               0\n",
            "          Conv2d-580           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-581           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-582           [-1, 32, 48, 48]               0\n",
            "          Conv2d-583           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-584           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-585           [-1, 32, 48, 48]               0\n",
            "          Conv2d-586           [-1, 64, 48, 48]         110,656\n",
            "        Identity-587           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-588           [-1, 64, 48, 48]               0\n",
            "             RDB-589           [-1, 64, 48, 48]               0\n",
            "            RRDB-590           [-1, 64, 48, 48]               0\n",
            "          Conv2d-591           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-592           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-593           [-1, 32, 48, 48]               0\n",
            "          Conv2d-594           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-595           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-596           [-1, 32, 48, 48]               0\n",
            "          Conv2d-597           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-598           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-599           [-1, 32, 48, 48]               0\n",
            "          Conv2d-600           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-601           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-602           [-1, 32, 48, 48]               0\n",
            "          Conv2d-603           [-1, 64, 48, 48]         110,656\n",
            "        Identity-604           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-605           [-1, 64, 48, 48]               0\n",
            "             RDB-606           [-1, 64, 48, 48]               0\n",
            "          Conv2d-607           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-608           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-609           [-1, 32, 48, 48]               0\n",
            "          Conv2d-610           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-611           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-612           [-1, 32, 48, 48]               0\n",
            "          Conv2d-613           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-614           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-615           [-1, 32, 48, 48]               0\n",
            "          Conv2d-616           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-617           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-618           [-1, 32, 48, 48]               0\n",
            "          Conv2d-619           [-1, 64, 48, 48]         110,656\n",
            "        Identity-620           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-621           [-1, 64, 48, 48]               0\n",
            "             RDB-622           [-1, 64, 48, 48]               0\n",
            "          Conv2d-623           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-624           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-625           [-1, 32, 48, 48]               0\n",
            "          Conv2d-626           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-627           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-628           [-1, 32, 48, 48]               0\n",
            "          Conv2d-629           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-630           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-631           [-1, 32, 48, 48]               0\n",
            "          Conv2d-632           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-633           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-634           [-1, 32, 48, 48]               0\n",
            "          Conv2d-635           [-1, 64, 48, 48]         110,656\n",
            "        Identity-636           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-637           [-1, 64, 48, 48]               0\n",
            "             RDB-638           [-1, 64, 48, 48]               0\n",
            "            RRDB-639           [-1, 64, 48, 48]               0\n",
            "          Conv2d-640           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-641           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-642           [-1, 32, 48, 48]               0\n",
            "          Conv2d-643           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-644           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-645           [-1, 32, 48, 48]               0\n",
            "          Conv2d-646           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-647           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-648           [-1, 32, 48, 48]               0\n",
            "          Conv2d-649           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-650           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-651           [-1, 32, 48, 48]               0\n",
            "          Conv2d-652           [-1, 64, 48, 48]         110,656\n",
            "        Identity-653           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-654           [-1, 64, 48, 48]               0\n",
            "             RDB-655           [-1, 64, 48, 48]               0\n",
            "          Conv2d-656           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-657           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-658           [-1, 32, 48, 48]               0\n",
            "          Conv2d-659           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-660           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-661           [-1, 32, 48, 48]               0\n",
            "          Conv2d-662           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-663           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-664           [-1, 32, 48, 48]               0\n",
            "          Conv2d-665           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-666           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-667           [-1, 32, 48, 48]               0\n",
            "          Conv2d-668           [-1, 64, 48, 48]         110,656\n",
            "        Identity-669           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-670           [-1, 64, 48, 48]               0\n",
            "             RDB-671           [-1, 64, 48, 48]               0\n",
            "          Conv2d-672           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-673           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-674           [-1, 32, 48, 48]               0\n",
            "          Conv2d-675           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-676           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-677           [-1, 32, 48, 48]               0\n",
            "          Conv2d-678           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-679           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-680           [-1, 32, 48, 48]               0\n",
            "          Conv2d-681           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-682           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-683           [-1, 32, 48, 48]               0\n",
            "          Conv2d-684           [-1, 64, 48, 48]         110,656\n",
            "        Identity-685           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-686           [-1, 64, 48, 48]               0\n",
            "             RDB-687           [-1, 64, 48, 48]               0\n",
            "            RRDB-688           [-1, 64, 48, 48]               0\n",
            "          Conv2d-689           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-690           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-691           [-1, 32, 48, 48]               0\n",
            "          Conv2d-692           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-693           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-694           [-1, 32, 48, 48]               0\n",
            "          Conv2d-695           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-696           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-697           [-1, 32, 48, 48]               0\n",
            "          Conv2d-698           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-699           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-700           [-1, 32, 48, 48]               0\n",
            "          Conv2d-701           [-1, 64, 48, 48]         110,656\n",
            "        Identity-702           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-703           [-1, 64, 48, 48]               0\n",
            "             RDB-704           [-1, 64, 48, 48]               0\n",
            "          Conv2d-705           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-706           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-707           [-1, 32, 48, 48]               0\n",
            "          Conv2d-708           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-709           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-710           [-1, 32, 48, 48]               0\n",
            "          Conv2d-711           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-712           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-713           [-1, 32, 48, 48]               0\n",
            "          Conv2d-714           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-715           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-716           [-1, 32, 48, 48]               0\n",
            "          Conv2d-717           [-1, 64, 48, 48]         110,656\n",
            "        Identity-718           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-719           [-1, 64, 48, 48]               0\n",
            "             RDB-720           [-1, 64, 48, 48]               0\n",
            "          Conv2d-721           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-722           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-723           [-1, 32, 48, 48]               0\n",
            "          Conv2d-724           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-725           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-726           [-1, 32, 48, 48]               0\n",
            "          Conv2d-727           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-728           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-729           [-1, 32, 48, 48]               0\n",
            "          Conv2d-730           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-731           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-732           [-1, 32, 48, 48]               0\n",
            "          Conv2d-733           [-1, 64, 48, 48]         110,656\n",
            "        Identity-734           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-735           [-1, 64, 48, 48]               0\n",
            "             RDB-736           [-1, 64, 48, 48]               0\n",
            "            RRDB-737           [-1, 64, 48, 48]               0\n",
            "          Conv2d-738           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-739           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-740           [-1, 32, 48, 48]               0\n",
            "          Conv2d-741           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-742           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-743           [-1, 32, 48, 48]               0\n",
            "          Conv2d-744           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-745           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-746           [-1, 32, 48, 48]               0\n",
            "          Conv2d-747           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-748           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-749           [-1, 32, 48, 48]               0\n",
            "          Conv2d-750           [-1, 64, 48, 48]         110,656\n",
            "        Identity-751           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-752           [-1, 64, 48, 48]               0\n",
            "             RDB-753           [-1, 64, 48, 48]               0\n",
            "          Conv2d-754           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-755           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-756           [-1, 32, 48, 48]               0\n",
            "          Conv2d-757           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-758           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-759           [-1, 32, 48, 48]               0\n",
            "          Conv2d-760           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-761           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-762           [-1, 32, 48, 48]               0\n",
            "          Conv2d-763           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-764           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-765           [-1, 32, 48, 48]               0\n",
            "          Conv2d-766           [-1, 64, 48, 48]         110,656\n",
            "        Identity-767           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-768           [-1, 64, 48, 48]               0\n",
            "             RDB-769           [-1, 64, 48, 48]               0\n",
            "          Conv2d-770           [-1, 32, 48, 48]          18,464\n",
            "       LeakyReLU-771           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-772           [-1, 32, 48, 48]               0\n",
            "          Conv2d-773           [-1, 32, 48, 48]          27,680\n",
            "       LeakyReLU-774           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-775           [-1, 32, 48, 48]               0\n",
            "          Conv2d-776           [-1, 32, 48, 48]          36,896\n",
            "       LeakyReLU-777           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-778           [-1, 32, 48, 48]               0\n",
            "          Conv2d-779           [-1, 32, 48, 48]          46,112\n",
            "       LeakyReLU-780           [-1, 32, 48, 48]               0\n",
            "       ConvBlock-781           [-1, 32, 48, 48]               0\n",
            "          Conv2d-782           [-1, 64, 48, 48]         110,656\n",
            "        Identity-783           [-1, 64, 48, 48]               0\n",
            "       ConvBlock-784           [-1, 64, 48, 48]               0\n",
            "             RDB-785           [-1, 64, 48, 48]               0\n",
            "            RRDB-786           [-1, 64, 48, 48]               0\n",
            "          Conv2d-787           [-1, 64, 48, 48]           1,792\n",
            "            Head-788           [-1, 64, 48, 48]               0\n",
            "          Conv2d-789           [-1, 64, 48, 48]          36,928\n",
            "          Conv2d-790          [-1, 256, 48, 48]         147,712\n",
            "        Upsample-791        [-1, 256, 144, 144]               0\n",
            "       LeakyReLU-792        [-1, 256, 144, 144]               0\n",
            "          Conv2d-793          [-1, 3, 144, 144]           6,915\n",
            "            Tail-794          [-1, 3, 144, 144]               0\n",
            "================================================================\n",
            "Total params: 11,705,923\n",
            "Trainable params: 11,705,923\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.03\n",
            "Forward/backward pass size (MB): 650.07\n",
            "Params size (MB): 44.65\n",
            "Estimated Total Size (MB): 694.76\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "gene = Generator()\n",
        "student = Student()\n",
        "teacher = Student()\n",
        "student.nb_of_bodies = 16\n",
        "summary(student, (3,48,48), device='cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HEIdx2SOm7f"
      },
      "outputs": [],
      "source": [
        "#teacher.requires_grad_(False)\n",
        "#gene.requires_grad_(False)\n",
        "input = torch.rand((1,480,480))\n",
        "out = gene(input)\n",
        "#display(torchvision.transforms.ToPILImage()(out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJxNOu7DaUdl",
        "outputId": "6ec49f01-ce24-4089-d268-fa36166d6382"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.1146, grad_fn=<MeanBackward0>)"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "student.train(out.detach(), teacher(out).detach())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOHxkyU98bsB"
      },
      "outputs": [],
      "source": [
        "class Knowledge_Distillation:\n",
        "  def __init__(self, student: nn.Module, teacher: nn.Module, generator: nn.Module, iterations: int = 120, imitation_steps: int = 50, height: int = 500, width: int = 500, batch_size: int = 2):\n",
        "    # Different bodies for the progressive training\n",
        "    self.student = student\n",
        "    self.teacher = teacher\n",
        "    self.generator = generator\n",
        "    self.cur_epoch = 0\n",
        "    self.imitation_steps = imitation_steps\n",
        "    self.batch_size = batch_size\n",
        "    self.height = height\n",
        "    self.width = width\n",
        "    self.iterations = iterations\n",
        "    \n",
        "    self.teacher.requires_grad_(False)\n",
        "\n",
        "    # The various S_i are as follows S_tail(Body_i...Body_0(S_head))\n",
        "  \n",
        "  def train(self, epochs: int):\n",
        "\n",
        "    for self.cur_epoch in range(epochs):\n",
        "      print(f'\\n*********Epoch {self.cur_epoch}/{epochs}*********\\n')\n",
        "      \n",
        "      for iteration in range(self.iterations):\n",
        "        print(f'Iteration {iteration}/{self.iterations}')\n",
        "\n",
        "        # Student training\n",
        "\n",
        "        self.generator.requires_grad_(False)\n",
        "\n",
        "        for k in range(self.imitation_steps):\n",
        "          print(f'Imitation step {k}/{self.imitation_steps}')\n",
        "\n",
        "          noise_images = torch.rand((self.batch_size, 1, self.height, self.width))\n",
        "          generated_images = self.generator(noise_images)\n",
        "          teacher_output = self.teacher(generated_images)\n",
        "          loss = self.student.train(generated_images, teacher_output)\n",
        "          print(loss.item())\n",
        "\n",
        "        self.student.scheduler.step()\n",
        "        self.generator.requires_grad_()\n",
        "        \n",
        "        # Generator training\n",
        "\n",
        "        print('\\nGenerator training')\n",
        "        self.student.requires_grad_(False)\n",
        "\n",
        "        noise_images = torch.rand((self.batch_size, 1, self.height, self.width))\n",
        "        generated_images = self.generator(noise_images)\n",
        "        teacher_output = self.teacher(generated_images)\n",
        "        student_output = self.student(generated_images)\n",
        "\n",
        "        loss = self.generator.train(generated_images, teacher_output, student_output)\n",
        "        print(loss.item())\n",
        "        \n",
        "        self.generator.scheduler.step()\n",
        "        self.student.requires_grad_()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "psflCLZ1F5jm",
        "outputId": "c9e66617-0036-4366-bc05-95d6174b9bf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Imitation step 49/50\n",
            "0.003474239259958267\n",
            "Generator training\n",
            "0.11734476685523987\n",
            "Iteration 25/120\n",
            "Imitation step 0/50\n",
            "0.003500130493193865\n",
            "Imitation step 1/50\n",
            "0.0035392974968999624\n",
            "Imitation step 2/50\n",
            "0.003648364683613181\n",
            "Imitation step 3/50\n",
            "0.0038301863241940737\n",
            "Imitation step 4/50\n",
            "0.004091516602784395\n",
            "Imitation step 5/50\n",
            "0.004283817484974861\n",
            "Imitation step 6/50\n",
            "0.004409704357385635\n",
            "Imitation step 7/50\n",
            "0.004378161393105984\n",
            "Imitation step 8/50\n",
            "0.004375381860882044\n",
            "Imitation step 9/50\n",
            "0.0042854174971580505\n",
            "Imitation step 10/50\n",
            "0.004244538489729166\n",
            "Imitation step 11/50\n",
            "0.004154119174927473\n",
            "Imitation step 12/50\n",
            "0.004132249392569065\n",
            "Imitation step 13/50\n",
            "0.004068807233124971\n",
            "Imitation step 14/50\n",
            "0.0040396819822490215\n",
            "Imitation step 15/50\n",
            "0.003986785188317299\n",
            "Imitation step 16/50\n",
            "0.003961618524044752\n",
            "Imitation step 17/50\n",
            "0.0038912200834602118\n",
            "Imitation step 18/50\n",
            "0.0038797773886471987\n",
            "Imitation step 19/50\n",
            "0.003833209630101919\n",
            "Imitation step 20/50\n",
            "0.0038047037087380886\n",
            "Imitation step 21/50\n",
            "0.0037726331502199173\n",
            "Imitation step 22/50\n",
            "0.0037651334423571825\n",
            "Imitation step 23/50\n",
            "0.00372123159468174\n",
            "Imitation step 24/50\n",
            "0.003719692351296544\n",
            "Imitation step 25/50\n",
            "0.0036845095455646515\n",
            "Imitation step 26/50\n",
            "0.003697439096868038\n",
            "Imitation step 27/50\n",
            "0.0036648137029260397\n",
            "Imitation step 28/50\n",
            "0.0036861912813037634\n",
            "Imitation step 29/50\n",
            "0.00373458256945014\n",
            "Imitation step 30/50\n",
            "0.0038545173592865467\n",
            "Imitation step 31/50\n",
            "0.004006186034530401\n",
            "Imitation step 32/50\n",
            "0.004195353481918573\n",
            "Imitation step 33/50\n",
            "0.004252255894243717\n",
            "Imitation step 34/50\n",
            "0.004294876009225845\n",
            "Imitation step 35/50\n",
            "0.004223756026476622\n",
            "Imitation step 36/50\n",
            "0.0042097968980669975\n",
            "Imitation step 37/50\n",
            "0.00414819223806262\n",
            "Imitation step 38/50\n",
            "0.004120551981031895\n",
            "Imitation step 39/50\n",
            "0.004041354637593031\n",
            "Imitation step 40/50\n",
            "0.0040236529894173145\n",
            "Imitation step 41/50\n",
            "0.003977407701313496\n",
            "Imitation step 42/50\n",
            "0.00396126601845026\n",
            "Imitation step 43/50\n",
            "0.003918097820132971\n",
            "Imitation step 44/50\n",
            "0.003893880173563957\n",
            "Imitation step 45/50\n",
            "0.003832320449873805\n",
            "Imitation step 46/50\n",
            "0.003819223726168275\n",
            "Imitation step 47/50\n",
            "0.003790995804592967\n",
            "Imitation step 48/50\n",
            "0.003787142690271139\n",
            "Imitation step 49/50\n",
            "0.0037322952412068844\n",
            "Generator training\n",
            "0.11702719330787659\n",
            "Iteration 26/120\n",
            "Imitation step 0/50\n",
            "0.0037186655681580305\n",
            "Imitation step 1/50\n",
            "0.0036829663440585136\n",
            "Imitation step 2/50\n",
            "0.0036704118829220533\n",
            "Imitation step 3/50\n",
            "0.0036501772701740265\n",
            "Imitation step 4/50\n",
            "0.0036297766491770744\n",
            "Imitation step 5/50\n",
            "0.0036131194792687893\n",
            "Imitation step 6/50\n",
            "0.0036117234267294407\n",
            "Imitation step 7/50\n",
            "0.003592214547097683\n",
            "Imitation step 8/50\n",
            "0.0036012702621519566\n",
            "Imitation step 9/50\n",
            "0.0035974967759102583\n",
            "Imitation step 10/50\n",
            "0.0036257209721952677\n",
            "Imitation step 11/50\n",
            "0.003667172510176897\n",
            "Imitation step 12/50\n",
            "0.0037714424543082714\n",
            "Imitation step 13/50\n",
            "0.0038969116285443306\n",
            "Imitation step 14/50\n",
            "0.00402455497533083\n",
            "Imitation step 15/50\n",
            "0.004135346505790949\n",
            "Imitation step 16/50\n",
            "0.004158508498221636\n",
            "Imitation step 17/50\n",
            "0.004165877588093281\n",
            "Imitation step 18/50\n",
            "0.004122828133404255\n",
            "Imitation step 19/50\n",
            "0.004089714959263802\n",
            "Imitation step 20/50\n",
            "0.004035523626953363\n",
            "Imitation step 21/50\n",
            "0.004009221214801073\n",
            "Imitation step 22/50\n",
            "0.003951382357627153\n",
            "Imitation step 23/50\n",
            "0.003914637491106987\n",
            "Imitation step 24/50\n",
            "0.003855549730360508\n",
            "Imitation step 25/50\n",
            "0.003847840940579772\n",
            "Imitation step 26/50\n",
            "0.00379496393725276\n",
            "Imitation step 27/50\n",
            "0.0037819407880306244\n",
            "Imitation step 28/50\n",
            "0.0037442264147102833\n",
            "Imitation step 29/50\n",
            "0.0037301410920917988\n",
            "Imitation step 30/50\n",
            "0.0036911508068442345\n",
            "Imitation step 31/50\n",
            "0.0036620269529521465\n",
            "Imitation step 32/50\n",
            "0.0036492047365754843\n",
            "Imitation step 33/50\n",
            "0.003627119353041053\n",
            "Imitation step 34/50\n",
            "0.003598666051402688\n",
            "Imitation step 35/50\n",
            "0.0035894715692847967\n",
            "Imitation step 36/50\n",
            "0.003557009855285287\n",
            "Imitation step 37/50\n",
            "0.0035604664590209723\n",
            "Imitation step 38/50\n",
            "0.003534149145707488\n",
            "Imitation step 39/50\n",
            "0.003523024031892419\n",
            "Imitation step 40/50\n",
            "0.0035083468537777662\n",
            "Imitation step 41/50\n",
            "0.0035023537930101156\n",
            "Imitation step 42/50\n",
            "0.0034962983336299658\n",
            "Imitation step 43/50\n",
            "0.0034815077669918537\n",
            "Imitation step 44/50\n",
            "0.0034680787939578295\n",
            "Imitation step 45/50\n",
            "0.0034742786083370447\n",
            "Imitation step 46/50\n",
            "0.003468247363343835\n",
            "Imitation step 47/50\n",
            "0.0034644261468201876\n",
            "Imitation step 48/50\n",
            "0.003448804374784231\n",
            "Imitation step 49/50\n",
            "0.003456489183008671\n",
            "Generator training\n",
            "0.11723779141902924\n",
            "Iteration 27/120\n",
            "Imitation step 0/50\n",
            "0.003447632770985365\n",
            "Imitation step 1/50\n",
            "0.0034375223331153393\n",
            "Imitation step 2/50\n",
            "0.0034249082673341036\n",
            "Imitation step 3/50\n",
            "0.003427168820053339\n",
            "Imitation step 4/50\n",
            "0.0034086594823747873\n",
            "Imitation step 5/50\n",
            "0.0034049355890601873\n",
            "Imitation step 6/50\n",
            "0.003396259620785713\n",
            "Imitation step 7/50\n",
            "0.0033883105497807264\n",
            "Imitation step 8/50\n",
            "0.0033829379826784134\n",
            "Imitation step 9/50\n",
            "0.003378841793164611\n",
            "Imitation step 10/50\n",
            "0.003371214959770441\n",
            "Imitation step 11/50\n",
            "0.003369956510141492\n",
            "Imitation step 12/50\n",
            "0.003358343616127968\n",
            "Imitation step 13/50\n",
            "0.00335711264051497\n",
            "Imitation step 14/50\n",
            "0.003356329398229718\n",
            "Imitation step 15/50\n",
            "0.0033571445383131504\n",
            "Imitation step 16/50\n",
            "0.0033594288397580385\n",
            "Imitation step 17/50\n",
            "0.0033650107216089964\n",
            "Imitation step 18/50\n",
            "0.0034065693616867065\n",
            "Imitation step 19/50\n",
            "0.0034736597444862127\n",
            "Imitation step 20/50\n",
            "0.003636647015810013\n",
            "Imitation step 21/50\n",
            "0.0038793240673840046\n",
            "Imitation step 22/50\n",
            "0.004184275399893522\n",
            "Imitation step 23/50\n",
            "0.004335151985287666\n",
            "Imitation step 24/50\n",
            "0.0044204359874129295\n",
            "Imitation step 25/50\n",
            "0.00432564178481698\n",
            "Imitation step 26/50\n",
            "0.004315159749239683\n",
            "Imitation step 27/50\n",
            "0.004195354413241148\n",
            "Imitation step 28/50\n",
            "0.0041848341934382915\n",
            "Imitation step 29/50\n",
            "0.004091015085577965\n",
            "Imitation step 30/50\n",
            "0.004075444769114256\n",
            "Imitation step 31/50\n",
            "0.003998469561338425\n",
            "Imitation step 32/50\n",
            "0.003971758298575878\n",
            "Imitation step 33/50\n",
            "0.003907160367816687\n",
            "Imitation step 34/50\n",
            "0.00389437866397202\n",
            "Imitation step 35/50\n",
            "0.003846836043521762\n",
            "Imitation step 36/50\n",
            "0.0038266112096607685\n",
            "Imitation step 37/50\n",
            "0.0037578062620013952\n",
            "Imitation step 38/50\n",
            "0.003735750215128064\n",
            "Imitation step 39/50\n",
            "0.0036912511568516493\n",
            "Imitation step 40/50\n",
            "0.0036683520302176476\n",
            "Imitation step 41/50\n",
            "0.003627031110227108\n",
            "Imitation step 42/50\n",
            "0.003646044759079814\n",
            "Imitation step 43/50\n",
            "0.003597549395635724\n",
            "Imitation step 44/50\n",
            "0.0036101825535297394\n",
            "Imitation step 45/50\n",
            "0.003624900011345744\n",
            "Imitation step 46/50\n",
            "0.0037180541548877954\n",
            "Imitation step 47/50\n",
            "0.003889586078003049\n",
            "Imitation step 48/50\n",
            "0.004177229478955269\n",
            "Imitation step 49/50\n",
            "0.0044061169028282166\n",
            "Generator training\n",
            "0.11613067984580994\n",
            "Iteration 28/120\n",
            "Imitation step 0/50\n",
            "0.004514873959124088\n",
            "Imitation step 1/50\n",
            "0.00443156948313117\n",
            "Imitation step 2/50\n",
            "0.004378252197057009\n",
            "Imitation step 3/50\n",
            "0.004286380019038916\n",
            "Imitation step 4/50\n",
            "0.004250729456543922\n",
            "Imitation step 5/50\n",
            "0.004186867270618677\n",
            "Imitation step 6/50\n",
            "0.004146778490394354\n",
            "Imitation step 7/50\n",
            "0.004083565436303616\n",
            "Imitation step 8/50\n",
            "0.004064377397298813\n",
            "Imitation step 9/50\n",
            "0.003995603881776333\n",
            "Imitation step 10/50\n",
            "0.003964569885283709\n",
            "Imitation step 11/50\n",
            "0.003901641583070159\n",
            "Imitation step 12/50\n",
            "0.0038756916765123606\n",
            "Imitation step 13/50\n",
            "0.0038214244414120913\n",
            "Imitation step 14/50\n",
            "0.0038068662397563457\n",
            "Imitation step 15/50\n",
            "0.00375805189833045\n",
            "Imitation step 16/50\n",
            "0.0037523868959397078\n",
            "Imitation step 17/50\n",
            "0.003725457703694701\n",
            "Imitation step 18/50\n",
            "0.0037169111892580986\n",
            "Imitation step 19/50\n",
            "0.003685328410938382\n",
            "Imitation step 20/50\n",
            "0.0036670893896371126\n",
            "Imitation step 21/50\n",
            "0.0036349426954984665\n",
            "Imitation step 22/50\n",
            "0.0036294416058808565\n",
            "Imitation step 23/50\n",
            "0.0035978571977466345\n",
            "Imitation step 24/50\n",
            "0.003591835033148527\n",
            "Imitation step 25/50\n",
            "0.003562818979844451\n",
            "Imitation step 26/50\n",
            "0.0035674849059432745\n",
            "Imitation step 27/50\n",
            "0.0035708891227841377\n",
            "Imitation step 28/50\n",
            "0.00357760745100677\n",
            "Imitation step 29/50\n",
            "0.003604591591283679\n",
            "Imitation step 30/50\n",
            "0.0036630788818001747\n",
            "Imitation step 31/50\n",
            "0.0037585922982543707\n",
            "Imitation step 32/50\n",
            "0.0038977554067969322\n",
            "Imitation step 33/50\n",
            "0.004043238703161478\n",
            "Imitation step 34/50\n",
            "0.0040947808884084225\n",
            "Imitation step 35/50\n",
            "0.004130554851144552\n",
            "Imitation step 36/50\n",
            "0.004073162563145161\n",
            "Imitation step 37/50\n",
            "0.004058869555592537\n",
            "Imitation step 38/50\n",
            "0.003987381234765053\n",
            "Imitation step 39/50\n",
            "0.003975928761065006\n",
            "Imitation step 40/50\n",
            "0.003919647540897131\n",
            "Imitation step 41/50\n",
            "0.003898434806615114\n",
            "Imitation step 42/50\n",
            "0.0038288843352347612\n",
            "Imitation step 43/50\n",
            "0.003812832524999976\n",
            "Imitation step 44/50\n",
            "0.003772235009819269\n",
            "Imitation step 45/50\n",
            "0.0037614027969539165\n",
            "Imitation step 46/50\n",
            "0.003714056685566902\n",
            "Imitation step 47/50\n",
            "0.0037037604488432407\n",
            "Imitation step 48/50\n",
            "0.003669826313853264\n",
            "Imitation step 49/50\n",
            "0.003651869250461459\n",
            "Generator training\n",
            "0.11700186133384705\n",
            "Iteration 29/120\n",
            "Imitation step 0/50\n",
            "0.0036152794491499662\n",
            "Imitation step 1/50\n",
            "0.0035965824499726295\n",
            "Imitation step 2/50\n",
            "0.0035741000901907682\n",
            "Imitation step 3/50\n",
            "0.0035723461769521236\n",
            "Imitation step 4/50\n",
            "0.0035509527660906315\n",
            "Imitation step 5/50\n",
            "0.0035404774826020002\n",
            "Imitation step 6/50\n",
            "0.003531472757458687\n",
            "Imitation step 7/50\n",
            "0.003522594226524234\n",
            "Imitation step 8/50\n",
            "0.003494874807074666\n",
            "Imitation step 9/50\n",
            "0.0034867774229496717\n",
            "Imitation step 10/50\n",
            "0.003478455124422908\n",
            "Imitation step 11/50\n",
            "0.003484291024506092\n",
            "Imitation step 12/50\n",
            "0.003453655866906047\n",
            "Imitation step 13/50\n",
            "0.0034537059254944324\n",
            "Imitation step 14/50\n",
            "0.0034345448948442936\n",
            "Imitation step 15/50\n",
            "0.003425364149734378\n",
            "Imitation step 16/50\n",
            "0.0034169291611760855\n",
            "Imitation step 17/50\n",
            "0.0034033984411507845\n",
            "Imitation step 18/50\n",
            "0.003386444179341197\n",
            "Imitation step 19/50\n",
            "0.003385800402611494\n",
            "Imitation step 20/50\n",
            "0.0033807798754423857\n",
            "Imitation step 21/50\n",
            "0.0033750112634152174\n",
            "Imitation step 22/50\n",
            "0.0033732159063220024\n",
            "Imitation step 23/50\n",
            "0.0033608218654990196\n",
            "Imitation step 24/50\n",
            "0.003348700935021043\n",
            "Imitation step 25/50\n",
            "0.003346359822899103\n",
            "Imitation step 26/50\n",
            "0.0033328940626233816\n",
            "Imitation step 27/50\n",
            "0.0033342621754854918\n",
            "Imitation step 28/50\n",
            "0.003346420591697097\n",
            "Imitation step 29/50\n",
            "0.0033786774147301912\n",
            "Imitation step 30/50\n",
            "0.003457463812083006\n",
            "Imitation step 31/50\n",
            "0.003611429827287793\n",
            "Imitation step 32/50\n",
            "0.003911767620593309\n",
            "Imitation step 33/50\n",
            "0.004213220439851284\n",
            "Imitation step 34/50\n",
            "0.00439705653116107\n",
            "Imitation step 35/50\n",
            "0.004351617302745581\n",
            "Imitation step 36/50\n",
            "0.004370770417153835\n",
            "Imitation step 37/50\n",
            "0.004243871197104454\n",
            "Imitation step 38/50\n",
            "0.004232355859130621\n",
            "Imitation step 39/50\n",
            "0.004133568610996008\n",
            "Imitation step 40/50\n",
            "0.004117043688893318\n",
            "Imitation step 41/50\n",
            "0.004062084946781397\n",
            "Imitation step 42/50\n",
            "0.004029160365462303\n",
            "Imitation step 43/50\n",
            "0.00395477470010519\n",
            "Imitation step 44/50\n",
            "0.003941275179386139\n",
            "Imitation step 45/50\n",
            "0.0038886975962668657\n",
            "Imitation step 46/50\n",
            "0.00387313193641603\n",
            "Imitation step 47/50\n",
            "0.0038263071328401566\n",
            "Imitation step 48/50\n",
            "0.003794334828853607\n",
            "Imitation step 49/50\n",
            "0.0037630849983543158\n",
            "Generator training\n",
            "0.11672017723321915\n",
            "Iteration 30/120\n",
            "Imitation step 0/50\n",
            "0.0037435630802065134\n",
            "Imitation step 1/50\n",
            "0.0027218731120228767\n",
            "Imitation step 2/50\n",
            "0.002726186066865921\n",
            "Imitation step 3/50\n",
            "0.002726601902395487\n",
            "Imitation step 4/50\n",
            "0.0027149689849466085\n",
            "Imitation step 5/50\n",
            "0.0027182104531675577\n",
            "Imitation step 6/50\n",
            "0.0027189182583242655\n",
            "Imitation step 7/50\n",
            "0.002718903822824359\n",
            "Imitation step 8/50\n",
            "0.002716977149248123\n",
            "Imitation step 9/50\n",
            "0.0027115868870168924\n",
            "Imitation step 10/50\n",
            "0.0027188623789697886\n",
            "Imitation step 11/50\n",
            "0.002708032727241516\n",
            "Imitation step 12/50\n",
            "0.0027080567087978125\n",
            "Imitation step 13/50\n",
            "0.0026995688676834106\n",
            "Imitation step 14/50\n",
            "0.0026968366000801325\n",
            "Imitation step 15/50\n",
            "0.0026990510523319244\n",
            "Imitation step 16/50\n",
            "0.0026928905863314867\n",
            "Imitation step 17/50\n",
            "0.0026936994399875402\n",
            "Imitation step 18/50\n",
            "0.0026935443747788668\n",
            "Imitation step 19/50\n",
            "0.0026929255109280348\n",
            "Imitation step 20/50\n",
            "0.0026947418227791786\n",
            "Imitation step 21/50\n",
            "0.00268630962818861\n",
            "Imitation step 22/50\n",
            "0.002688204636797309\n",
            "Imitation step 23/50\n",
            "0.0026843303348869085\n",
            "Imitation step 24/50\n",
            "0.00268386909738183\n",
            "Imitation step 25/50\n",
            "0.0026849096175283194\n",
            "Imitation step 26/50\n",
            "0.0026794802397489548\n",
            "Imitation step 27/50\n",
            "0.0026784553192555904\n",
            "Imitation step 28/50\n",
            "0.002681032521650195\n",
            "Imitation step 29/50\n",
            "0.002680259756743908\n",
            "Imitation step 30/50\n",
            "0.002676345407962799\n",
            "Imitation step 31/50\n",
            "0.002668604487553239\n",
            "Imitation step 32/50\n",
            "0.0026709509547799826\n",
            "Imitation step 33/50\n",
            "0.0026687984354794025\n",
            "Imitation step 34/50\n",
            "0.0026656545232981443\n",
            "Imitation step 35/50\n",
            "0.0026670098304748535\n",
            "Imitation step 36/50\n",
            "0.002661906648427248\n",
            "Imitation step 37/50\n",
            "0.0026605436578392982\n",
            "Imitation step 38/50\n",
            "0.002667083404958248\n",
            "Imitation step 39/50\n",
            "0.00265961023978889\n",
            "Imitation step 40/50\n",
            "0.0026577895041555166\n",
            "Imitation step 41/50\n",
            "0.0026538558304309845\n",
            "Imitation step 42/50\n",
            "0.0026502537075430155\n",
            "Imitation step 43/50\n",
            "0.0026531415060162544\n",
            "Imitation step 44/50\n",
            "0.002646892797201872\n",
            "Imitation step 45/50\n",
            "0.00265216245315969\n",
            "Imitation step 46/50\n",
            "0.0026470667216926813\n",
            "Imitation step 47/50\n",
            "0.0026524458080530167\n",
            "Imitation step 48/50\n",
            "0.002650253241881728\n",
            "Imitation step 49/50\n",
            "0.002641548402607441\n",
            "Generator training\n",
            "0.11790592223405838\n",
            "Iteration 31/120\n",
            "Imitation step 0/50\n",
            "0.0026411362923681736\n",
            "Imitation step 1/50\n",
            "0.00263920403085649\n",
            "Imitation step 2/50\n",
            "0.0026359418407082558\n",
            "Imitation step 3/50\n",
            "0.0026371683925390244\n",
            "Imitation step 4/50\n",
            "0.0026341553311794996\n",
            "Imitation step 5/50\n",
            "0.0026313888374716043\n",
            "Imitation step 6/50\n",
            "0.002629164606332779\n",
            "Imitation step 7/50\n",
            "0.0026307066436856985\n",
            "Imitation step 8/50\n",
            "0.002632778137922287\n",
            "Imitation step 9/50\n",
            "0.0026288528461009264\n",
            "Imitation step 10/50\n",
            "0.0026271094102412462\n",
            "Imitation step 11/50\n",
            "0.0026222371961921453\n",
            "Imitation step 12/50\n",
            "0.0026201445143669844\n",
            "Imitation step 13/50\n",
            "0.0026264579501003027\n",
            "Imitation step 14/50\n",
            "0.0026230476796627045\n",
            "Imitation step 15/50\n",
            "0.002613116055727005\n",
            "Imitation step 16/50\n",
            "0.0026128690224140882\n",
            "Imitation step 17/50\n",
            "0.002619186881929636\n",
            "Imitation step 18/50\n",
            "0.002612269949167967\n",
            "Imitation step 19/50\n",
            "0.0026170152705162764\n",
            "Imitation step 20/50\n",
            "0.002606928115710616\n",
            "Imitation step 21/50\n",
            "0.002605924615636468\n",
            "Imitation step 22/50\n",
            "0.0026079509407281876\n",
            "Imitation step 23/50\n",
            "0.002599699655547738\n",
            "Imitation step 24/50\n",
            "0.0026044240221381187\n",
            "Imitation step 25/50\n",
            "0.0026032044552266598\n",
            "Imitation step 26/50\n",
            "0.002601497806608677\n",
            "Imitation step 27/50\n",
            "0.0025988221168518066\n",
            "Imitation step 28/50\n",
            "0.002594650024548173\n",
            "Imitation step 29/50\n",
            "0.002594590885564685\n",
            "Imitation step 30/50\n",
            "0.0025962665677070618\n",
            "Imitation step 31/50\n",
            "0.002589948708191514\n",
            "Imitation step 32/50\n",
            "0.002589772455394268\n",
            "Imitation step 33/50\n",
            "0.0025913245044648647\n",
            "Imitation step 34/50\n",
            "0.002590271644294262\n",
            "Imitation step 35/50\n",
            "0.002589599462226033\n",
            "Imitation step 36/50\n",
            "0.0025871789548546076\n",
            "Imitation step 37/50\n",
            "0.0025842194445431232\n",
            "Imitation step 38/50\n",
            "0.0025827502831816673\n",
            "Imitation step 39/50\n",
            "0.0025879554450511932\n",
            "Imitation step 40/50\n",
            "0.002573365578427911\n",
            "Imitation step 41/50\n",
            "0.0025797039270401\n",
            "Imitation step 42/50\n",
            "0.0025732088834047318\n",
            "Imitation step 43/50\n",
            "0.0025747069157660007\n",
            "Imitation step 44/50\n",
            "0.002578685525804758\n",
            "Imitation step 45/50\n",
            "0.0025714626535773277\n",
            "Imitation step 46/50\n",
            "0.0025737660471349955\n",
            "Imitation step 47/50\n",
            "0.002565385540947318\n",
            "Imitation step 48/50\n",
            "0.002568623051047325\n",
            "Imitation step 49/50\n",
            "0.002566069830209017\n",
            "Generator training\n",
            "0.11783388257026672\n",
            "Iteration 32/120\n",
            "Imitation step 0/50\n",
            "0.0025655764620751143\n",
            "Imitation step 1/50\n",
            "0.0025643138214945793\n",
            "Imitation step 2/50\n",
            "0.0025664200074970722\n",
            "Imitation step 3/50\n",
            "0.0025588488206267357\n",
            "Imitation step 4/50\n",
            "0.002559221815317869\n",
            "Imitation step 5/50\n",
            "0.002561635570600629\n",
            "Imitation step 6/50\n",
            "0.002558126812800765\n",
            "Imitation step 7/50\n",
            "0.0025509633123874664\n",
            "Imitation step 8/50\n",
            "0.002552311634644866\n",
            "Imitation step 9/50\n",
            "0.002552240388467908\n",
            "Imitation step 10/50\n",
            "0.002548515098169446\n",
            "Imitation step 11/50\n",
            "0.0025494263973087072\n",
            "Imitation step 12/50\n",
            "0.002542489906772971\n",
            "Imitation step 13/50\n",
            "0.002546563744544983\n",
            "Imitation step 14/50\n",
            "0.002547519514337182\n",
            "Imitation step 15/50\n",
            "0.0025466608349233866\n",
            "Imitation step 16/50\n",
            "0.002541986294090748\n",
            "Imitation step 17/50\n",
            "0.002537654945626855\n",
            "Imitation step 18/50\n",
            "0.0025333771482110023\n",
            "Imitation step 19/50\n",
            "0.002537168562412262\n",
            "Imitation step 20/50\n",
            "0.002541250316426158\n",
            "Imitation step 21/50\n",
            "0.002535103587433696\n",
            "Imitation step 22/50\n",
            "0.002533911494538188\n",
            "Imitation step 23/50\n",
            "0.002528984099626541\n",
            "Imitation step 24/50\n",
            "0.0025340437423437834\n",
            "Imitation step 25/50\n",
            "0.0025281505659222603\n",
            "Imitation step 26/50\n",
            "0.0025253393687307835\n",
            "Imitation step 27/50\n",
            "0.002517297398298979\n",
            "Imitation step 28/50\n",
            "0.002527007134631276\n",
            "Imitation step 29/50\n",
            "0.002524374285712838\n",
            "Imitation step 30/50\n",
            "0.002524103969335556\n",
            "Imitation step 31/50\n",
            "0.0025202331598848104\n",
            "Imitation step 32/50\n",
            "0.0025142452213913202\n",
            "Imitation step 33/50\n",
            "0.0025205565616488457\n",
            "Imitation step 34/50\n",
            "0.0025103632360696793\n",
            "Imitation step 35/50\n",
            "0.0025123527739197016\n",
            "Imitation step 36/50\n",
            "0.002515513217076659\n",
            "Imitation step 37/50\n",
            "0.0025114465970546007\n",
            "Imitation step 38/50\n",
            "0.002507635159417987\n",
            "Imitation step 39/50\n",
            "0.0025091024581342936\n",
            "Imitation step 40/50\n",
            "0.0025080572813749313\n",
            "Imitation step 41/50\n",
            "0.0024992497637867928\n",
            "Imitation step 42/50\n",
            "0.002508958335965872\n",
            "Imitation step 43/50\n",
            "0.0025006101932376623\n",
            "Imitation step 44/50\n",
            "0.0024996823631227016\n",
            "Imitation step 45/50\n",
            "0.002500117989256978\n",
            "Imitation step 46/50\n",
            "0.002496525878086686\n",
            "Imitation step 47/50\n",
            "0.002495766617357731\n",
            "Imitation step 48/50\n",
            "0.0024941314477473497\n",
            "Imitation step 49/50\n",
            "0.0024953316897153854\n",
            "Generator training\n",
            "0.11801215261220932\n",
            "Iteration 33/120\n",
            "Imitation step 0/50\n",
            "0.0024969663936644793\n",
            "Imitation step 1/50\n",
            "0.0024914054665714502\n",
            "Imitation step 2/50\n",
            "0.0024909963831305504\n",
            "Imitation step 3/50\n",
            "0.002486246172338724\n",
            "Imitation step 4/50\n",
            "0.0024857178796082735\n",
            "Imitation step 5/50\n",
            "0.002488885773345828\n",
            "Imitation step 6/50\n",
            "0.002486657351255417\n",
            "Imitation step 7/50\n",
            "0.0024849732872098684\n",
            "Imitation step 8/50\n",
            "0.002486015670001507\n",
            "Imitation step 9/50\n",
            "0.0024805795401334763\n",
            "Imitation step 10/50\n",
            "0.002473245607689023\n",
            "Imitation step 11/50\n",
            "0.0024788237642496824\n",
            "Imitation step 12/50\n",
            "0.0024777520447969437\n",
            "Imitation step 13/50\n",
            "0.002477380447089672\n",
            "Imitation step 14/50\n",
            "0.0024718192871659994\n",
            "Imitation step 15/50\n",
            "0.002477574860677123\n",
            "Imitation step 16/50\n",
            "0.002470278413966298\n",
            "Imitation step 17/50\n",
            "0.0024646420497447252\n",
            "Imitation step 18/50\n",
            "0.0024691694416105747\n",
            "Imitation step 19/50\n",
            "0.0024656152818351984\n",
            "Imitation step 20/50\n",
            "0.0024587633088231087\n",
            "Imitation step 21/50\n",
            "0.0024659254122525454\n",
            "Imitation step 22/50\n",
            "0.0024648429825901985\n",
            "Imitation step 23/50\n",
            "0.0024645214434713125\n",
            "Imitation step 24/50\n",
            "0.0024620455224066973\n",
            "Imitation step 25/50\n",
            "0.002458674367517233\n",
            "Imitation step 26/50\n",
            "0.0024586620274931192\n",
            "Imitation step 27/50\n",
            "0.0024538219440728426\n",
            "Imitation step 28/50\n",
            "0.0024560338351875544\n",
            "Imitation step 29/50\n",
            "0.0024586219806224108\n",
            "Imitation step 30/50\n",
            "0.0024553898256272078\n",
            "Imitation step 31/50\n",
            "0.002451657084748149\n",
            "Imitation step 32/50\n",
            "0.002450989093631506\n",
            "Imitation step 33/50\n",
            "0.002449730644002557\n",
            "Imitation step 34/50\n",
            "0.002454336965456605\n",
            "Imitation step 35/50\n",
            "0.0024431804195046425\n",
            "Imitation step 36/50\n",
            "0.002448482671752572\n",
            "Imitation step 37/50\n",
            "0.0024433787912130356\n",
            "Imitation step 38/50\n",
            "0.002445017918944359\n",
            "Imitation step 39/50\n",
            "0.00243994384072721\n",
            "Imitation step 40/50\n",
            "0.0024423336144536734\n",
            "Imitation step 41/50\n",
            "0.0024419710971415043\n",
            "Imitation step 42/50\n",
            "0.002433069748803973\n",
            "Imitation step 43/50\n",
            "0.0024315330665558577\n",
            "Imitation step 44/50\n",
            "0.0024349228478968143\n",
            "Imitation step 45/50\n",
            "0.002436374081298709\n",
            "Imitation step 46/50\n",
            "0.0024321689270436764\n",
            "Imitation step 47/50\n",
            "0.0024358597584068775\n",
            "Imitation step 48/50\n",
            "0.002425495069473982\n",
            "Imitation step 49/50\n",
            "0.00242936541326344\n",
            "Generator training\n",
            "0.11800064891576767\n",
            "Iteration 34/120\n",
            "Imitation step 0/50\n",
            "0.002429252490401268\n",
            "Imitation step 1/50\n",
            "0.0024279975332319736\n",
            "Imitation step 2/50\n",
            "0.002425718354061246\n",
            "Imitation step 3/50\n",
            "0.0024240450002253056\n",
            "Imitation step 4/50\n",
            "0.002421667566522956\n",
            "Imitation step 5/50\n",
            "0.0024219949264079332\n",
            "Imitation step 6/50\n",
            "0.002417390001937747\n",
            "Imitation step 7/50\n",
            "0.0024167613591998816\n",
            "Imitation step 8/50\n",
            "0.002420044271275401\n",
            "Imitation step 9/50\n",
            "0.0024141918402165174\n",
            "Imitation step 10/50\n",
            "0.0024103934410959482\n",
            "Imitation step 11/50\n",
            "0.00241157878190279\n",
            "Imitation step 12/50\n",
            "0.002411164343357086\n",
            "Imitation step 13/50\n",
            "0.00241290801204741\n",
            "Imitation step 14/50\n",
            "0.002416342031210661\n",
            "Imitation step 15/50\n",
            "0.0024062013253569603\n",
            "Imitation step 16/50\n",
            "0.0024045538157224655\n",
            "Imitation step 17/50\n",
            "0.0024052278604358435\n",
            "Imitation step 18/50\n",
            "0.002400740049779415\n",
            "Imitation step 19/50\n",
            "0.0024045195896178484\n",
            "Imitation step 20/50\n",
            "0.0023988441098481417\n",
            "Imitation step 21/50\n",
            "0.0024015894159674644\n",
            "Imitation step 22/50\n",
            "0.002398613840341568\n",
            "Imitation step 23/50\n",
            "0.0024025659076869488\n",
            "Imitation step 24/50\n",
            "0.002396299969404936\n",
            "Imitation step 25/50\n",
            "0.0023923153057694435\n",
            "Imitation step 26/50\n",
            "0.002396815689280629\n",
            "Imitation step 27/50\n",
            "0.0023888598661869764\n",
            "Imitation step 28/50\n",
            "0.0023960480466485023\n",
            "Imitation step 29/50\n",
            "0.0023896151687949896\n",
            "Imitation step 30/50\n",
            "0.0023917527869343758\n",
            "Imitation step 31/50\n",
            "0.0023871094454079866\n",
            "Imitation step 32/50\n",
            "0.0023893509060144424\n",
            "Imitation step 33/50\n",
            "0.0023870051372796297\n",
            "Imitation step 34/50\n",
            "0.0023829303681850433\n",
            "Imitation step 35/50\n",
            "0.0023831045255064964\n",
            "Imitation step 36/50\n",
            "0.002383580431342125\n",
            "Imitation step 37/50\n",
            "0.002383304527029395\n",
            "Imitation step 38/50\n",
            "0.0023820274509489536\n",
            "Imitation step 39/50\n",
            "0.002372623421251774\n",
            "Imitation step 40/50\n",
            "0.002376569202169776\n",
            "Imitation step 41/50\n",
            "0.002377696568146348\n",
            "Imitation step 42/50\n",
            "0.0023780392948538065\n",
            "Imitation step 43/50\n",
            "0.0023718432057648897\n",
            "Imitation step 44/50\n",
            "0.0023700727615505457\n",
            "Imitation step 45/50\n",
            "0.0023701973259449005\n",
            "Imitation step 46/50\n",
            "0.0023679130245000124\n",
            "Imitation step 47/50\n",
            "0.002374125411733985\n",
            "Imitation step 48/50\n",
            "0.0023714746348559856\n",
            "Imitation step 49/50\n",
            "0.0023636212572455406\n",
            "Generator training\n",
            "0.11805630475282669\n",
            "Iteration 35/120\n",
            "Imitation step 0/50\n",
            "0.0023726269137114286\n",
            "Imitation step 1/50\n",
            "0.0023628156632184982\n",
            "Imitation step 2/50\n",
            "0.002366619883105159\n",
            "Imitation step 3/50\n",
            "0.002363296691328287\n",
            "Imitation step 4/50\n",
            "0.0023599877022206783\n",
            "Imitation step 5/50\n",
            "0.0023563348222523928\n",
            "Imitation step 6/50\n",
            "0.002358504803851247\n",
            "Imitation step 7/50\n",
            "0.002358208643272519\n",
            "Imitation step 8/50\n",
            "0.0023591178469359875\n",
            "Imitation step 9/50\n",
            "0.0023508064914494753\n",
            "Imitation step 10/50\n",
            "0.0023502775002270937\n",
            "Imitation step 11/50\n",
            "0.002349946880713105\n",
            "Imitation step 12/50\n",
            "0.002353808842599392\n",
            "Imitation step 13/50\n",
            "0.0023479200899600983\n",
            "Imitation step 14/50\n",
            "0.002347793662920594\n",
            "Imitation step 15/50\n",
            "0.002341792220249772\n",
            "Imitation step 16/50\n",
            "0.0023443009704351425\n",
            "Imitation step 17/50\n",
            "0.002344348467886448\n",
            "Imitation step 18/50\n",
            "0.0023445242550224066\n",
            "Imitation step 19/50\n",
            "0.0023420071229338646\n",
            "Imitation step 20/50\n",
            "0.0023361470084637403\n",
            "Imitation step 21/50\n",
            "0.002336425706744194\n",
            "Imitation step 22/50\n",
            "0.00233856332488358\n",
            "Imitation step 23/50\n",
            "0.0023370757699012756\n",
            "Imitation step 24/50\n",
            "0.0023381272330880165\n",
            "Imitation step 25/50\n",
            "0.0023367858957499266\n",
            "Imitation step 26/50\n",
            "0.0023322354536503553\n",
            "Imitation step 27/50\n",
            "0.002332517644390464\n",
            "Imitation step 28/50\n",
            "0.002333094133064151\n",
            "Imitation step 29/50\n",
            "0.002333118347451091\n",
            "Imitation step 30/50\n",
            "0.002333427546545863\n",
            "Imitation step 31/50\n",
            "0.002329643117263913\n",
            "Imitation step 32/50\n",
            "0.002325606532394886\n",
            "Imitation step 33/50\n",
            "0.002325508277863264\n",
            "Imitation step 34/50\n",
            "0.0023270423989742994\n",
            "Imitation step 35/50\n",
            "0.0023234128020703793\n",
            "Imitation step 36/50\n",
            "0.002319905674085021\n",
            "Imitation step 37/50\n",
            "0.0023194891400635242\n",
            "Imitation step 38/50\n",
            "0.0023179559502750635\n",
            "Imitation step 39/50\n",
            "0.0023220153525471687\n",
            "Imitation step 40/50\n",
            "0.00232132850214839\n",
            "Imitation step 41/50\n",
            "0.0023178723640739918\n",
            "Imitation step 42/50\n",
            "0.0023097910452634096\n",
            "Imitation step 43/50\n",
            "0.0023159529082477093\n",
            "Imitation step 44/50\n",
            "0.0023145873565226793\n",
            "Imitation step 45/50\n",
            "0.0023125517182052135\n",
            "Imitation step 46/50\n",
            "0.0023120741825550795\n",
            "Imitation step 47/50\n",
            "0.002309320727363229\n",
            "Imitation step 48/50\n",
            "0.0023089065216481686\n",
            "Imitation step 49/50\n",
            "0.0023042161483317614\n",
            "Generator training\n",
            "0.11800366640090942\n",
            "Iteration 36/120\n",
            "Imitation step 0/50\n",
            "0.0023034759797155857\n",
            "Imitation step 1/50\n",
            "0.0023009348660707474\n",
            "Imitation step 2/50\n",
            "0.0023026778362691402\n",
            "Imitation step 3/50\n",
            "0.0023006824776530266\n",
            "Imitation step 4/50\n",
            "0.0022998671047389507\n",
            "Imitation step 5/50\n",
            "0.0023011763114482164\n",
            "Imitation step 6/50\n",
            "0.0023005062248557806\n",
            "Imitation step 7/50\n",
            "0.0022992128506302834\n",
            "Imitation step 8/50\n",
            "0.002297439845278859\n",
            "Imitation step 9/50\n",
            "0.00229651783592999\n",
            "Imitation step 10/50\n",
            "0.002291414188221097\n",
            "Imitation step 11/50\n",
            "0.0022915606386959553\n",
            "Imitation step 12/50\n",
            "0.0022938887123018503\n",
            "Imitation step 13/50\n",
            "0.002288765273988247\n",
            "Imitation step 14/50\n",
            "0.002289657248184085\n",
            "Imitation step 15/50\n",
            "0.002287554554641247\n",
            "Imitation step 16/50\n",
            "0.002289462136104703\n",
            "Imitation step 17/50\n",
            "0.002287419978529215\n",
            "Imitation step 18/50\n",
            "0.0022840651217848063\n",
            "Imitation step 19/50\n",
            "0.00228652055375278\n",
            "Imitation step 20/50\n",
            "0.002289937809109688\n",
            "Imitation step 21/50\n",
            "0.002281446708366275\n",
            "Imitation step 22/50\n",
            "0.002281250199303031\n",
            "Imitation step 23/50\n",
            "0.0022769721690565348\n",
            "Imitation step 24/50\n",
            "0.00228091049939394\n",
            "Imitation step 25/50\n",
            "0.002280972898006439\n",
            "Imitation step 26/50\n",
            "0.0022792129311710596\n",
            "Imitation step 27/50\n",
            "0.0022762673906981945\n",
            "Imitation step 28/50\n",
            "0.0022749966010451317\n",
            "Imitation step 29/50\n",
            "0.0022773584350943565\n",
            "Imitation step 30/50\n",
            "0.002274401020258665\n",
            "Imitation step 31/50\n",
            "0.002273817313835025\n",
            "Imitation step 32/50\n",
            "0.0022725462913513184\n",
            "Imitation step 33/50\n",
            "0.002271021017804742\n",
            "Imitation step 34/50\n",
            "0.002270173979923129\n",
            "Imitation step 35/50\n",
            "0.002268209122121334\n",
            "Imitation step 36/50\n",
            "0.002269162330776453\n",
            "Imitation step 37/50\n",
            "0.002262078458443284\n",
            "Imitation step 38/50\n",
            "0.002265124348923564\n",
            "Imitation step 39/50\n",
            "0.0022619490046054125\n",
            "Imitation step 40/50\n",
            "0.00226015318185091\n",
            "Imitation step 41/50\n",
            "0.002261401852592826\n",
            "Imitation step 42/50\n",
            "0.0022586442064493895\n",
            "Imitation step 43/50\n",
            "0.00225925724953413\n",
            "Imitation step 44/50\n",
            "0.002257668413221836\n",
            "Imitation step 45/50\n",
            "0.0022550851572304964\n",
            "Imitation step 46/50\n",
            "0.002256145002320409\n",
            "Imitation step 47/50\n",
            "0.0022550635039806366\n",
            "Imitation step 48/50\n",
            "0.0022507968824356794\n",
            "Imitation step 49/50\n",
            "0.0022493447177112103\n",
            "Generator training\n",
            "0.11811666190624237\n",
            "Iteration 37/120\n",
            "Imitation step 0/50\n",
            "0.0022505170200020075\n",
            "Imitation step 1/50\n",
            "0.0022522504441440105\n",
            "Imitation step 2/50\n",
            "0.0022493130527436733\n",
            "Imitation step 3/50\n",
            "0.002245577285066247\n",
            "Imitation step 4/50\n",
            "0.0022470783442258835\n",
            "Imitation step 5/50\n",
            "0.0022479495964944363\n",
            "Imitation step 6/50\n",
            "0.0022485041990876198\n",
            "Imitation step 7/50\n",
            "0.0022435644641518593\n",
            "Imitation step 8/50\n",
            "0.0022431586403399706\n",
            "Imitation step 9/50\n",
            "0.0022417057771235704\n",
            "Imitation step 10/50\n",
            "0.0022419418673962355\n",
            "Imitation step 11/50\n",
            "0.002242346992716193\n",
            "Imitation step 12/50\n",
            "0.002240370260551572\n",
            "Imitation step 13/50\n",
            "0.002243244554847479\n",
            "Imitation step 14/50\n",
            "0.0022405837662518024\n",
            "Imitation step 15/50\n",
            "0.00224512442946434\n",
            "Imitation step 16/50\n",
            "0.00224185548722744\n",
            "Imitation step 17/50\n",
            "0.002240224974229932\n",
            "Imitation step 18/50\n",
            "0.002241086680442095\n",
            "Imitation step 19/50\n",
            "0.0022423805203288794\n",
            "Imitation step 20/50\n",
            "0.002244008705019951\n",
            "Imitation step 21/50\n",
            "0.002250776393339038\n",
            "Imitation step 22/50\n",
            "0.0022583468817174435\n",
            "Imitation step 23/50\n",
            "0.0022612593602389097\n",
            "Imitation step 24/50\n",
            "0.00226750411093235\n",
            "Imitation step 25/50\n",
            "0.0022730794735252857\n",
            "Imitation step 26/50\n",
            "0.0022843745537102222\n",
            "Imitation step 27/50\n",
            "0.002292514778673649\n",
            "Imitation step 28/50\n",
            "0.0023032468743622303\n",
            "Imitation step 29/50\n",
            "0.0023257581051439047\n",
            "Imitation step 30/50\n",
            "0.002341335639357567\n",
            "Imitation step 31/50\n",
            "0.00235357484780252\n",
            "Imitation step 32/50\n",
            "0.0023580736014992\n",
            "Imitation step 33/50\n",
            "0.002373817376792431\n",
            "Imitation step 34/50\n",
            "0.002386554377153516\n",
            "Imitation step 35/50\n",
            "0.0024101899471133947\n",
            "Imitation step 36/50\n",
            "0.002413056092336774\n",
            "Imitation step 37/50\n",
            "0.0024311444722115993\n",
            "Imitation step 38/50\n",
            "0.002438873052597046\n",
            "Imitation step 39/50\n",
            "0.0024489222560077906\n",
            "Imitation step 40/50\n",
            "0.002449385356158018\n",
            "Imitation step 41/50\n",
            "0.0024519211146980524\n",
            "Imitation step 42/50\n",
            "0.002452528104186058\n",
            "Imitation step 43/50\n",
            "0.0024527248460799456\n",
            "Imitation step 44/50\n",
            "0.00244599930010736\n",
            "Imitation step 45/50\n",
            "0.002449827501550317\n",
            "Imitation step 46/50\n",
            "0.0024520435836166143\n",
            "Imitation step 47/50\n",
            "0.002452680841088295\n",
            "Imitation step 48/50\n",
            "0.0024410495534539223\n",
            "Imitation step 49/50\n",
            "0.0024483404122292995\n",
            "Generator training\n",
            "0.11795150488615036\n",
            "Iteration 38/120\n",
            "Imitation step 0/50\n",
            "0.00244913250207901\n",
            "Imitation step 1/50\n",
            "0.002451126230880618\n",
            "Imitation step 2/50\n",
            "0.0024453247897326946\n",
            "Imitation step 3/50\n",
            "0.0024526738561689854\n",
            "Imitation step 4/50\n",
            "0.0024457687977701426\n",
            "Imitation step 5/50\n",
            "0.002445874735713005\n",
            "Imitation step 6/50\n",
            "0.002448143670335412\n",
            "Imitation step 7/50\n",
            "0.0024537688586860895\n",
            "Imitation step 8/50\n",
            "0.0024521697778254747\n",
            "Imitation step 9/50\n",
            "0.002454745350405574\n",
            "Imitation step 10/50\n",
            "0.0024439559783786535\n",
            "Imitation step 11/50\n",
            "0.0024447396863251925\n",
            "Imitation step 12/50\n",
            "0.0024376483634114265\n",
            "Imitation step 13/50\n",
            "0.0024473678786307573\n",
            "Imitation step 14/50\n",
            "0.0024469199124723673\n",
            "Imitation step 15/50\n",
            "0.002449424471706152\n",
            "Imitation step 16/50\n",
            "0.002442561322823167\n",
            "Imitation step 17/50\n",
            "0.0024455671664327383\n",
            "Imitation step 18/50\n",
            "0.002440408803522587\n",
            "Imitation step 19/50\n",
            "0.002442309632897377\n",
            "Imitation step 20/50\n",
            "0.002433729125186801\n",
            "Imitation step 21/50\n",
            "0.002434885362163186\n",
            "Imitation step 22/50\n",
            "0.0024349242448806763\n",
            "Imitation step 23/50\n",
            "0.002438981318846345\n",
            "Imitation step 24/50\n",
            "0.0024318937212228775\n",
            "Imitation step 25/50\n",
            "0.0024347612634301186\n",
            "Imitation step 26/50\n",
            "0.002421583980321884\n",
            "Imitation step 27/50\n",
            "0.0024220538325607777\n",
            "Imitation step 28/50\n",
            "0.002418550895527005\n",
            "Imitation step 29/50\n",
            "0.002422541379928589\n",
            "Imitation step 30/50\n",
            "0.0024061209987848997\n",
            "Imitation step 31/50\n",
            "0.0024170824326574802\n",
            "Imitation step 32/50\n",
            "0.002412110101431608\n",
            "Imitation step 33/50\n",
            "0.0024146786890923977\n",
            "Imitation step 34/50\n",
            "0.0024163208436220884\n",
            "Imitation step 35/50\n",
            "0.0024215218145400286\n",
            "Imitation step 36/50\n",
            "0.0024158877786248922\n",
            "Imitation step 37/50\n",
            "0.0024227581452578306\n",
            "Imitation step 38/50\n",
            "0.0024114276748150587\n",
            "Imitation step 39/50\n",
            "0.0024079440627247095\n",
            "Imitation step 40/50\n",
            "0.002400825032964349\n",
            "Imitation step 41/50\n",
            "0.0024048767518252134\n",
            "Imitation step 42/50\n",
            "0.002393877599388361\n",
            "Imitation step 43/50\n",
            "0.0023994892835617065\n",
            "Imitation step 44/50\n",
            "0.00240434636361897\n",
            "Imitation step 45/50\n",
            "0.002403436228632927\n",
            "Imitation step 46/50\n",
            "0.002394840819761157\n",
            "Imitation step 47/50\n",
            "0.0024003132712095976\n",
            "Imitation step 48/50\n",
            "0.0023889392614364624\n",
            "Imitation step 49/50\n",
            "0.002396928844973445\n",
            "Generator training\n",
            "0.11793778836727142\n",
            "Iteration 39/120\n",
            "Imitation step 0/50\n",
            "0.002383519895374775\n",
            "Imitation step 1/50\n",
            "0.0023849140852689743\n",
            "Imitation step 2/50\n",
            "0.002384092891588807\n",
            "Imitation step 3/50\n",
            "0.002386700361967087\n",
            "Imitation step 4/50\n",
            "0.0023830255959182978\n",
            "Imitation step 5/50\n",
            "0.002390599576756358\n",
            "Imitation step 6/50\n",
            "0.0023848693817853928\n",
            "Imitation step 7/50\n",
            "0.002384963445365429\n",
            "Imitation step 8/50\n",
            "0.0023885401897132397\n",
            "Imitation step 9/50\n",
            "0.002391138579696417\n",
            "Imitation step 10/50\n",
            "0.00237481202930212\n",
            "Imitation step 11/50\n",
            "0.0023773605935275555\n",
            "Imitation step 12/50\n",
            "0.002375549403950572\n",
            "Imitation step 13/50\n",
            "0.0023829888086766005\n",
            "Imitation step 14/50\n",
            "0.0023880419321358204\n",
            "Imitation step 15/50\n",
            "0.0023941074032336473\n",
            "Imitation step 16/50\n",
            "0.002373507944867015\n",
            "Imitation step 17/50\n",
            "0.002376112388446927\n",
            "Imitation step 18/50\n",
            "0.002370123751461506\n",
            "Imitation step 19/50\n",
            "0.002379924524575472\n",
            "Imitation step 20/50\n",
            "0.0023699169978499413\n",
            "Imitation step 21/50\n",
            "0.002371476963162422\n",
            "Imitation step 22/50\n",
            "0.0023672510869801044\n",
            "Imitation step 23/50\n",
            "0.002372750313952565\n",
            "Imitation step 24/50\n",
            "0.0023653164971619844\n",
            "Imitation step 25/50\n",
            "0.0023705470375716686\n",
            "Imitation step 26/50\n",
            "0.0023685041815042496\n",
            "Imitation step 27/50\n",
            "0.0023763321805745363\n",
            "Imitation step 28/50\n",
            "0.002374692354351282\n",
            "Imitation step 29/50\n",
            "0.002385464496910572\n",
            "Imitation step 30/50\n",
            "0.00238626217469573\n",
            "Imitation step 31/50\n",
            "0.0023959896061569452\n",
            "Imitation step 32/50\n",
            "0.002383854240179062\n",
            "Imitation step 33/50\n",
            "0.00239258143119514\n",
            "Imitation step 34/50\n",
            "0.002378445351496339\n",
            "Imitation step 35/50\n",
            "0.0023742886260151863\n",
            "Imitation step 36/50\n",
            "0.002371802693232894\n",
            "Imitation step 37/50\n",
            "0.0023812404833734035\n",
            "Imitation step 38/50\n",
            "0.0023773813154548407\n",
            "Imitation step 39/50\n",
            "0.002369878115132451\n",
            "Imitation step 40/50\n",
            "0.0023682403843849897\n",
            "Imitation step 41/50\n",
            "0.0023764867801219225\n",
            "Imitation step 42/50\n",
            "0.0023664170876145363\n",
            "Imitation step 43/50\n",
            "0.002365032909438014\n",
            "Imitation step 44/50\n",
            "0.002349791582673788\n",
            "Imitation step 45/50\n",
            "0.0023558498360216618\n",
            "Imitation step 46/50\n",
            "0.0023550360929220915\n",
            "Imitation step 47/50\n",
            "0.002360038924962282\n",
            "Imitation step 48/50\n",
            "0.0023641157895326614\n",
            "Imitation step 49/50\n",
            "0.002372256712988019\n",
            "Generator training\n",
            "0.11784091591835022\n",
            "Iteration 40/120\n",
            "Imitation step 0/50\n",
            "0.0023748979438096285\n",
            "Imitation step 1/50\n",
            "0.0021369026508182287\n",
            "Imitation step 2/50\n",
            "0.0021287573035806417\n",
            "Imitation step 3/50\n",
            "0.0021316881757229567\n",
            "Imitation step 4/50\n",
            "0.002128560096025467\n",
            "Imitation step 5/50\n",
            "0.002129250904545188\n",
            "Imitation step 6/50\n",
            "0.002131646266207099\n",
            "Imitation step 7/50\n",
            "0.0021281938534229994\n",
            "Imitation step 8/50\n",
            "0.002126529114320874\n",
            "Imitation step 9/50\n",
            "0.0021288630086928606\n",
            "Imitation step 10/50\n",
            "0.0021249838173389435\n",
            "Imitation step 11/50\n",
            "0.002125341910868883\n",
            "Imitation step 12/50\n",
            "0.0021243193186819553\n",
            "Imitation step 13/50\n",
            "0.0021248613484203815\n",
            "Imitation step 14/50\n",
            "0.002125683007761836\n",
            "Imitation step 15/50\n",
            "0.002122630598023534\n",
            "Imitation step 16/50\n",
            "0.0021274026948958635\n",
            "Imitation step 17/50\n",
            "0.0021228839177638292\n",
            "Imitation step 18/50\n",
            "0.002118219155818224\n",
            "Imitation step 19/50\n",
            "0.002116515301167965\n",
            "Imitation step 20/50\n",
            "0.002123605227097869\n",
            "Imitation step 21/50\n",
            "0.0021209134720265865\n",
            "Imitation step 22/50\n",
            "0.002120820339769125\n",
            "Imitation step 23/50\n",
            "0.002116650575771928\n",
            "Imitation step 24/50\n",
            "0.0021204266231507063\n",
            "Imitation step 25/50\n",
            "0.0021220408380031586\n",
            "Imitation step 26/50\n",
            "0.002117360709235072\n",
            "Imitation step 27/50\n",
            "0.00212363270111382\n",
            "Imitation step 28/50\n",
            "0.0021188105456531048\n",
            "Imitation step 29/50\n",
            "0.002114082919433713\n",
            "Imitation step 30/50\n",
            "0.0021165867801755667\n",
            "Imitation step 31/50\n",
            "0.0021131064277142286\n",
            "Imitation step 32/50\n",
            "0.0021117241121828556\n",
            "Imitation step 33/50\n",
            "0.0021127036307007074\n",
            "Imitation step 34/50\n",
            "0.002111586043611169\n",
            "Imitation step 35/50\n",
            "0.002113052411004901\n",
            "Imitation step 36/50\n",
            "0.0021163185592740774\n",
            "Imitation step 37/50\n",
            "0.0021101869642734528\n",
            "Imitation step 38/50\n",
            "0.002111569745466113\n",
            "Imitation step 39/50\n",
            "0.0021091944072395563\n",
            "Imitation step 40/50\n",
            "0.002111996989697218\n",
            "Imitation step 41/50\n",
            "0.0021110628731548786\n",
            "Imitation step 42/50\n",
            "0.0021087999921292067\n",
            "Imitation step 43/50\n",
            "0.0021087070927023888\n",
            "Imitation step 44/50\n",
            "0.002110125031322241\n",
            "Imitation step 45/50\n",
            "0.002105500316247344\n",
            "Imitation step 46/50\n",
            "0.0021091673988848925\n",
            "Imitation step 47/50\n",
            "0.002106413943693042\n",
            "Imitation step 48/50\n",
            "0.002109730849042535\n",
            "Imitation step 49/50\n",
            "0.0021047089248895645\n",
            "Generator training\n",
            "0.1180371567606926\n",
            "Iteration 41/120\n",
            "Imitation step 0/50\n",
            "0.002104335930198431\n",
            "Imitation step 1/50\n",
            "0.0021065312903374434\n",
            "Imitation step 2/50\n",
            "0.002105777384713292\n",
            "Imitation step 3/50\n",
            "0.0021061724983155727\n",
            "Imitation step 4/50\n",
            "0.0021069024223834276\n",
            "Imitation step 5/50\n",
            "0.0021056169643998146\n",
            "Imitation step 6/50\n",
            "0.0021064714528620243\n",
            "Imitation step 7/50\n",
            "0.0021029538474977016\n",
            "Imitation step 8/50\n",
            "0.0020997922401875257\n",
            "Imitation step 9/50\n",
            "0.0020992220379412174\n",
            "Imitation step 10/50\n",
            "0.0021031557116657495\n",
            "Imitation step 11/50\n",
            "0.0021027710754424334\n",
            "Imitation step 12/50\n",
            "0.0020992555655539036\n",
            "Imitation step 13/50\n",
            "0.002100636251270771\n",
            "Imitation step 14/50\n",
            "0.0020965011790394783\n",
            "Imitation step 15/50\n",
            "0.002101113321259618\n",
            "Imitation step 16/50\n",
            "0.002103240927681327\n",
            "Imitation step 17/50\n",
            "0.0020957039669156075\n",
            "Imitation step 18/50\n",
            "0.0020957584492862225\n",
            "Imitation step 19/50\n",
            "0.002102486090734601\n",
            "Imitation step 20/50\n",
            "0.0020941109396517277\n",
            "Imitation step 21/50\n",
            "0.0020944748539477587\n",
            "Imitation step 22/50\n",
            "0.002093049231916666\n",
            "Imitation step 23/50\n",
            "0.0020987004972994328\n",
            "Imitation step 24/50\n",
            "0.0020939456298947334\n",
            "Imitation step 25/50\n",
            "0.002095265546813607\n",
            "Imitation step 26/50\n",
            "0.0020927032455801964\n",
            "Imitation step 27/50\n",
            "0.002096857875585556\n",
            "Imitation step 28/50\n",
            "0.0020917390938848257\n",
            "Imitation step 29/50\n",
            "0.002090221969410777\n",
            "Imitation step 30/50\n",
            "0.002091983100399375\n",
            "Imitation step 31/50\n",
            "0.0020934981293976307\n",
            "Imitation step 32/50\n",
            "0.0020905067212879658\n",
            "Imitation step 33/50\n",
            "0.0020888173021376133\n",
            "Imitation step 34/50\n",
            "0.002085003536194563\n",
            "Imitation step 35/50\n",
            "0.0020881337113678455\n",
            "Imitation step 36/50\n",
            "0.002089214511215687\n",
            "Imitation step 37/50\n",
            "0.0020874778274446726\n",
            "Imitation step 38/50\n",
            "0.002090999623760581\n",
            "Imitation step 39/50\n",
            "0.0020837208721786737\n",
            "Imitation step 40/50\n",
            "0.002087713684886694\n",
            "Imitation step 41/50\n",
            "0.002086015185341239\n",
            "Imitation step 42/50\n",
            "0.002085257787257433\n",
            "Imitation step 43/50\n",
            "0.002086714841425419\n",
            "Imitation step 44/50\n",
            "0.0020835346076637506\n",
            "Imitation step 45/50\n",
            "0.0020853423047810793\n",
            "Imitation step 46/50\n",
            "0.0020849588327109814\n",
            "Imitation step 47/50\n",
            "0.002081225859001279\n",
            "Imitation step 48/50\n",
            "0.002083547180518508\n",
            "Imitation step 49/50\n",
            "0.0020825546234846115\n",
            "Generator training\n",
            "0.11809840053319931\n",
            "Iteration 42/120\n",
            "Imitation step 0/50\n",
            "0.0020809227135032415\n",
            "Imitation step 1/50\n",
            "0.002080521546304226\n",
            "Imitation step 2/50\n",
            "0.002080153673887253\n",
            "Imitation step 3/50\n",
            "0.002082798397168517\n",
            "Imitation step 4/50\n",
            "0.0020784707739949226\n",
            "Imitation step 5/50\n",
            "0.0020830309949815273\n",
            "Imitation step 6/50\n",
            "0.0020774470176547766\n",
            "Imitation step 7/50\n",
            "0.0020779601763933897\n",
            "Imitation step 8/50\n",
            "0.002077400917187333\n",
            "Imitation step 9/50\n",
            "0.0020815087482333183\n",
            "Imitation step 10/50\n",
            "0.0020781683269888163\n",
            "Imitation step 11/50\n",
            "0.002078103832900524\n",
            "Imitation step 12/50\n",
            "0.0020783990621566772\n",
            "Imitation step 13/50\n",
            "0.002075886121019721\n",
            "Imitation step 14/50\n",
            "0.0020799373742192984\n",
            "Imitation step 15/50\n",
            "0.00207258528098464\n",
            "Imitation step 16/50\n",
            "0.0020738176535815\n",
            "Imitation step 17/50\n",
            "0.0020733578130602837\n",
            "Imitation step 18/50\n",
            "0.002075664233416319\n",
            "Imitation step 19/50\n",
            "0.002071830676868558\n",
            "Imitation step 20/50\n",
            "0.002073802752420306\n",
            "Imitation step 21/50\n",
            "0.00207241321913898\n",
            "Imitation step 22/50\n",
            "0.0020716306753456593\n",
            "Imitation step 23/50\n",
            "0.002073750365525484\n",
            "Imitation step 24/50\n",
            "0.002068595727905631\n",
            "Imitation step 25/50\n",
            "0.0020693792030215263\n",
            "Imitation step 26/50\n",
            "0.0020696844439953566\n",
            "Imitation step 27/50\n",
            "0.002066005254164338\n",
            "Imitation step 28/50\n",
            "0.002069345908239484\n",
            "Imitation step 29/50\n",
            "0.002069658599793911\n",
            "Imitation step 30/50\n",
            "0.00207189517095685\n",
            "Imitation step 31/50\n",
            "0.002067131455987692\n",
            "Imitation step 32/50\n",
            "0.002066574292257428\n",
            "Imitation step 33/50\n",
            "0.0020646252669394016\n",
            "Imitation step 34/50\n",
            "0.002065616426989436\n",
            "Imitation step 35/50\n",
            "0.002065173117443919\n",
            "Imitation step 36/50\n",
            "0.0020631710067391396\n",
            "Imitation step 37/50\n",
            "0.002064276020973921\n",
            "Imitation step 38/50\n",
            "0.0020665908232331276\n",
            "Imitation step 39/50\n",
            "0.002064600121229887\n",
            "Imitation step 40/50\n",
            "0.002062615007162094\n",
            "Imitation step 41/50\n",
            "0.0020570114720612764\n",
            "Imitation step 42/50\n",
            "0.0020599085837602615\n",
            "Imitation step 43/50\n",
            "0.0020624410826712847\n",
            "Imitation step 44/50\n",
            "0.002064477652311325\n",
            "Imitation step 45/50\n",
            "0.0020608659833669662\n",
            "Imitation step 46/50\n",
            "0.0020580491982400417\n",
            "Imitation step 47/50\n",
            "0.0020587844774127007\n",
            "Imitation step 48/50\n",
            "0.0020631635561585426\n",
            "Imitation step 49/50\n",
            "0.0020594927482306957\n",
            "Generator training\n",
            "0.11815840750932693\n",
            "Iteration 43/120\n",
            "Imitation step 0/50\n",
            "0.0020581167191267014\n",
            "Imitation step 1/50\n",
            "0.002059041988104582\n",
            "Imitation step 2/50\n",
            "0.0020548615138977766\n",
            "Imitation step 3/50\n",
            "0.0020592287182807922\n",
            "Imitation step 4/50\n",
            "0.002057497389614582\n",
            "Imitation step 5/50\n",
            "0.002055781427770853\n",
            "Imitation step 6/50\n",
            "0.0020535418298095465\n",
            "Imitation step 7/50\n",
            "0.00205534347333014\n",
            "Imitation step 8/50\n",
            "0.002054299460723996\n",
            "Imitation step 9/50\n",
            "0.002051802584901452\n",
            "Imitation step 10/50\n",
            "0.0020565406884998083\n",
            "Imitation step 11/50\n",
            "0.002051791176199913\n",
            "Imitation step 12/50\n",
            "0.0020534314680844545\n",
            "Imitation step 13/50\n",
            "0.00205002399161458\n",
            "Imitation step 14/50\n",
            "0.002050763228908181\n",
            "Imitation step 15/50\n",
            "0.002049583476036787\n",
            "Imitation step 16/50\n",
            "0.002050778828561306\n",
            "Imitation step 17/50\n",
            "0.0020483580883592367\n",
            "Imitation step 18/50\n",
            "0.0020496028009802103\n",
            "Imitation step 19/50\n",
            "0.002049026545137167\n",
            "Imitation step 20/50\n",
            "0.0020463864784687757\n",
            "Imitation step 21/50\n",
            "0.0020470141898840666\n",
            "Imitation step 22/50\n",
            "0.0020451622549444437\n",
            "Imitation step 23/50\n",
            "0.002047924790531397\n",
            "Imitation step 24/50\n",
            "0.0020449624862521887\n",
            "Imitation step 25/50\n",
            "0.0020426404662430286\n",
            "Imitation step 26/50\n",
            "0.0020427554845809937\n",
            "Imitation step 27/50\n",
            "0.0020443869289010763\n",
            "Imitation step 28/50\n",
            "0.0020457536447793245\n",
            "Imitation step 29/50\n",
            "0.0020409661810845137\n",
            "Imitation step 30/50\n",
            "0.002043532906100154\n",
            "Imitation step 31/50\n",
            "0.002044662367552519\n",
            "Imitation step 32/50\n",
            "0.0020410199649631977\n",
            "Imitation step 33/50\n",
            "0.0020430234726518393\n",
            "Imitation step 34/50\n",
            "0.0020398132037371397\n",
            "Imitation step 35/50\n",
            "0.0020423366222530603\n",
            "Imitation step 36/50\n",
            "0.002039598533883691\n",
            "Imitation step 37/50\n",
            "0.002043053274974227\n",
            "Imitation step 38/50\n",
            "0.0020411701407283545\n",
            "Imitation step 39/50\n",
            "0.0020423124078661203\n",
            "Imitation step 40/50\n",
            "0.002035901416093111\n",
            "Imitation step 41/50\n",
            "0.0020405456889420748\n",
            "Imitation step 42/50\n",
            "0.00203870702534914\n",
            "Imitation step 43/50\n",
            "0.00203973357565701\n",
            "Imitation step 44/50\n",
            "0.002041308209300041\n",
            "Imitation step 45/50\n",
            "0.002041687723249197\n",
            "Imitation step 46/50\n",
            "0.002036851132288575\n",
            "Imitation step 47/50\n",
            "0.0020362134091556072\n",
            "Imitation step 48/50\n",
            "0.0020321602933108807\n",
            "Imitation step 49/50\n",
            "0.0020383705850690603\n",
            "Generator training\n",
            "0.11822576075792313\n",
            "Iteration 44/120\n",
            "Imitation step 0/50\n",
            "0.002035098848864436\n",
            "Imitation step 1/50\n",
            "0.0020386099349707365\n",
            "Imitation step 2/50\n",
            "0.002035614103078842\n",
            "Imitation step 3/50\n",
            "0.0020344697404652834\n",
            "Imitation step 4/50\n",
            "0.002033175202086568\n",
            "Imitation step 5/50\n",
            "0.002027408452704549\n",
            "Imitation step 6/50\n",
            "0.0020338166505098343\n",
            "Imitation step 7/50\n",
            "0.0020297684241086245\n",
            "Imitation step 8/50\n",
            "0.0020322289783507586\n",
            "Imitation step 9/50\n",
            "0.0020330457482486963\n",
            "Imitation step 10/50\n",
            "0.0020290056709200144\n",
            "Imitation step 11/50\n",
            "0.0020300187170505524\n",
            "Imitation step 12/50\n",
            "0.0020277616567909718\n",
            "Imitation step 13/50\n",
            "0.0020288722589612007\n",
            "Imitation step 14/50\n",
            "0.002028442220762372\n",
            "Imitation step 15/50\n",
            "0.002029547467827797\n",
            "Imitation step 16/50\n",
            "0.00202964898198843\n",
            "Imitation step 17/50\n",
            "0.0020273688714951277\n",
            "Imitation step 18/50\n",
            "0.0020278100855648518\n",
            "Imitation step 19/50\n",
            "0.0020262999460101128\n",
            "Imitation step 20/50\n",
            "0.002024774206802249\n",
            "Imitation step 21/50\n",
            "0.002027621027082205\n",
            "Imitation step 22/50\n",
            "0.0020203751046210527\n",
            "Imitation step 23/50\n",
            "0.002021219115704298\n",
            "Imitation step 24/50\n",
            "0.002020688960328698\n",
            "Imitation step 25/50\n",
            "0.0020252319518476725\n",
            "Imitation step 26/50\n",
            "0.0020211236551404\n",
            "Imitation step 27/50\n",
            "0.002023137640208006\n",
            "Imitation step 28/50\n",
            "0.0020211234223097563\n",
            "Imitation step 29/50\n",
            "0.0020163385197520256\n",
            "Imitation step 30/50\n",
            "0.0020222822204232216\n",
            "Imitation step 31/50\n",
            "0.0020169641356915236\n",
            "Imitation step 32/50\n",
            "0.002018087077885866\n",
            "Imitation step 33/50\n",
            "0.002021874999627471\n",
            "Imitation step 34/50\n",
            "0.0020217711571604013\n",
            "Imitation step 35/50\n",
            "0.00201788661070168\n",
            "Imitation step 36/50\n",
            "0.002021116903051734\n",
            "Imitation step 37/50\n",
            "0.0020159617997705936\n",
            "Imitation step 38/50\n",
            "0.0020156879909336567\n",
            "Imitation step 39/50\n",
            "0.0020136688835918903\n",
            "Imitation step 40/50\n",
            "0.0020187890622764826\n",
            "Imitation step 41/50\n",
            "0.0020133238285779953\n",
            "Imitation step 42/50\n",
            "0.002016006736084819\n",
            "Imitation step 43/50\n",
            "0.0020179401617497206\n",
            "Imitation step 44/50\n",
            "0.002016194863244891\n",
            "Imitation step 45/50\n",
            "0.002015461213886738\n",
            "Imitation step 46/50\n",
            "0.00201360578648746\n",
            "Imitation step 47/50\n",
            "0.0020138712134212255\n",
            "Imitation step 48/50\n",
            "0.0020121426787227392\n",
            "Imitation step 49/50\n",
            "0.0020142237190157175\n",
            "Generator training\n",
            "0.11819372326135635\n",
            "Iteration 45/120\n",
            "Imitation step 0/50\n",
            "0.0020162949804216623\n",
            "Imitation step 1/50\n",
            "0.0020141720306128263\n",
            "Imitation step 2/50\n",
            "0.0020112409256398678\n",
            "Imitation step 3/50\n",
            "0.0020094034262001514\n",
            "Imitation step 4/50\n",
            "0.002008482115343213\n",
            "Imitation step 5/50\n",
            "0.002009053947404027\n",
            "Imitation step 6/50\n",
            "0.0020072166807949543\n",
            "Imitation step 7/50\n",
            "0.002010677009820938\n",
            "Imitation step 8/50\n",
            "0.0020077573135495186\n",
            "Imitation step 9/50\n",
            "0.002005739603191614\n",
            "Imitation step 10/50\n",
            "0.0020051682367920876\n",
            "Imitation step 11/50\n",
            "0.002009759657084942\n",
            "Imitation step 12/50\n",
            "0.0020044343546032906\n",
            "Imitation step 13/50\n",
            "0.002008963841944933\n",
            "Imitation step 14/50\n",
            "0.0020065137650817633\n",
            "Imitation step 15/50\n",
            "0.0020069924648851156\n",
            "Imitation step 16/50\n",
            "0.0020042730029672384\n",
            "Imitation step 17/50\n",
            "0.0020039398223161697\n",
            "Imitation step 18/50\n",
            "0.002004147507250309\n",
            "Imitation step 19/50\n",
            "0.002002543769776821\n",
            "Imitation step 20/50\n",
            "0.0020030816085636616\n",
            "Imitation step 21/50\n",
            "0.0020032061729580164\n",
            "Imitation step 22/50\n",
            "0.0020025891717523336\n",
            "Imitation step 23/50\n",
            "0.0020031901076436043\n",
            "Imitation step 24/50\n",
            "0.0020041579846292734\n",
            "Imitation step 25/50\n",
            "0.0020016927737742662\n",
            "Imitation step 26/50\n",
            "0.001999293453991413\n",
            "Imitation step 27/50\n",
            "0.0020036199130117893\n",
            "Imitation step 28/50\n",
            "0.0019987488631159067\n",
            "Imitation step 29/50\n",
            "0.0019965043757110834\n",
            "Imitation step 30/50\n",
            "0.0019993155729025602\n",
            "Imitation step 31/50\n",
            "0.001997260143980384\n",
            "Imitation step 32/50\n",
            "0.001997806131839752\n",
            "Imitation step 33/50\n",
            "0.0019970957655459642\n",
            "Imitation step 34/50\n",
            "0.001996023114770651\n",
            "Imitation step 35/50\n",
            "0.001995460130274296\n",
            "Imitation step 36/50\n",
            "0.001995119033381343\n",
            "Imitation step 37/50\n",
            "0.0019951825961470604\n",
            "Imitation step 38/50\n",
            "0.0019951926078647375\n",
            "Imitation step 39/50\n",
            "0.0019946799147874117\n",
            "Imitation step 40/50\n",
            "0.0019958054181188345\n",
            "Imitation step 41/50\n",
            "0.0019872814882546663\n",
            "Imitation step 42/50\n",
            "0.0019912889692932367\n",
            "Imitation step 43/50\n",
            "0.0019946915563195944\n",
            "Imitation step 44/50\n",
            "0.0019894419237971306\n",
            "Imitation step 45/50\n",
            "0.0019916959572583437\n",
            "Imitation step 46/50\n",
            "0.0019931336864829063\n",
            "Imitation step 47/50\n",
            "0.0019948699045926332\n",
            "Imitation step 48/50\n",
            "0.0019868973176926374\n",
            "Imitation step 49/50\n",
            "0.0019895147997885942\n",
            "Generator training\n",
            "0.11809637397527695\n",
            "Iteration 46/120\n",
            "Imitation step 0/50\n",
            "0.0019899222534149885\n",
            "Imitation step 1/50\n",
            "0.0019876142032444477\n",
            "Imitation step 2/50\n",
            "0.001988606061786413\n",
            "Imitation step 3/50\n",
            "0.001986672403290868\n",
            "Imitation step 4/50\n",
            "0.001988594187423587\n",
            "Imitation step 5/50\n",
            "0.0019901562482118607\n",
            "Imitation step 6/50\n",
            "0.0019886072259396315\n",
            "Imitation step 7/50\n",
            "0.0019840316381305456\n",
            "Imitation step 8/50\n",
            "0.0019834202248603106\n",
            "Imitation step 9/50\n",
            "0.00198620674200356\n",
            "Imitation step 10/50\n",
            "0.001985067967325449\n",
            "Imitation step 11/50\n",
            "0.001984240021556616\n",
            "Imitation step 12/50\n",
            "0.0019858884625136852\n",
            "Imitation step 13/50\n",
            "0.0019831075333058834\n",
            "Imitation step 14/50\n",
            "0.0019814602565020323\n",
            "Imitation step 15/50\n",
            "0.0019858316518366337\n",
            "Imitation step 16/50\n",
            "0.001983341993764043\n",
            "Imitation step 17/50\n",
            "0.001983227673918009\n",
            "Imitation step 18/50\n",
            "0.001980928471311927\n",
            "Imitation step 19/50\n",
            "0.0019816590938717127\n",
            "Imitation step 20/50\n",
            "0.0019781191367655993\n",
            "Imitation step 21/50\n",
            "0.0019790150690823793\n",
            "Imitation step 22/50\n",
            "0.001977359177544713\n",
            "Imitation step 23/50\n",
            "0.0019802756141871214\n",
            "Imitation step 24/50\n",
            "0.001978821586817503\n",
            "Imitation step 25/50\n",
            "0.0019768294878304005\n",
            "Imitation step 26/50\n",
            "0.0019760290160775185\n",
            "Imitation step 27/50\n",
            "0.0019790837541222572\n",
            "Imitation step 28/50\n",
            "0.0019751887302845716\n",
            "Imitation step 29/50\n",
            "0.0019822330214083195\n",
            "Imitation step 30/50\n",
            "0.0019786974880844355\n",
            "Imitation step 31/50\n",
            "0.001978405052796006\n",
            "Imitation step 32/50\n",
            "0.001977313542738557\n",
            "Imitation step 33/50\n",
            "0.00197236449457705\n",
            "Imitation step 34/50\n",
            "0.001976512372493744\n",
            "Imitation step 35/50\n",
            "0.001974646933376789\n",
            "Imitation step 36/50\n",
            "0.00197299150750041\n",
            "Imitation step 37/50\n",
            "0.001974202925339341\n",
            "Imitation step 38/50\n",
            "0.001971451099961996\n",
            "Imitation step 39/50\n",
            "0.001976225757971406\n",
            "Imitation step 40/50\n",
            "0.001971446443349123\n",
            "Imitation step 41/50\n",
            "0.0019720415584743023\n",
            "Imitation step 42/50\n",
            "0.001973759150132537\n",
            "Imitation step 43/50\n",
            "0.0019675393123179674\n",
            "Imitation step 44/50\n",
            "0.00197284366004169\n",
            "Imitation step 45/50\n",
            "0.00197027251124382\n",
            "Imitation step 46/50\n",
            "0.0019693688955157995\n",
            "Imitation step 47/50\n",
            "0.001969822682440281\n",
            "Imitation step 48/50\n",
            "0.001971766585484147\n",
            "Imitation step 49/50\n",
            "0.0019678224343806505\n",
            "Generator training\n",
            "0.11825785040855408\n",
            "Iteration 47/120\n",
            "Imitation step 0/50\n",
            "0.001967121846973896\n",
            "Imitation step 1/50\n",
            "0.0019678790122270584\n",
            "Imitation step 2/50\n",
            "0.0019666377920657396\n",
            "Imitation step 3/50\n",
            "0.0019667602609843016\n",
            "Imitation step 4/50\n",
            "0.0019671693444252014\n",
            "Imitation step 5/50\n",
            "0.0019630708266049623\n",
            "Imitation step 6/50\n",
            "0.00196400610730052\n",
            "Imitation step 7/50\n",
            "0.001966713462024927\n",
            "Imitation step 8/50\n",
            "0.001964826136827469\n",
            "Imitation step 9/50\n",
            "0.001962882000952959\n",
            "Imitation step 10/50\n",
            "0.0019646654836833477\n",
            "Imitation step 11/50\n",
            "0.0019655160140246153\n",
            "Imitation step 12/50\n",
            "0.0019616535864770412\n",
            "Imitation step 13/50\n",
            "0.0019617867656052113\n",
            "Imitation step 14/50\n",
            "0.001960690366104245\n",
            "Imitation step 15/50\n",
            "0.001958357635885477\n",
            "Imitation step 16/50\n",
            "0.001958922715857625\n",
            "Imitation step 17/50\n",
            "0.0019603404216468334\n",
            "Imitation step 18/50\n",
            "0.001962688285857439\n",
            "Imitation step 19/50\n",
            "0.001962079433724284\n",
            "Imitation step 20/50\n",
            "0.001955330604687333\n",
            "Imitation step 21/50\n",
            "0.0019587108399719\n",
            "Imitation step 22/50\n",
            "0.00196303753182292\n",
            "Imitation step 23/50\n",
            "0.00196081236936152\n",
            "Imitation step 24/50\n",
            "0.001956542953848839\n",
            "Imitation step 25/50\n",
            "0.0019583215471357107\n",
            "Imitation step 26/50\n",
            "0.0019580840598791838\n",
            "Imitation step 27/50\n",
            "0.0019555361941456795\n",
            "Imitation step 28/50\n",
            "0.001957678934559226\n",
            "Imitation step 29/50\n",
            "0.001955169951543212\n",
            "Imitation step 30/50\n",
            "0.001953309867531061\n",
            "Imitation step 31/50\n",
            "0.001954528968781233\n",
            "Imitation step 32/50\n",
            "0.001955550629645586\n",
            "Imitation step 33/50\n",
            "0.0019495385931804776\n",
            "Imitation step 34/50\n",
            "0.0019559229258447886\n",
            "Imitation step 35/50\n",
            "0.0019540125504136086\n",
            "Imitation step 36/50\n",
            "0.0019534893799573183\n",
            "Imitation step 37/50\n",
            "0.0019520903006196022\n",
            "Imitation step 38/50\n",
            "0.0019520762143656611\n",
            "Imitation step 39/50\n",
            "0.0019534986931830645\n",
            "Imitation step 40/50\n",
            "0.0019506030948832631\n",
            "Imitation step 41/50\n",
            "0.0019486395176500082\n",
            "Imitation step 42/50\n",
            "0.0019484254298731685\n",
            "Imitation step 43/50\n",
            "0.0019485801458358765\n",
            "Imitation step 44/50\n",
            "0.0019488378893584013\n",
            "Imitation step 45/50\n",
            "0.00194987328723073\n",
            "Imitation step 46/50\n",
            "0.0019493188010528684\n",
            "Imitation step 47/50\n",
            "0.0019520311616361141\n",
            "Imitation step 48/50\n",
            "0.0019502828363329172\n",
            "Imitation step 49/50\n",
            "0.0019477598834782839\n",
            "Generator training\n",
            "0.11823661625385284\n",
            "Iteration 48/120\n",
            "Imitation step 0/50\n",
            "0.0019485193770378828\n",
            "Imitation step 1/50\n",
            "0.0019455836154520512\n",
            "Imitation step 2/50\n",
            "0.0019452165579423308\n",
            "Imitation step 3/50\n",
            "0.0019507715478539467\n",
            "Imitation step 4/50\n",
            "0.0019467264646664262\n",
            "Imitation step 5/50\n",
            "0.001945847412571311\n",
            "Imitation step 6/50\n",
            "0.0019467698875814676\n",
            "Imitation step 7/50\n",
            "0.0019440543837845325\n",
            "Imitation step 8/50\n",
            "0.0019443496130406857\n",
            "Imitation step 9/50\n",
            "0.001947436248883605\n",
            "Imitation step 10/50\n",
            "0.0019400365417823195\n",
            "Imitation step 11/50\n",
            "0.001944804098457098\n",
            "Imitation step 12/50\n",
            "0.0019434979185461998\n",
            "Imitation step 13/50\n",
            "0.0019398480653762817\n",
            "Imitation step 14/50\n",
            "0.001943350536748767\n",
            "Imitation step 15/50\n",
            "0.0019415264250710607\n",
            "Imitation step 16/50\n",
            "0.00194247392937541\n",
            "Imitation step 17/50\n",
            "0.0019373485120013356\n",
            "Imitation step 18/50\n",
            "0.0019371393136680126\n",
            "Imitation step 19/50\n",
            "0.001934989239089191\n",
            "Imitation step 20/50\n",
            "0.0019415172282606363\n",
            "Imitation step 21/50\n",
            "0.001939902431331575\n",
            "Imitation step 22/50\n",
            "0.0019382640020921826\n",
            "Imitation step 23/50\n",
            "0.00193805864546448\n",
            "Imitation step 24/50\n",
            "0.0019373170798644423\n",
            "Imitation step 25/50\n",
            "0.0019353224197402596\n",
            "Imitation step 26/50\n",
            "0.00193745456635952\n",
            "Imitation step 27/50\n",
            "0.0019362438470125198\n",
            "Imitation step 28/50\n",
            "0.0019314335659146309\n",
            "Imitation step 29/50\n",
            "0.0019356721313670278\n",
            "Imitation step 30/50\n",
            "0.0019327490590512753\n",
            "Imitation step 31/50\n",
            "0.0019352942472323775\n",
            "Imitation step 32/50\n",
            "0.0019340756116434932\n",
            "Imitation step 33/50\n",
            "0.0019339025020599365\n",
            "Imitation step 34/50\n",
            "0.0019336513942107558\n",
            "Imitation step 35/50\n",
            "0.0019312035292387009\n",
            "Imitation step 36/50\n",
            "0.0019343402236700058\n",
            "Imitation step 37/50\n",
            "0.0019317514961585402\n",
            "Imitation step 38/50\n",
            "0.0019294496160000563\n",
            "Imitation step 39/50\n",
            "0.0019352410454303026\n",
            "Imitation step 40/50\n",
            "0.0019299737177789211\n",
            "Imitation step 41/50\n",
            "0.0019312510266900063\n",
            "Imitation step 42/50\n",
            "0.0019301041029393673\n",
            "Imitation step 43/50\n",
            "0.0019283934962004423\n",
            "Imitation step 44/50\n",
            "0.0019288931507617235\n",
            "Imitation step 45/50\n",
            "0.0019316576654091477\n",
            "Imitation step 46/50\n",
            "0.0019261849811300635\n",
            "Imitation step 47/50\n",
            "0.0019247893942520022\n",
            "Imitation step 48/50\n",
            "0.0019270734628662467\n",
            "Imitation step 49/50\n",
            "0.0019261788111180067\n",
            "Generator training\n",
            "0.11838319897651672\n",
            "Iteration 49/120\n",
            "Imitation step 0/50\n",
            "0.0019264842849224806\n",
            "Imitation step 1/50\n",
            "0.001929461257532239\n",
            "Imitation step 2/50\n",
            "0.0019282117718830705\n",
            "Imitation step 3/50\n",
            "0.0019258190877735615\n",
            "Imitation step 4/50\n",
            "0.0019255551742389798\n",
            "Imitation step 5/50\n",
            "0.0019265912706032395\n",
            "Imitation step 6/50\n",
            "0.0019235039362683892\n",
            "Imitation step 7/50\n",
            "0.0019265577429905534\n",
            "Imitation step 8/50\n",
            "0.0019227437442168593\n",
            "Imitation step 9/50\n",
            "0.0019191080937162042\n",
            "Imitation step 10/50\n",
            "0.0019237702945247293\n",
            "Imitation step 11/50\n",
            "0.0019238169770687819\n",
            "Imitation step 12/50\n",
            "0.0019221351249143481\n",
            "Imitation step 13/50\n",
            "0.0019180546514689922\n",
            "Imitation step 14/50\n",
            "0.0019221819238737226\n",
            "Imitation step 15/50\n",
            "0.0019209927413612604\n",
            "Imitation step 16/50\n",
            "0.0019219157984480262\n",
            "Imitation step 17/50\n",
            "0.0019191725878044963\n",
            "Imitation step 18/50\n",
            "0.0019205660792067647\n",
            "Imitation step 19/50\n",
            "0.0019176475470885634\n",
            "Imitation step 20/50\n",
            "0.001920216134749353\n",
            "Imitation step 21/50\n",
            "0.0019154982874169946\n",
            "Imitation step 22/50\n",
            "0.0019153293687850237\n",
            "Imitation step 23/50\n",
            "0.0019150389125570655\n",
            "Imitation step 24/50\n",
            "0.0019167741993442178\n",
            "Imitation step 25/50\n",
            "0.0019183631520718336\n",
            "Imitation step 26/50\n",
            "0.0019142013043165207\n",
            "Imitation step 27/50\n",
            "0.001914359861984849\n",
            "Imitation step 28/50\n",
            "0.0019139193464070559\n",
            "Imitation step 29/50\n",
            "0.0019140724325552583\n",
            "Imitation step 30/50\n",
            "0.001914888620376587\n",
            "Imitation step 31/50\n",
            "0.0019136474002152681\n",
            "Imitation step 32/50\n",
            "0.0019098733318969607\n",
            "Imitation step 33/50\n",
            "0.0019118537893518806\n",
            "Imitation step 34/50\n",
            "0.0019132146844640374\n",
            "Imitation step 35/50\n",
            "0.0019118220079690218\n",
            "Imitation step 36/50\n",
            "0.001915863249450922\n",
            "Imitation step 37/50\n",
            "0.0019111073343083262\n",
            "Imitation step 38/50\n",
            "0.0019100421341136098\n",
            "Imitation step 39/50\n",
            "0.0019088394474238157\n",
            "Imitation step 40/50\n",
            "0.0019073321018368006\n",
            "Imitation step 41/50\n",
            "0.0019105133833363652\n",
            "Imitation step 42/50\n",
            "0.0019106398103758693\n",
            "Imitation step 43/50\n",
            "0.0019089392153546214\n",
            "Imitation step 44/50\n",
            "0.0019107246771454811\n",
            "Imitation step 45/50\n",
            "0.0019055899465456605\n",
            "Imitation step 46/50\n",
            "0.001908975071273744\n",
            "Imitation step 47/50\n",
            "0.0019062214996665716\n",
            "Imitation step 48/50\n",
            "0.0019040822517126799\n",
            "Imitation step 49/50\n",
            "0.001904742093756795\n",
            "Generator training\n",
            "0.1181972473859787\n",
            "Iteration 50/120\n",
            "Imitation step 0/50\n",
            "0.0019071648130193353\n",
            "Imitation step 1/50\n",
            "0.0019066081149503589\n",
            "Imitation step 2/50\n",
            "0.001902199350297451\n",
            "Imitation step 3/50\n",
            "0.0019047920359298587\n",
            "Imitation step 4/50\n",
            "0.0019067783141508698\n",
            "Imitation step 5/50\n",
            "0.0019092607544735074\n",
            "Imitation step 6/50\n",
            "0.0019057405879721045\n",
            "Imitation step 7/50\n",
            "0.0019053909927606583\n",
            "Imitation step 8/50\n",
            "0.0019047848181799054\n",
            "Imitation step 9/50\n",
            "0.001906959107145667\n",
            "Imitation step 10/50\n",
            "0.0019034115830436349\n",
            "Imitation step 11/50\n",
            "0.0019055648008361459\n",
            "Imitation step 12/50\n",
            "0.0019051182316616178\n",
            "Imitation step 13/50\n",
            "0.001902871998026967\n",
            "Imitation step 14/50\n",
            "0.0019064032239839435\n",
            "Imitation step 15/50\n",
            "0.001901889336295426\n",
            "Imitation step 16/50\n",
            "0.0019047207897529006\n",
            "Imitation step 17/50\n",
            "0.0019034049473702908\n",
            "Imitation step 18/50\n",
            "0.0019001616165041924\n",
            "Imitation step 19/50\n",
            "0.0019048011163249612\n",
            "Imitation step 20/50\n",
            "0.0019060266204178333\n",
            "Imitation step 21/50\n",
            "0.001903829164803028\n",
            "Imitation step 22/50\n",
            "0.0019040688639506698\n",
            "Imitation step 23/50\n",
            "0.0019008645322173834\n",
            "Imitation step 24/50\n",
            "0.0019003896741196513\n",
            "Imitation step 25/50\n",
            "0.001902046031318605\n",
            "Imitation step 26/50\n",
            "0.001899033784866333\n",
            "Imitation step 27/50\n",
            "0.001900706673040986\n",
            "Imitation step 28/50\n",
            "0.0019003186607733369\n",
            "Imitation step 29/50\n",
            "0.0018978441366925836\n",
            "Imitation step 30/50\n",
            "0.001898080692626536\n",
            "Imitation step 31/50\n",
            "0.0018990590469911695\n",
            "Imitation step 32/50\n",
            "0.0018967479700222611\n",
            "Imitation step 33/50\n",
            "0.0018977016443386674\n",
            "Imitation step 34/50\n",
            "0.0019000618485733867\n",
            "Imitation step 35/50\n",
            "0.0018995989812538028\n",
            "Imitation step 36/50\n",
            "0.001898732502013445\n",
            "Imitation step 37/50\n",
            "0.0018982826732099056\n",
            "Imitation step 38/50\n",
            "0.0018971781246364117\n",
            "Imitation step 39/50\n",
            "0.0018986089853569865\n",
            "Imitation step 40/50\n",
            "0.0018985735950991511\n",
            "Imitation step 41/50\n",
            "0.0018951223464682698\n",
            "Imitation step 42/50\n",
            "0.0018972820835188031\n",
            "Imitation step 43/50\n",
            "0.0018992731347680092\n",
            "Imitation step 44/50\n",
            "0.0018979025771841407\n",
            "Imitation step 45/50\n",
            "0.0018988511292263865\n",
            "Imitation step 46/50\n",
            "0.0018989162053912878\n",
            "Imitation step 47/50\n",
            "0.0018941242014989257\n",
            "Imitation step 48/50\n",
            "0.001899524824693799\n",
            "Imitation step 49/50\n",
            "0.0018965635681524873\n",
            "Generator training\n",
            "0.11823593825101852\n",
            "Iteration 51/120\n",
            "Imitation step 0/50\n",
            "0.0018972248071804643\n",
            "Imitation step 1/50\n",
            "0.0018966346979141235\n",
            "Imitation step 2/50\n",
            "0.0018953342223539948\n",
            "Imitation step 3/50\n",
            "0.0018959706649184227\n",
            "Imitation step 4/50\n",
            "0.0018994462443515658\n",
            "Imitation step 5/50\n",
            "0.001894688350148499\n",
            "Imitation step 6/50\n",
            "0.001893175533041358\n",
            "Imitation step 7/50\n",
            "0.0018885609460994601\n",
            "Imitation step 8/50\n",
            "0.0018923149909824133\n",
            "Imitation step 9/50\n",
            "0.0018936855485662818\n",
            "Imitation step 10/50\n",
            "0.0018953467952087522\n",
            "Imitation step 11/50\n",
            "0.0018937980057671666\n",
            "Imitation step 12/50\n",
            "0.0018935630796477199\n",
            "Imitation step 13/50\n",
            "0.0018970491364598274\n",
            "Imitation step 14/50\n",
            "0.0018934105755761266\n",
            "Imitation step 15/50\n",
            "0.001896494417451322\n",
            "Imitation step 16/50\n",
            "0.0018938780995085835\n",
            "Imitation step 17/50\n",
            "0.0018932739039883018\n",
            "Imitation step 18/50\n",
            "0.0018924690084531903\n",
            "Imitation step 19/50\n",
            "0.0018916056724265218\n",
            "Imitation step 20/50\n",
            "0.0018885002937167883\n",
            "Imitation step 21/50\n",
            "0.0018916664412245154\n",
            "Imitation step 22/50\n",
            "0.0018918296555057168\n",
            "Imitation step 23/50\n",
            "0.0018948079086840153\n",
            "Imitation step 24/50\n",
            "0.0018928231438621879\n",
            "Imitation step 25/50\n",
            "0.001892086467705667\n",
            "Imitation step 26/50\n",
            "0.001890685991384089\n",
            "Imitation step 27/50\n",
            "0.0018901306902989745\n",
            "Imitation step 28/50\n",
            "0.001890237326733768\n",
            "Imitation step 29/50\n",
            "0.0018897575791925192\n",
            "Imitation step 30/50\n",
            "0.001889122067950666\n",
            "Imitation step 31/50\n",
            "0.0018914161482825875\n",
            "Imitation step 32/50\n",
            "0.0018924102187156677\n",
            "Imitation step 33/50\n",
            "0.0018854442751035094\n",
            "Imitation step 34/50\n",
            "0.0018909209175035357\n",
            "Imitation step 35/50\n",
            "0.0018882491858676076\n",
            "Imitation step 36/50\n",
            "0.0018879756098613143\n",
            "Imitation step 37/50\n",
            "0.001891008927486837\n",
            "Imitation step 38/50\n",
            "0.0018895961111411452\n",
            "Imitation step 39/50\n",
            "0.0018906715558841825\n",
            "Imitation step 40/50\n",
            "0.0018881424330174923\n",
            "Imitation step 41/50\n",
            "0.0018836641684174538\n",
            "Imitation step 42/50\n",
            "0.0018861460266634822\n",
            "Imitation step 43/50\n",
            "0.0018881799187511206\n",
            "Imitation step 44/50\n",
            "0.0018855457892641425\n",
            "Imitation step 45/50\n",
            "0.0018911779625341296\n",
            "Imitation step 46/50\n",
            "0.0018898154376074672\n",
            "Imitation step 47/50\n",
            "0.0018871723441407084\n",
            "Imitation step 48/50\n",
            "0.0018904830794781446\n",
            "Imitation step 49/50\n",
            "0.0018849248299375176\n",
            "Generator training\n",
            "0.11825396120548248\n",
            "Iteration 52/120\n",
            "Imitation step 0/50\n",
            "0.0018856677925214171\n",
            "Imitation step 1/50\n",
            "0.001885156030766666\n",
            "Imitation step 2/50\n",
            "0.0018838957184925675\n",
            "Imitation step 3/50\n",
            "0.001885172794573009\n",
            "Imitation step 4/50\n",
            "0.0018870506901293993\n",
            "Imitation step 5/50\n",
            "0.0018874616362154484\n",
            "Imitation step 6/50\n",
            "0.0018844326259568334\n",
            "Imitation step 7/50\n",
            "0.001886909594759345\n",
            "Imitation step 8/50\n",
            "0.0018838811665773392\n",
            "Imitation step 9/50\n",
            "0.0018855805974453688\n",
            "Imitation step 10/50\n",
            "0.0018843596335500479\n",
            "Imitation step 11/50\n",
            "0.001885873032733798\n",
            "Imitation step 12/50\n",
            "0.0018873743247240782\n",
            "Imitation step 13/50\n",
            "0.0018847523024305701\n",
            "Imitation step 14/50\n",
            "0.0018832350615411997\n",
            "Imitation step 15/50\n",
            "0.0018846583552658558\n",
            "Imitation step 16/50\n",
            "0.0018827234162017703\n",
            "Imitation step 17/50\n",
            "0.0018839570693671703\n",
            "Imitation step 18/50\n",
            "0.001879939460195601\n",
            "Imitation step 19/50\n",
            "0.00188375951256603\n",
            "Imitation step 20/50\n",
            "0.0018843895522877574\n",
            "Imitation step 21/50\n",
            "0.0018824095604941249\n",
            "Imitation step 22/50\n",
            "0.001882854732684791\n",
            "Imitation step 23/50\n",
            "0.001880008727312088\n",
            "Imitation step 24/50\n",
            "0.0018861711723729968\n",
            "Imitation step 25/50\n",
            "0.0018810381880030036\n",
            "Imitation step 26/50\n",
            "0.0018827144522219896\n",
            "Imitation step 27/50\n",
            "0.0018799988320097327\n",
            "Imitation step 28/50\n",
            "0.0018811183981597424\n",
            "Imitation step 29/50\n",
            "0.0018778982339426875\n",
            "Imitation step 30/50\n",
            "0.0018824446015059948\n",
            "Imitation step 31/50\n",
            "0.0018826061859726906\n",
            "Imitation step 32/50\n",
            "0.0018799015088006854\n",
            "Imitation step 33/50\n",
            "0.0018771971808746457\n",
            "Imitation step 34/50\n",
            "0.0018803896382451057\n",
            "Imitation step 35/50\n",
            "0.001882740412838757\n",
            "Imitation step 36/50\n",
            "0.0018808313179761171\n",
            "Imitation step 37/50\n",
            "0.001877969829365611\n",
            "Imitation step 38/50\n",
            "0.0018767107976600528\n",
            "Imitation step 39/50\n",
            "0.0018787960289046168\n",
            "Imitation step 40/50\n",
            "0.001880671246908605\n",
            "Imitation step 41/50\n",
            "0.0018781023100018501\n",
            "Imitation step 42/50\n",
            "0.0018781552789732814\n",
            "Imitation step 43/50\n",
            "0.0018775623757392168\n",
            "Imitation step 44/50\n",
            "0.0018787563312798738\n",
            "Imitation step 45/50\n",
            "0.001879437011666596\n",
            "Imitation step 46/50\n",
            "0.0018788757734000683\n",
            "Imitation step 47/50\n",
            "0.0018764804117381573\n",
            "Imitation step 48/50\n",
            "0.0018783186096698046\n",
            "Imitation step 49/50\n",
            "0.0018758665537461638\n",
            "Generator training\n",
            "0.11820321530103683\n",
            "Iteration 53/120\n",
            "Imitation step 0/50\n",
            "0.0018799256067723036\n",
            "Imitation step 1/50\n",
            "0.0018780982354655862\n",
            "Imitation step 2/50\n",
            "0.0018783125560730696\n",
            "Imitation step 3/50\n",
            "0.001878275885246694\n",
            "Imitation step 4/50\n",
            "0.0018761040410026908\n",
            "Imitation step 5/50\n",
            "0.0018764825072139502\n",
            "Imitation step 6/50\n",
            "0.0018761282553896308\n",
            "Imitation step 7/50\n",
            "0.0018702548695728183\n",
            "Imitation step 8/50\n",
            "0.00187763012945652\n",
            "Imitation step 9/50\n",
            "0.0018759842496365309\n",
            "Imitation step 10/50\n",
            "0.001873440109193325\n",
            "Imitation step 11/50\n",
            "0.001876079710200429\n",
            "Imitation step 12/50\n",
            "0.0018760518869385123\n",
            "Imitation step 13/50\n",
            "0.001876196125522256\n",
            "Imitation step 14/50\n",
            "0.001870871288701892\n",
            "Imitation step 15/50\n",
            "0.0018727780552580953\n",
            "Imitation step 16/50\n",
            "0.0018775917124003172\n",
            "Imitation step 17/50\n",
            "0.0018738501239567995\n",
            "Imitation step 18/50\n",
            "0.0018746983259916306\n",
            "Imitation step 19/50\n",
            "0.0018720878288149834\n",
            "Imitation step 20/50\n",
            "0.0018711400916799903\n",
            "Imitation step 21/50\n",
            "0.001873144181445241\n",
            "Imitation step 22/50\n",
            "0.0018712215824052691\n",
            "Imitation step 23/50\n",
            "0.0018731342861428857\n",
            "Imitation step 24/50\n",
            "0.0018719453364610672\n",
            "Imitation step 25/50\n",
            "0.001873229630291462\n",
            "Imitation step 26/50\n",
            "0.0018715825863182545\n",
            "Imitation step 27/50\n",
            "0.0018725106492638588\n",
            "Imitation step 28/50\n",
            "0.0018707127310335636\n",
            "Imitation step 29/50\n",
            "0.0018717326456680894\n",
            "Imitation step 30/50\n",
            "0.001872583874501288\n",
            "Imitation step 31/50\n",
            "0.001871036016382277\n",
            "Imitation step 32/50\n",
            "0.0018719970248639584\n",
            "Imitation step 33/50\n",
            "0.0018709887517616153\n",
            "Imitation step 34/50\n",
            "0.0018676710315048695\n",
            "Imitation step 35/50\n",
            "0.001868788036517799\n",
            "Imitation step 36/50\n",
            "0.0018684053793549538\n",
            "Imitation step 37/50\n",
            "0.0018685127142816782\n",
            "Imitation step 38/50\n",
            "0.001868783263489604\n",
            "Imitation step 39/50\n",
            "0.0018687174888327718\n",
            "Imitation step 40/50\n",
            "0.0018688378622755408\n",
            "Imitation step 41/50\n",
            "0.0018690121360123158\n",
            "Imitation step 42/50\n",
            "0.0018641609931364655\n",
            "Imitation step 43/50\n",
            "0.0018700368236750364\n",
            "Imitation step 44/50\n",
            "0.0018655875464901328\n",
            "Imitation step 45/50\n",
            "0.0018702709348872304\n",
            "Imitation step 46/50\n",
            "0.0018663674127310514\n",
            "Imitation step 47/50\n",
            "0.001867387443780899\n",
            "Imitation step 48/50\n",
            "0.0018654497107490897\n",
            "Imitation step 49/50\n",
            "0.0018667924450710416\n",
            "Generator training\n",
            "0.11826392263174057\n",
            "Iteration 54/120\n",
            "Imitation step 0/50\n",
            "0.0018674758030101657\n",
            "Imitation step 1/50\n",
            "0.0018676110776141286\n",
            "Imitation step 2/50\n",
            "0.0018666755640879273\n",
            "Imitation step 3/50\n",
            "0.001865775790065527\n",
            "Imitation step 4/50\n",
            "0.0018644587835296988\n",
            "Imitation step 5/50\n",
            "0.0018651655409485102\n",
            "Imitation step 6/50\n",
            "0.0018663002410903573\n",
            "Imitation step 7/50\n",
            "0.001865171710960567\n",
            "Imitation step 8/50\n",
            "0.0018661445938050747\n",
            "Imitation step 9/50\n",
            "0.0018654426094144583\n",
            "Imitation step 10/50\n",
            "0.0018664617091417313\n",
            "Imitation step 11/50\n",
            "0.0018627180252224207\n",
            "Imitation step 12/50\n",
            "0.0018640264170244336\n",
            "Imitation step 13/50\n",
            "0.0018646392272785306\n",
            "Imitation step 14/50\n",
            "0.0018670853460207582\n",
            "Imitation step 15/50\n",
            "0.0018649548292160034\n",
            "Imitation step 16/50\n",
            "0.0018604568904265761\n",
            "Imitation step 17/50\n",
            "0.001865802682004869\n",
            "Imitation step 18/50\n",
            "0.0018619127804413438\n",
            "Imitation step 19/50\n",
            "0.0018620797200128436\n",
            "Imitation step 20/50\n",
            "0.0018641119822859764\n",
            "Imitation step 21/50\n",
            "0.0018646081443876028\n",
            "Imitation step 22/50\n",
            "0.0018649663543328643\n",
            "Imitation step 23/50\n",
            "0.0018631397979333997\n",
            "Imitation step 24/50\n",
            "0.001859716372564435\n",
            "Imitation step 25/50\n",
            "0.0018633053405210376\n",
            "Imitation step 26/50\n",
            "0.0018611620180308819\n",
            "Imitation step 27/50\n",
            "0.0018600730691105127\n",
            "Imitation step 28/50\n",
            "0.0018595827277749777\n",
            "Imitation step 29/50\n",
            "0.0018633492290973663\n",
            "Imitation step 30/50\n",
            "0.0018600495532155037\n",
            "Imitation step 31/50\n",
            "0.0018624081276357174\n",
            "Imitation step 32/50\n",
            "0.0018592363921925426\n",
            "Imitation step 33/50\n",
            "0.0018593312706798315\n",
            "Imitation step 34/50\n",
            "0.0018615459557622671\n",
            "Imitation step 35/50\n",
            "0.0018615107983350754\n",
            "Imitation step 36/50\n",
            "0.0018618463072925806\n",
            "Imitation step 37/50\n",
            "0.0018629215192049742\n",
            "Imitation step 38/50\n",
            "0.0018594866851344705\n",
            "Imitation step 39/50\n",
            "0.0018597361631691456\n",
            "Imitation step 40/50\n",
            "0.0018622208153828979\n",
            "Imitation step 41/50\n",
            "0.0018601693445816636\n",
            "Imitation step 42/50\n",
            "0.0018590993713587523\n",
            "Imitation step 43/50\n",
            "0.001859793090261519\n",
            "Imitation step 44/50\n",
            "0.0018554215785115957\n",
            "Imitation step 45/50\n",
            "0.0018582469783723354\n",
            "Imitation step 46/50\n",
            "0.0018574116984382272\n",
            "Imitation step 47/50\n",
            "0.0018608522368595004\n",
            "Imitation step 48/50\n",
            "0.0018572855042293668\n",
            "Imitation step 49/50\n",
            "0.001859824638813734\n",
            "Generator training\n",
            "0.11825967580080032\n",
            "Iteration 55/120\n",
            "Imitation step 0/50\n",
            "0.001861326745711267\n",
            "Imitation step 1/50\n",
            "0.0018579359166324139\n",
            "Imitation step 2/50\n",
            "0.0018622211646288633\n",
            "Imitation step 3/50\n",
            "0.0018582913326099515\n",
            "Imitation step 4/50\n",
            "0.001856096088886261\n",
            "Imitation step 5/50\n",
            "0.0018572489498183131\n",
            "Imitation step 6/50\n",
            "0.001860047341324389\n",
            "Imitation step 7/50\n",
            "0.0018559450982138515\n",
            "Imitation step 8/50\n",
            "0.0018567262450233102\n",
            "Imitation step 9/50\n",
            "0.0018548524240031838\n",
            "Imitation step 10/50\n",
            "0.0018545386847108603\n",
            "Imitation step 11/50\n",
            "0.0018564920173957944\n",
            "Imitation step 12/50\n",
            "0.0018545357743278146\n",
            "Imitation step 13/50\n",
            "0.0018542662728577852\n",
            "Imitation step 14/50\n",
            "0.0018571886466816068\n",
            "Imitation step 15/50\n",
            "0.001854923670180142\n",
            "Imitation step 16/50\n",
            "0.0018495154799893498\n",
            "Imitation step 17/50\n",
            "0.001853968482464552\n",
            "Imitation step 18/50\n",
            "0.0018533639376983047\n",
            "Imitation step 19/50\n",
            "0.0018526635831221938\n",
            "Imitation step 20/50\n",
            "0.0018567289225757122\n",
            "Imitation step 21/50\n",
            "0.0018539982847869396\n",
            "Imitation step 22/50\n",
            "0.0018527531065046787\n",
            "Imitation step 23/50\n",
            "0.0018512196838855743\n",
            "Imitation step 24/50\n",
            "0.0018505044281482697\n",
            "Imitation step 25/50\n",
            "0.0018549106316640973\n",
            "Imitation step 26/50\n",
            "0.00185174320358783\n",
            "Imitation step 27/50\n",
            "0.001857440103776753\n",
            "Imitation step 28/50\n",
            "0.0018529732478782535\n",
            "Imitation step 29/50\n",
            "0.001852734829299152\n",
            "Imitation step 30/50\n",
            "0.0018539519514888525\n",
            "Imitation step 31/50\n",
            "0.0018522996688261628\n",
            "Imitation step 32/50\n",
            "0.0018526628846302629\n",
            "Imitation step 33/50\n",
            "0.001852938556112349\n",
            "Imitation step 34/50\n",
            "0.0018528939690440893\n",
            "Imitation step 35/50\n",
            "0.0018480733269825578\n",
            "Imitation step 36/50\n",
            "0.0018497679848223925\n",
            "Imitation step 37/50\n",
            "0.0018517088610678911\n",
            "Imitation step 38/50\n",
            "0.001850268803536892\n",
            "Imitation step 39/50\n",
            "0.0018473328091204166\n",
            "Imitation step 40/50\n",
            "0.0018476595869287848\n",
            "Imitation step 41/50\n",
            "0.0018512939568609\n",
            "Imitation step 42/50\n",
            "0.0018490690272301435\n",
            "Imitation step 43/50\n",
            "0.0018515379633754492\n",
            "Imitation step 44/50\n",
            "0.0018484049942344427\n",
            "Imitation step 45/50\n",
            "0.0018444601446390152\n",
            "Imitation step 46/50\n",
            "0.0018476034747436643\n",
            "Imitation step 47/50\n",
            "0.0018490669317543507\n",
            "Imitation step 48/50\n",
            "0.0018484871834516525\n",
            "Imitation step 49/50\n",
            "0.0018471804214641452\n",
            "Generator training\n",
            "0.11817895621061325\n",
            "Iteration 56/120\n",
            "Imitation step 0/50\n",
            "0.001846533501520753\n",
            "Imitation step 1/50\n",
            "0.0018467262852936983\n",
            "Imitation step 2/50\n",
            "0.0018501164158806205\n",
            "Imitation step 3/50\n",
            "0.0018439640989527106\n",
            "Imitation step 4/50\n",
            "0.0018456006655469537\n",
            "Imitation step 5/50\n",
            "0.0018471992807462811\n",
            "Imitation step 6/50\n",
            "0.0018468662165105343\n",
            "Imitation step 7/50\n",
            "0.0018461698200553656\n",
            "Imitation step 8/50\n",
            "0.001844395650550723\n",
            "Imitation step 9/50\n",
            "0.0018524924525991082\n",
            "Imitation step 10/50\n",
            "0.0018457743572071195\n",
            "Imitation step 11/50\n",
            "0.0018458057893440127\n",
            "Imitation step 12/50\n",
            "0.0018442055443301797\n",
            "Imitation step 13/50\n",
            "0.0018444966990500689\n",
            "Imitation step 14/50\n",
            "0.0018460617866367102\n",
            "Imitation step 15/50\n",
            "0.0018472486408427358\n",
            "Imitation step 16/50\n",
            "0.0018471606308594346\n",
            "Imitation step 17/50\n",
            "0.001845266087912023\n",
            "Imitation step 18/50\n",
            "0.0018449354683980346\n",
            "Imitation step 19/50\n",
            "0.001842104597017169\n",
            "Imitation step 20/50\n",
            "0.0018431980861350894\n",
            "Imitation step 21/50\n",
            "0.0018430317286401987\n",
            "Imitation step 22/50\n",
            "0.0018427029717713594\n",
            "Imitation step 23/50\n",
            "0.0018457385012879968\n",
            "Imitation step 24/50\n",
            "0.0018476342083886266\n",
            "Imitation step 25/50\n",
            "0.0018438625847920775\n",
            "Imitation step 26/50\n",
            "0.0018415694357827306\n",
            "Imitation step 27/50\n",
            "0.001842221012338996\n",
            "Imitation step 28/50\n",
            "0.0018395341467112303\n",
            "Imitation step 29/50\n",
            "0.0018424601294100285\n",
            "Imitation step 30/50\n",
            "0.0018444025190547109\n",
            "Imitation step 31/50\n",
            "0.001840655691921711\n",
            "Imitation step 32/50\n",
            "0.0018444627057760954\n",
            "Imitation step 33/50\n",
            "0.0018406473100185394\n",
            "Imitation step 34/50\n",
            "0.0018424253212288022\n",
            "Imitation step 35/50\n",
            "0.0018404265865683556\n",
            "Imitation step 36/50\n",
            "0.0018380498513579369\n",
            "Imitation step 37/50\n",
            "0.001843241392634809\n",
            "Imitation step 38/50\n",
            "0.0018403116846457124\n",
            "Imitation step 39/50\n",
            "0.0018410857301205397\n",
            "Imitation step 40/50\n",
            "0.0018415733939036727\n",
            "Imitation step 41/50\n",
            "0.0018399017862975597\n",
            "Imitation step 42/50\n",
            "0.001842926605604589\n",
            "Imitation step 43/50\n",
            "0.0018395611550658941\n",
            "Imitation step 44/50\n",
            "0.0018387183081358671\n",
            "Imitation step 45/50\n",
            "0.0018385667353868484\n",
            "Imitation step 46/50\n",
            "0.0018424511654302478\n",
            "Imitation step 47/50\n",
            "0.0018374535720795393\n",
            "Imitation step 48/50\n",
            "0.001837090472690761\n",
            "Imitation step 49/50\n",
            "0.0018394822254776955\n",
            "Generator training\n",
            "0.11825248599052429\n",
            "Iteration 57/120\n",
            "Imitation step 0/50\n",
            "0.0018389401957392693\n",
            "Imitation step 1/50\n",
            "0.0018407173920422792\n",
            "Imitation step 2/50\n",
            "0.0018386219162493944\n",
            "Imitation step 3/50\n",
            "0.0018380634719505906\n",
            "Imitation step 4/50\n",
            "0.0018376987427473068\n",
            "Imitation step 5/50\n",
            "0.0018348891753703356\n",
            "Imitation step 6/50\n",
            "0.0018390357727184892\n",
            "Imitation step 7/50\n",
            "0.001837011892348528\n",
            "Imitation step 8/50\n",
            "0.0018360995454713702\n",
            "Imitation step 9/50\n",
            "0.0018371074693277478\n",
            "Imitation step 10/50\n",
            "0.0018350450554862618\n",
            "Imitation step 11/50\n",
            "0.0018359821988269687\n",
            "Imitation step 12/50\n",
            "0.0018330322345718741\n",
            "Imitation step 13/50\n",
            "0.0018341985996812582\n",
            "Imitation step 14/50\n",
            "0.0018361026886850595\n",
            "Imitation step 15/50\n",
            "0.0018401859560981393\n",
            "Imitation step 16/50\n",
            "0.0018322194227948785\n",
            "Imitation step 17/50\n",
            "0.00183373992331326\n",
            "Imitation step 18/50\n",
            "0.001834904425777495\n",
            "Imitation step 19/50\n",
            "0.0018349380698055029\n",
            "Imitation step 20/50\n",
            "0.001835470786318183\n",
            "Imitation step 21/50\n",
            "0.0018373385537415743\n",
            "Imitation step 22/50\n",
            "0.0018327117431908846\n",
            "Imitation step 23/50\n",
            "0.0018345399294048548\n",
            "Imitation step 24/50\n",
            "0.0018343407427892089\n",
            "Imitation step 25/50\n",
            "0.001833751448430121\n",
            "Imitation step 26/50\n",
            "0.0018320672679692507\n",
            "Imitation step 27/50\n",
            "0.0018357662484049797\n",
            "Imitation step 28/50\n",
            "0.0018345863791182637\n",
            "Imitation step 29/50\n",
            "0.0018316765781491995\n",
            "Imitation step 30/50\n",
            "0.001831927802413702\n",
            "Imitation step 31/50\n",
            "0.0018346705473959446\n",
            "Imitation step 32/50\n",
            "0.0018308778526261449\n",
            "Imitation step 33/50\n",
            "0.0018299301154911518\n",
            "Imitation step 34/50\n",
            "0.0018336898647248745\n",
            "Imitation step 35/50\n",
            "0.0018341607647016644\n",
            "Imitation step 36/50\n",
            "0.0018313298933207989\n",
            "Imitation step 37/50\n",
            "0.0018302914686501026\n",
            "Imitation step 38/50\n",
            "0.0018358060624450445\n",
            "Imitation step 39/50\n",
            "0.0018300125375390053\n",
            "Imitation step 40/50\n",
            "0.0018307964783161879\n",
            "Imitation step 41/50\n",
            "0.0018309771548956633\n",
            "Imitation step 42/50\n",
            "0.0018305862322449684\n",
            "Imitation step 43/50\n",
            "0.0018291757442057133\n",
            "Imitation step 44/50\n",
            "0.0018296720227226615\n",
            "Imitation step 45/50\n",
            "0.0018320608651265502\n",
            "Imitation step 46/50\n",
            "0.0018268568674102426\n",
            "Imitation step 47/50\n",
            "0.0018311339663341641\n",
            "Imitation step 48/50\n",
            "0.0018303426913917065\n",
            "Imitation step 49/50\n",
            "0.0018265203107148409\n",
            "Generator training\n",
            "0.1183324083685875\n",
            "Iteration 58/120\n",
            "Imitation step 0/50\n",
            "0.0018313906621187925\n",
            "Imitation step 1/50\n",
            "0.0018265042454004288\n",
            "Imitation step 2/50\n",
            "0.001830521272495389\n",
            "Imitation step 3/50\n",
            "0.001825983403250575\n",
            "Imitation step 4/50\n",
            "0.0018267000559717417\n",
            "Imitation step 5/50\n",
            "0.0018309849547222257\n",
            "Imitation step 6/50\n",
            "0.0018301239470019937\n",
            "Imitation step 7/50\n",
            "0.0018278701463714242\n",
            "Imitation step 8/50\n",
            "0.001826502732001245\n",
            "Imitation step 9/50\n",
            "0.0018262367229908705\n",
            "Imitation step 10/50\n",
            "0.0018251602305099368\n",
            "Imitation step 11/50\n",
            "0.001827204949222505\n",
            "Imitation step 12/50\n",
            "0.0018295269692316651\n",
            "Imitation step 13/50\n",
            "0.001827605301514268\n",
            "Imitation step 14/50\n",
            "0.001827751169912517\n",
            "Imitation step 15/50\n",
            "0.0018296318594366312\n",
            "Imitation step 16/50\n",
            "0.0018252149457111955\n",
            "Imitation step 17/50\n",
            "0.0018242764053866267\n",
            "Imitation step 18/50\n",
            "0.0018261111108586192\n",
            "Imitation step 19/50\n",
            "0.0018297103233635426\n",
            "Imitation step 20/50\n",
            "0.0018283071694895625\n",
            "Imitation step 21/50\n",
            "0.0018251424189656973\n",
            "Imitation step 22/50\n",
            "0.0018257418414577842\n",
            "Imitation step 23/50\n",
            "0.0018273419700562954\n",
            "Imitation step 24/50\n",
            "0.0018240883946418762\n",
            "Imitation step 25/50\n",
            "0.0018271947046741843\n",
            "Imitation step 26/50\n",
            "0.0018255653558298945\n",
            "Imitation step 27/50\n",
            "0.001824632752686739\n",
            "Imitation step 28/50\n",
            "0.001825503190048039\n",
            "Imitation step 29/50\n",
            "0.0018241788493469357\n",
            "Imitation step 30/50\n",
            "0.001823836355470121\n",
            "Imitation step 31/50\n",
            "0.0018228761618956923\n",
            "Imitation step 32/50\n",
            "0.0018227235414087772\n",
            "Imitation step 33/50\n",
            "0.0018238790798932314\n",
            "Imitation step 34/50\n",
            "0.0018218649784103036\n",
            "Imitation step 35/50\n",
            "0.0018230793066322803\n",
            "Imitation step 36/50\n",
            "0.0018231209833174944\n",
            "Imitation step 37/50\n",
            "0.0018246700055897236\n",
            "Imitation step 38/50\n",
            "0.0018234913004562259\n",
            "Imitation step 39/50\n",
            "0.0018235184252262115\n",
            "Imitation step 40/50\n",
            "0.001822521910071373\n",
            "Imitation step 41/50\n",
            "0.0018218024633824825\n",
            "Imitation step 42/50\n",
            "0.0018220433266833425\n",
            "Imitation step 43/50\n",
            "0.0018211499555036426\n",
            "Imitation step 44/50\n",
            "0.0018222210928797722\n",
            "Imitation step 45/50\n",
            "0.001824027393013239\n",
            "Imitation step 46/50\n",
            "0.0018241251818835735\n",
            "Imitation step 47/50\n",
            "0.0018216546159237623\n",
            "Imitation step 48/50\n",
            "0.0018227118998765945\n",
            "Imitation step 49/50\n",
            "0.0018174633150920272\n",
            "Generator training\n",
            "0.11825785785913467\n",
            "Iteration 59/120\n",
            "Imitation step 0/50\n",
            "0.0018214273732155561\n",
            "Imitation step 1/50\n",
            "0.0018197571625933051\n",
            "Imitation step 2/50\n",
            "0.001817721757106483\n",
            "Imitation step 3/50\n",
            "0.0018202229402959347\n",
            "Imitation step 4/50\n",
            "0.0018196256132796407\n",
            "Imitation step 5/50\n",
            "0.0018212816212326288\n",
            "Imitation step 6/50\n",
            "0.001819149125367403\n",
            "Imitation step 7/50\n",
            "0.0018179897451773286\n",
            "Imitation step 8/50\n",
            "0.0018167096422985196\n",
            "Imitation step 9/50\n",
            "0.0018190753180533648\n",
            "Imitation step 10/50\n",
            "0.001820359961129725\n",
            "Imitation step 11/50\n",
            "0.0018165605142712593\n",
            "Imitation step 12/50\n",
            "0.001817113603465259\n",
            "Imitation step 13/50\n",
            "0.001816076459363103\n",
            "Imitation step 14/50\n",
            "0.0018189230468124151\n",
            "Imitation step 15/50\n",
            "0.0018176655285060406\n",
            "Imitation step 16/50\n",
            "0.0018193329451605678\n",
            "Imitation step 17/50\n",
            "0.0018182535422965884\n",
            "Imitation step 18/50\n",
            "0.0018177683232352138\n",
            "Imitation step 19/50\n",
            "0.0018164798384532332\n",
            "Imitation step 20/50\n",
            "0.0018168948590755463\n",
            "Imitation step 21/50\n",
            "0.001815597410313785\n",
            "Imitation step 22/50\n",
            "0.0018165360670536757\n",
            "Imitation step 23/50\n",
            "0.0018136347644031048\n",
            "Imitation step 24/50\n",
            "0.001814518473111093\n",
            "Imitation step 25/50\n",
            "0.0018141220789402723\n",
            "Imitation step 26/50\n",
            "0.0018142112530767918\n",
            "Imitation step 27/50\n",
            "0.0018181379418820143\n",
            "Imitation step 28/50\n",
            "0.0018137241713702679\n",
            "Imitation step 29/50\n",
            "0.00181667844299227\n",
            "Imitation step 30/50\n",
            "0.0018122670007869601\n",
            "Imitation step 31/50\n",
            "0.00181406713090837\n",
            "Imitation step 32/50\n",
            "0.0018169458489865065\n",
            "Imitation step 33/50\n",
            "0.0018130427924916148\n",
            "Imitation step 34/50\n",
            "0.0018160688923671842\n",
            "Imitation step 35/50\n",
            "0.0018142834305763245\n",
            "Imitation step 36/50\n",
            "0.0018125500064343214\n",
            "Imitation step 37/50\n",
            "0.0018149369861930609\n",
            "Imitation step 38/50\n",
            "0.0018136905273422599\n",
            "Imitation step 39/50\n",
            "0.0018158506136387587\n",
            "Imitation step 40/50\n",
            "0.0018118227599188685\n",
            "Imitation step 41/50\n",
            "0.0018096191342920065\n",
            "Imitation step 42/50\n",
            "0.001813759678043425\n",
            "Imitation step 43/50\n",
            "0.0018160473555326462\n",
            "Imitation step 44/50\n",
            "0.001809788984246552\n",
            "Imitation step 45/50\n",
            "0.0018112051766365767\n",
            "Imitation step 46/50\n",
            "0.0018143635243177414\n",
            "Imitation step 47/50\n",
            "0.0018130436073988676\n",
            "Imitation step 48/50\n",
            "0.0018093526596203446\n",
            "Imitation step 49/50\n",
            "0.0018121144967153668\n",
            "Generator training\n",
            "0.11826498061418533\n",
            "Iteration 60/120\n",
            "Imitation step 0/50\n",
            "0.0018143977504223585\n",
            "Imitation step 1/50\n",
            "0.0018101263558492064\n",
            "Imitation step 2/50\n",
            "0.0018077701097354293\n",
            "Imitation step 3/50\n",
            "0.0018150218529626727\n",
            "Imitation step 4/50\n",
            "0.001809005392715335\n",
            "Imitation step 5/50\n",
            "0.001808776636607945\n",
            "Imitation step 6/50\n",
            "0.0018092682585120201\n",
            "Imitation step 7/50\n",
            "0.001809832756407559\n",
            "Imitation step 8/50\n",
            "0.0018093688413500786\n",
            "Imitation step 9/50\n",
            "0.0018148748204112053\n",
            "Imitation step 10/50\n",
            "0.0018119121668860316\n",
            "Imitation step 11/50\n",
            "0.001811069785617292\n",
            "Imitation step 12/50\n",
            "0.0018085147021338344\n",
            "Imitation step 13/50\n",
            "0.0018122510518878698\n",
            "Imitation step 14/50\n",
            "0.001809141831472516\n",
            "Imitation step 15/50\n",
            "0.0018108041258528829\n",
            "Imitation step 16/50\n",
            "0.0018080846639350057\n",
            "Imitation step 17/50\n",
            "0.001809928915463388\n",
            "Imitation step 18/50\n",
            "0.0018091668607667089\n",
            "Imitation step 19/50\n",
            "0.0018089907243847847\n",
            "Imitation step 20/50\n",
            "0.0018082760507240891\n",
            "Imitation step 21/50\n",
            "0.0018117405707016587\n",
            "Imitation step 22/50\n",
            "0.0018091046949848533\n",
            "Imitation step 23/50\n",
            "0.0018126448849216104\n",
            "Imitation step 24/50\n",
            "0.001808159169740975\n",
            "Imitation step 25/50\n",
            "0.0018104126211255789\n",
            "Imitation step 26/50\n",
            "0.001807310851290822\n",
            "Imitation step 27/50\n",
            "0.001809760113246739\n",
            "Imitation step 28/50\n",
            "0.0018096998101100326\n",
            "Imitation step 29/50\n",
            "0.00180758663918823\n",
            "Imitation step 30/50\n",
            "0.0018110236851498485\n",
            "Imitation step 31/50\n",
            "0.0018116203136742115\n",
            "Imitation step 32/50\n",
            "0.0018107985379174352\n",
            "Imitation step 33/50\n",
            "0.0018082571914419532\n",
            "Imitation step 34/50\n",
            "0.001804223982617259\n",
            "Imitation step 35/50\n",
            "0.0018061280716210604\n",
            "Imitation step 36/50\n",
            "0.0018086977070197463\n",
            "Imitation step 37/50\n",
            "0.0018051393562927842\n",
            "Imitation step 38/50\n",
            "0.0018071585800498724\n",
            "Imitation step 39/50\n",
            "0.0018086633644998074\n",
            "Imitation step 40/50\n",
            "0.0018070997903123498\n",
            "Imitation step 41/50\n",
            "0.001807073364034295\n",
            "Imitation step 42/50\n",
            "0.0018069744110107422\n",
            "Imitation step 43/50\n",
            "0.0018081098096445203\n",
            "Imitation step 44/50\n",
            "0.0018061408773064613\n",
            "Imitation step 45/50\n",
            "0.0018092384561896324\n",
            "Imitation step 46/50\n",
            "0.0018057696288451552\n",
            "Imitation step 47/50\n",
            "0.0018088174983859062\n",
            "Imitation step 48/50\n",
            "0.001805558567866683\n",
            "Imitation step 49/50\n",
            "0.0018079117871820927\n",
            "Generator training\n",
            "0.11818617582321167\n",
            "Iteration 61/120\n",
            "Imitation step 0/50\n",
            "0.001804980100132525\n",
            "Imitation step 1/50\n",
            "0.0018038845155388117\n",
            "Imitation step 2/50\n",
            "0.0018078398425132036\n",
            "Imitation step 3/50\n",
            "0.0018071141093969345\n",
            "Imitation step 4/50\n",
            "0.0018053206149488688\n",
            "Imitation step 5/50\n",
            "0.001803568098694086\n",
            "Imitation step 6/50\n",
            "0.0018102839821949601\n",
            "Imitation step 7/50\n",
            "0.0018058799905702472\n",
            "Imitation step 8/50\n",
            "0.0018062357557937503\n",
            "Imitation step 9/50\n",
            "0.001807653927244246\n",
            "Imitation step 10/50\n",
            "0.0018038501730188727\n",
            "Imitation step 11/50\n",
            "0.0018060400616377592\n",
            "Imitation step 12/50\n",
            "0.001809880486689508\n",
            "Imitation step 13/50\n",
            "0.0018073354149237275\n",
            "Imitation step 14/50\n",
            "0.0018064597388729453\n",
            "Imitation step 15/50\n",
            "0.0018059213180094957\n",
            "Imitation step 16/50\n",
            "0.0018045093165710568\n",
            "Imitation step 17/50\n",
            "0.0018059135181829333\n",
            "Imitation step 18/50\n",
            "0.0018039086135104299\n",
            "Imitation step 19/50\n",
            "0.0018054558895528316\n",
            "Imitation step 20/50\n",
            "0.0018049618229269981\n",
            "Imitation step 21/50\n",
            "0.0018031280487775803\n",
            "Imitation step 22/50\n",
            "0.0018023987067863345\n",
            "Imitation step 23/50\n",
            "0.001803298480808735\n",
            "Imitation step 24/50\n",
            "0.0018033899832516909\n",
            "Imitation step 25/50\n",
            "0.0018081612652167678\n",
            "Imitation step 26/50\n",
            "0.0018052513478323817\n",
            "Imitation step 27/50\n",
            "0.0018053260864689946\n",
            "Imitation step 28/50\n",
            "0.0018030436476692557\n",
            "Imitation step 29/50\n",
            "0.0018011505017057061\n",
            "Imitation step 30/50\n",
            "0.0018040454015135765\n",
            "Imitation step 31/50\n",
            "0.0018039847491309047\n",
            "Imitation step 32/50\n",
            "0.001803636085242033\n",
            "Imitation step 33/50\n",
            "0.0018024571472778916\n",
            "Imitation step 34/50\n",
            "0.0018058354035019875\n",
            "Imitation step 35/50\n",
            "0.0018046126933768392\n",
            "Imitation step 36/50\n",
            "0.0018048147903755307\n",
            "Imitation step 37/50\n",
            "0.001801850856281817\n",
            "Imitation step 38/50\n",
            "0.001802486483938992\n",
            "Imitation step 39/50\n",
            "0.0018026235047727823\n",
            "Imitation step 40/50\n",
            "0.001802105805836618\n",
            "Imitation step 41/50\n",
            "0.0018018650589510798\n",
            "Imitation step 42/50\n",
            "0.001801791600883007\n",
            "Imitation step 43/50\n",
            "0.00180237356107682\n",
            "Imitation step 44/50\n",
            "0.0018029672792181373\n",
            "Imitation step 45/50\n",
            "0.0018011151114478707\n",
            "Imitation step 46/50\n",
            "0.0018043200252577662\n",
            "Imitation step 47/50\n",
            "0.0018061386654153466\n",
            "Imitation step 48/50\n",
            "0.0018043456366285682\n",
            "Imitation step 49/50\n",
            "0.0018049199134111404\n",
            "Generator training\n",
            "0.11824359744787216\n",
            "Iteration 62/120\n",
            "Imitation step 0/50\n",
            "0.0018014035886153579\n",
            "Imitation step 1/50\n",
            "0.0017993948422372341\n",
            "Imitation step 2/50\n",
            "0.001799879944883287\n",
            "Imitation step 3/50\n",
            "0.0018011615611612797\n",
            "Imitation step 4/50\n",
            "0.0018004585290327668\n",
            "Imitation step 5/50\n",
            "0.0018016216345131397\n",
            "Imitation step 6/50\n",
            "0.0018031176878139377\n",
            "Imitation step 7/50\n",
            "0.0018006226746365428\n",
            "Imitation step 8/50\n",
            "0.0017988544423133135\n",
            "Imitation step 9/50\n",
            "0.0018005535239353776\n",
            "Imitation step 10/50\n",
            "0.0018011158099398017\n",
            "Imitation step 11/50\n",
            "0.0018044611206278205\n",
            "Imitation step 12/50\n",
            "0.0018020553980022669\n",
            "Imitation step 13/50\n",
            "0.001800358179025352\n",
            "Imitation step 14/50\n",
            "0.0018016216345131397\n",
            "Imitation step 15/50\n",
            "0.0017978973919525743\n",
            "Imitation step 16/50\n",
            "0.0017973956419155002\n",
            "Imitation step 17/50\n",
            "0.0018011491047218442\n",
            "Imitation step 18/50\n",
            "0.001801284495741129\n",
            "Imitation step 19/50\n",
            "0.001799906836822629\n",
            "Imitation step 20/50\n",
            "0.0017989176558330655\n",
            "Imitation step 21/50\n",
            "0.0018016706453636289\n",
            "Imitation step 22/50\n",
            "0.0017967827152460814\n",
            "Imitation step 23/50\n",
            "0.001800401834771037\n",
            "Imitation step 24/50\n",
            "0.0017977171810343862\n",
            "Imitation step 25/50\n",
            "0.0017982154386118054\n",
            "Imitation step 26/50\n",
            "0.0017985207960009575\n",
            "Imitation step 27/50\n",
            "0.0017997145187109709\n",
            "Imitation step 28/50\n",
            "0.0017974803922697902\n",
            "Imitation step 29/50\n",
            "0.0017986586317420006\n",
            "Imitation step 30/50\n",
            "0.0018001048592850566\n",
            "Imitation step 31/50\n",
            "0.0017981771379709244\n",
            "Imitation step 32/50\n",
            "0.00179953349288553\n",
            "Imitation step 33/50\n",
            "0.0018006251193583012\n",
            "Imitation step 34/50\n",
            "0.0017986202146857977\n",
            "Imitation step 35/50\n",
            "0.0017977542011067271\n",
            "Imitation step 36/50\n",
            "0.0018005174351856112\n",
            "Imitation step 37/50\n",
            "0.0018018732080236077\n",
            "Imitation step 38/50\n",
            "0.0018003059085458517\n",
            "Imitation step 39/50\n",
            "0.0018005173187702894\n",
            "Imitation step 40/50\n",
            "0.0018010203493759036\n",
            "Imitation step 41/50\n",
            "0.0017982017016038299\n",
            "Imitation step 42/50\n",
            "0.0018006832106038928\n",
            "Imitation step 43/50\n",
            "0.001797234290279448\n",
            "Imitation step 44/50\n",
            "0.0017969959881156683\n",
            "Imitation step 45/50\n",
            "0.0017998977564275265\n",
            "Imitation step 46/50\n",
            "0.001798914629034698\n",
            "Imitation step 47/50\n",
            "0.0017988949548453093\n",
            "Imitation step 48/50\n",
            "0.0017951135523617268\n",
            "Imitation step 49/50\n",
            "0.001796205178834498\n",
            "Generator training\n",
            "0.1182376816868782\n",
            "Iteration 63/120\n",
            "Imitation step 0/50\n",
            "0.0017983214929699898\n",
            "Imitation step 1/50\n",
            "0.0017956793308258057\n",
            "Imitation step 2/50\n",
            "0.0017965170554816723\n",
            "Imitation step 3/50\n",
            "0.0017951304325833917\n",
            "Imitation step 4/50\n",
            "0.001798546058125794\n",
            "Imitation step 5/50\n",
            "0.0018002737779170275\n",
            "Imitation step 6/50\n",
            "0.0017978765536099672\n",
            "Imitation step 7/50\n",
            "0.001796948490664363\n",
            "Imitation step 8/50\n",
            "0.0017978823743760586\n",
            "Imitation step 9/50\n",
            "0.0017953736241906881\n",
            "Imitation step 10/50\n",
            "0.0017973014619201422\n",
            "Imitation step 11/50\n",
            "0.001793973846361041\n",
            "Imitation step 12/50\n",
            "0.001794267911463976\n",
            "Imitation step 13/50\n",
            "0.001796425087377429\n",
            "Imitation step 14/50\n",
            "0.0017972473287954926\n",
            "Imitation step 15/50\n",
            "0.0017991437343880534\n",
            "Imitation step 16/50\n",
            "0.001796281198039651\n",
            "Imitation step 17/50\n",
            "0.0017961469711735845\n",
            "Imitation step 18/50\n",
            "0.001797232311218977\n",
            "Imitation step 19/50\n",
            "0.0017945305444300175\n",
            "Imitation step 20/50\n",
            "0.0017955369548872113\n",
            "Imitation step 21/50\n",
            "0.0017955226358026266\n",
            "Imitation step 22/50\n",
            "0.001797199947759509\n",
            "Imitation step 23/50\n",
            "0.0017963822465389967\n",
            "Imitation step 24/50\n",
            "0.001796392840333283\n",
            "Imitation step 25/50\n",
            "0.0017958179814741015\n",
            "Imitation step 26/50\n",
            "0.0017935108626261353\n",
            "Imitation step 27/50\n",
            "0.001795299001969397\n",
            "Imitation step 28/50\n",
            "0.0017955583753064275\n",
            "Imitation step 29/50\n",
            "0.0017954559298232198\n",
            "Imitation step 30/50\n",
            "0.0017952314810827374\n",
            "Imitation step 31/50\n",
            "0.001794425188563764\n",
            "Imitation step 32/50\n",
            "0.0017975879600271583\n",
            "Imitation step 33/50\n",
            "0.0017917923396453261\n",
            "Imitation step 34/50\n",
            "0.0017981362761929631\n",
            "Imitation step 35/50\n",
            "0.0017925810534507036\n",
            "Imitation step 36/50\n",
            "0.0017928018933162093\n",
            "Imitation step 37/50\n",
            "0.0017946262378245592\n",
            "Imitation step 38/50\n",
            "0.0017949198372662067\n",
            "Imitation step 39/50\n",
            "0.0017938505625352263\n",
            "Imitation step 40/50\n",
            "0.0017941539408639073\n",
            "Imitation step 41/50\n",
            "0.001791724469512701\n",
            "Imitation step 42/50\n",
            "0.0017940609250217676\n",
            "Imitation step 43/50\n",
            "0.0017929833848029375\n",
            "Imitation step 44/50\n",
            "0.0017906439024955034\n",
            "Imitation step 45/50\n",
            "0.0017943347338587046\n",
            "Imitation step 46/50\n",
            "0.0017973408102989197\n",
            "Imitation step 47/50\n",
            "0.0017939580138772726\n",
            "Imitation step 48/50\n",
            "0.001796114258468151\n",
            "Imitation step 49/50\n",
            "0.0017941695405170321\n",
            "Generator training\n",
            "0.11828865855932236\n",
            "Iteration 64/120\n",
            "Imitation step 0/50\n",
            "0.0017951660556718707\n",
            "Imitation step 1/50\n",
            "0.0017955260118469596\n",
            "Imitation step 2/50\n",
            "0.001794522046111524\n",
            "Imitation step 3/50\n",
            "0.0017918706871569157\n",
            "Imitation step 4/50\n",
            "0.0017928102752193809\n",
            "Imitation step 5/50\n",
            "0.0017943792045116425\n",
            "Imitation step 6/50\n",
            "0.0017931509064510465\n",
            "Imitation step 7/50\n",
            "0.0017952745547518134\n",
            "Imitation step 8/50\n",
            "0.0017929794266819954\n",
            "Imitation step 9/50\n",
            "0.0017920564860105515\n",
            "Imitation step 10/50\n",
            "0.001790264854207635\n",
            "Imitation step 11/50\n",
            "0.001792440190911293\n",
            "Imitation step 12/50\n",
            "0.0017879907973110676\n",
            "Imitation step 13/50\n",
            "0.0017939561512321234\n",
            "Imitation step 14/50\n",
            "0.0017914468189701438\n",
            "Imitation step 15/50\n",
            "0.0017928383313119411\n",
            "Imitation step 16/50\n",
            "0.001790645532310009\n",
            "Imitation step 17/50\n",
            "0.001793173374608159\n",
            "Imitation step 18/50\n",
            "0.0017920458922162652\n",
            "Imitation step 19/50\n",
            "0.0017941537080332637\n",
            "Imitation step 20/50\n",
            "0.0017937637167051435\n",
            "Imitation step 21/50\n",
            "0.0017916586948558688\n",
            "Imitation step 22/50\n",
            "0.0017903068801388144\n",
            "Imitation step 23/50\n",
            "0.0017894722986966372\n",
            "Imitation step 24/50\n",
            "0.0017913648625835776\n",
            "Imitation step 25/50\n",
            "0.0017888654256239533\n",
            "Imitation step 26/50\n",
            "0.0017915033968165517\n",
            "Imitation step 27/50\n",
            "0.001790249370969832\n",
            "Imitation step 28/50\n",
            "0.0017937903758138418\n",
            "Imitation step 29/50\n",
            "0.0017951204208657146\n",
            "Imitation step 30/50\n",
            "0.0017932115588337183\n",
            "Imitation step 31/50\n",
            "0.001790286274626851\n",
            "Imitation step 32/50\n",
            "0.0017923252889886498\n",
            "Imitation step 33/50\n",
            "0.0017897969810292125\n",
            "Imitation step 34/50\n",
            "0.0017923812847584486\n",
            "Imitation step 35/50\n",
            "0.0017902060644701123\n",
            "Imitation step 36/50\n",
            "0.001789190573617816\n",
            "Imitation step 37/50\n",
            "0.0017885674024000764\n",
            "Imitation step 38/50\n",
            "0.0017905393615365028\n",
            "Imitation step 39/50\n",
            "0.0017891025636345148\n",
            "Imitation step 40/50\n",
            "0.0017912170151248574\n",
            "Imitation step 41/50\n",
            "0.001791005372069776\n",
            "Imitation step 42/50\n",
            "0.0017894684569910169\n",
            "Imitation step 43/50\n",
            "0.0017879375955089927\n",
            "Imitation step 44/50\n",
            "0.001791386865079403\n",
            "Imitation step 45/50\n",
            "0.0017864820547401905\n",
            "Imitation step 46/50\n",
            "0.0017862251261249185\n",
            "Imitation step 47/50\n",
            "0.0017914300551638007\n",
            "Imitation step 48/50\n",
            "0.0017860084772109985\n",
            "Imitation step 49/50\n",
            "0.001788484281860292\n",
            "Generator training\n",
            "0.11837201565504074\n",
            "Iteration 65/120\n",
            "Imitation step 0/50\n",
            "0.0017876990605145693\n",
            "Imitation step 1/50\n",
            "0.0017904677661135793\n",
            "Imitation step 2/50\n",
            "0.0017847339622676373\n",
            "Imitation step 3/50\n",
            "0.0017879027873277664\n",
            "Imitation step 4/50\n",
            "0.0017884713597595692\n",
            "Imitation step 5/50\n",
            "0.001788301975466311\n",
            "Imitation step 6/50\n",
            "0.001786605454981327\n",
            "Imitation step 7/50\n",
            "0.0017901217797771096\n",
            "Imitation step 8/50\n",
            "0.001789075555279851\n",
            "Imitation step 9/50\n",
            "0.0017883520340546966\n",
            "Imitation step 10/50\n",
            "0.0017860353691503406\n",
            "Imitation step 11/50\n",
            "0.001785856205970049\n",
            "Imitation step 12/50\n",
            "0.0017883135005831718\n",
            "Imitation step 13/50\n",
            "0.0017874884651973844\n",
            "Imitation step 14/50\n",
            "0.0017886239802464843\n",
            "Imitation step 15/50\n",
            "0.0017862931126728654\n",
            "Imitation step 16/50\n",
            "0.001788296620361507\n",
            "Imitation step 17/50\n",
            "0.001786159467883408\n",
            "Imitation step 18/50\n",
            "0.001785870990715921\n",
            "Imitation step 19/50\n",
            "0.0017888019792735577\n",
            "Imitation step 20/50\n",
            "0.0017825368558987975\n",
            "Imitation step 21/50\n",
            "0.0017870183801278472\n",
            "Imitation step 22/50\n",
            "0.0017870721640065312\n",
            "Imitation step 23/50\n",
            "0.0017887994181364775\n",
            "Imitation step 24/50\n",
            "0.0017887632129713893\n",
            "Imitation step 25/50\n",
            "0.001788254245184362\n",
            "Imitation step 26/50\n",
            "0.0017856520134955645\n",
            "Imitation step 27/50\n",
            "0.001787977758795023\n",
            "Imitation step 28/50\n",
            "0.001787752378731966\n",
            "Imitation step 29/50\n",
            "0.0017829769058153033\n",
            "Imitation step 30/50\n",
            "0.0017848648130893707\n",
            "Imitation step 31/50\n",
            "0.001783974003046751\n",
            "Imitation step 32/50\n",
            "0.0017866764683276415\n",
            "Imitation step 33/50\n",
            "0.0017831905279308558\n",
            "Imitation step 34/50\n",
            "0.0017835862236097455\n",
            "Imitation step 35/50\n",
            "0.0017850794829428196\n",
            "Imitation step 36/50\n",
            "0.001788115012459457\n",
            "Imitation step 37/50\n",
            "0.0017860260559245944\n",
            "Imitation step 38/50\n",
            "0.0017859836807474494\n",
            "Imitation step 39/50\n",
            "0.0017836274346336722\n",
            "Imitation step 40/50\n",
            "0.0017853141762316227\n",
            "Imitation step 41/50\n",
            "0.0017846233677119017\n",
            "Imitation step 42/50\n",
            "0.0017842481611296535\n",
            "Imitation step 43/50\n",
            "0.0017876102356240153\n",
            "Imitation step 44/50\n",
            "0.001786918961443007\n",
            "Imitation step 45/50\n",
            "0.0017860655207186937\n",
            "Imitation step 46/50\n",
            "0.0017845227848738432\n",
            "Imitation step 47/50\n",
            "0.0017850572476163507\n",
            "Imitation step 48/50\n",
            "0.0017827133415266871\n",
            "Imitation step 49/50\n",
            "0.0017850303556770086\n",
            "Generator training\n",
            "0.11832994222640991\n",
            "Iteration 66/120\n",
            "Imitation step 0/50\n",
            "0.0017831239383667707\n",
            "Imitation step 1/50\n",
            "0.0017875569174066186\n",
            "Imitation step 2/50\n",
            "0.0017827505944296718\n",
            "Imitation step 3/50\n",
            "0.001784985652193427\n",
            "Imitation step 4/50\n",
            "0.0017857695929706097\n",
            "Imitation step 5/50\n",
            "0.0017867422429844737\n",
            "Imitation step 6/50\n",
            "0.0017850794829428196\n",
            "Imitation step 7/50\n",
            "0.0017855288460850716\n",
            "Imitation step 8/50\n",
            "0.0017823490779846907\n",
            "Imitation step 9/50\n",
            "0.0017831705044955015\n",
            "Imitation step 10/50\n",
            "0.0017832405865192413\n",
            "Imitation step 11/50\n",
            "0.001786405686289072\n",
            "Imitation step 12/50\n",
            "0.0017819126369431615\n",
            "Imitation step 13/50\n",
            "0.0017835869221016765\n",
            "Imitation step 14/50\n",
            "0.0017813591985031962\n",
            "Imitation step 15/50\n",
            "0.0017809774726629257\n",
            "Imitation step 16/50\n",
            "0.0017840691143646836\n",
            "Imitation step 17/50\n",
            "0.0017863824032247066\n",
            "Imitation step 18/50\n",
            "0.0017817214829847217\n",
            "Imitation step 19/50\n",
            "0.001783133251592517\n",
            "Imitation step 20/50\n",
            "0.0017832573503255844\n",
            "Imitation step 21/50\n",
            "0.0017802930669859052\n",
            "Imitation step 22/50\n",
            "0.0017841391963884234\n",
            "Imitation step 23/50\n",
            "0.0017798814224079251\n",
            "Imitation step 24/50\n",
            "0.0017853225581347942\n",
            "Imitation step 25/50\n",
            "0.0017840602668002248\n",
            "Imitation step 26/50\n",
            "0.0017841915832832456\n",
            "Imitation step 27/50\n",
            "0.0017844332614913583\n",
            "Imitation step 28/50\n",
            "0.0017831971636041999\n",
            "Imitation step 29/50\n",
            "0.001784428139217198\n",
            "Imitation step 30/50\n",
            "0.0017791733844205737\n",
            "Imitation step 31/50\n",
            "0.0017830468714237213\n",
            "Imitation step 32/50\n",
            "0.0017832164885476232\n",
            "Imitation step 33/50\n",
            "0.0017808502307161689\n",
            "Imitation step 34/50\n",
            "0.001782896346412599\n",
            "Imitation step 35/50\n",
            "0.0017824298702180386\n",
            "Imitation step 36/50\n",
            "0.0017825638642534614\n",
            "Imitation step 37/50\n",
            "0.0017792413709685206\n",
            "Imitation step 38/50\n",
            "0.0017837299965322018\n",
            "Imitation step 39/50\n",
            "0.001780883758328855\n",
            "Imitation step 40/50\n",
            "0.0017809021519497037\n",
            "Imitation step 41/50\n",
            "0.0017788293771445751\n",
            "Imitation step 42/50\n",
            "0.0017791811842471361\n",
            "Imitation step 43/50\n",
            "0.0017794937593862414\n",
            "Imitation step 44/50\n",
            "0.0017797528998926282\n",
            "Imitation step 45/50\n",
            "0.0017830393044278026\n",
            "Imitation step 46/50\n",
            "0.0017790371784940362\n",
            "Imitation step 47/50\n",
            "0.0017803318332880735\n",
            "Imitation step 48/50\n",
            "0.001778547652065754\n",
            "Imitation step 49/50\n",
            "0.0017813993617892265\n",
            "Generator training\n",
            "0.118303082883358\n",
            "Iteration 67/120\n",
            "Imitation step 0/50\n",
            "0.0017795570893213153\n",
            "Imitation step 1/50\n",
            "0.0017784335650503635\n",
            "Imitation step 2/50\n",
            "0.0017819242784753442\n",
            "Imitation step 3/50\n",
            "0.0017803417285904288\n",
            "Imitation step 4/50\n",
            "0.0017792629078030586\n",
            "Imitation step 5/50\n",
            "0.0017771057318896055\n",
            "Imitation step 6/50\n",
            "0.001777995959855616\n",
            "Imitation step 7/50\n",
            "0.001778111094608903\n",
            "Imitation step 8/50\n",
            "0.001782124163582921\n",
            "Imitation step 9/50\n",
            "0.0017777449684217572\n",
            "Imitation step 10/50\n",
            "0.0017783658113330603\n",
            "Imitation step 11/50\n",
            "0.0017747398233041167\n",
            "Imitation step 12/50\n",
            "0.0017826864495873451\n",
            "Imitation step 13/50\n",
            "0.001778575126081705\n",
            "Imitation step 14/50\n",
            "0.0017755965236574411\n",
            "Imitation step 15/50\n",
            "0.0017788559198379517\n",
            "Imitation step 16/50\n",
            "0.001776581397280097\n",
            "Imitation step 17/50\n",
            "0.0017806935356929898\n",
            "Imitation step 18/50\n",
            "0.001777840661816299\n",
            "Imitation step 19/50\n",
            "0.001776541699655354\n",
            "Imitation step 20/50\n",
            "0.0017794714076444507\n",
            "Imitation step 21/50\n",
            "0.001779396552592516\n",
            "Imitation step 22/50\n",
            "0.001781725906766951\n",
            "Imitation step 23/50\n",
            "0.001777007826603949\n",
            "Imitation step 24/50\n",
            "0.0017775564920157194\n",
            "Imitation step 25/50\n",
            "0.0017771903658285737\n",
            "Imitation step 26/50\n",
            "0.0017773075960576534\n",
            "Imitation step 27/50\n",
            "0.001779447658918798\n",
            "Imitation step 28/50\n",
            "0.0017785329837352037\n",
            "Imitation step 29/50\n",
            "0.0017751125851646066\n",
            "Imitation step 30/50\n",
            "0.0017788478871807456\n",
            "Imitation step 31/50\n",
            "0.0017758806934580207\n",
            "Imitation step 32/50\n",
            "0.0017801097128540277\n",
            "Imitation step 33/50\n",
            "0.0017791757127270103\n",
            "Imitation step 34/50\n",
            "0.001777028664946556\n",
            "Imitation step 35/50\n",
            "0.001779792713932693\n",
            "Imitation step 36/50\n",
            "0.0017768375109881163\n",
            "Imitation step 37/50\n",
            "0.0017768620746210217\n",
            "Imitation step 38/50\n",
            "0.0017754720756784081\n",
            "Imitation step 39/50\n",
            "0.0017768183024600148\n",
            "Imitation step 40/50\n",
            "0.0017763589276000857\n",
            "Imitation step 41/50\n",
            "0.001775393495336175\n",
            "Imitation step 42/50\n",
            "0.0017743897624313831\n",
            "Imitation step 43/50\n",
            "0.0017767648678272963\n",
            "Imitation step 44/50\n",
            "0.0017758497269824147\n",
            "Imitation step 45/50\n",
            "0.0017770719714462757\n",
            "Imitation step 46/50\n",
            "0.0017711075488477945\n",
            "Imitation step 47/50\n",
            "0.0017791778082028031\n",
            "Imitation step 48/50\n",
            "0.0017777439206838608\n",
            "Imitation step 49/50\n",
            "0.001779588172212243\n",
            "Generator training\n",
            "0.11827215552330017\n",
            "Iteration 68/120\n",
            "Imitation step 0/50\n",
            "0.001776619697920978\n",
            "Imitation step 1/50\n",
            "0.0017752439016476274\n",
            "Imitation step 2/50\n",
            "0.0017753933789208531\n",
            "Imitation step 3/50\n",
            "0.0017773786094039679\n",
            "Imitation step 4/50\n",
            "0.0017729727551341057\n",
            "Imitation step 5/50\n",
            "0.0017741689225658774\n",
            "Imitation step 6/50\n",
            "0.0017790703568607569\n",
            "Imitation step 7/50\n",
            "0.0017735859146341681\n",
            "Imitation step 8/50\n",
            "0.0017749221296980977\n",
            "Imitation step 9/50\n",
            "0.0017738690366968513\n",
            "Imitation step 10/50\n",
            "0.0017752974526956677\n",
            "Imitation step 11/50\n",
            "0.0017719656461849809\n",
            "Imitation step 12/50\n",
            "0.001776696415618062\n",
            "Imitation step 13/50\n",
            "0.001775893266312778\n",
            "Imitation step 14/50\n",
            "0.00177443225402385\n",
            "Imitation step 15/50\n",
            "0.0017747015226632357\n",
            "Imitation step 16/50\n",
            "0.0017739365575835109\n",
            "Imitation step 17/50\n",
            "0.0017733260756358504\n",
            "Imitation step 18/50\n",
            "0.0017706616781651974\n",
            "Imitation step 19/50\n",
            "0.001773193827830255\n",
            "Imitation step 20/50\n",
            "0.001772586372680962\n",
            "Imitation step 21/50\n",
            "0.0017741323681548238\n",
            "Imitation step 22/50\n",
            "0.0017724360805004835\n",
            "Imitation step 23/50\n",
            "0.001776370219886303\n",
            "Imitation step 24/50\n",
            "0.0017719430616125464\n",
            "Imitation step 25/50\n",
            "0.0017730663530528545\n",
            "Imitation step 26/50\n",
            "0.0017725690267980099\n",
            "Imitation step 27/50\n",
            "0.001772605231963098\n",
            "Imitation step 28/50\n",
            "0.0017712118569761515\n",
            "Imitation step 29/50\n",
            "0.0017751717241480947\n",
            "Imitation step 30/50\n",
            "0.0017708188388496637\n",
            "Imitation step 31/50\n",
            "0.0017717902082949877\n",
            "Imitation step 32/50\n",
            "0.0017722765915095806\n",
            "Imitation step 33/50\n",
            "0.0017736777663230896\n",
            "Imitation step 34/50\n",
            "0.0017733577406033874\n",
            "Imitation step 35/50\n",
            "0.0017720898613333702\n",
            "Imitation step 36/50\n",
            "0.0017749546095728874\n",
            "Imitation step 37/50\n",
            "0.0017712984699755907\n",
            "Imitation step 38/50\n",
            "0.0017733195563778281\n",
            "Imitation step 39/50\n",
            "0.001771948765963316\n",
            "Imitation step 40/50\n",
            "0.001772706164047122\n",
            "Imitation step 41/50\n",
            "0.001772190211340785\n",
            "Imitation step 42/50\n",
            "0.0017742887139320374\n",
            "Imitation step 43/50\n",
            "0.001768768299371004\n",
            "Imitation step 44/50\n",
            "0.001775287906639278\n",
            "Imitation step 45/50\n",
            "0.0017726983642205596\n",
            "Imitation step 46/50\n",
            "0.001772661809809506\n",
            "Imitation step 47/50\n",
            "0.001770915579982102\n",
            "Imitation step 48/50\n",
            "0.0017707033548504114\n",
            "Imitation step 49/50\n",
            "0.001772977178916335\n",
            "Generator training\n",
            "0.11829031258821487\n",
            "Iteration 69/120\n",
            "Imitation step 0/50\n",
            "0.0017733621643856168\n",
            "Imitation step 1/50\n",
            "0.0017711133696138859\n",
            "Imitation step 2/50\n",
            "0.0017713690176606178\n",
            "Imitation step 3/50\n",
            "0.0017732013948261738\n",
            "Imitation step 4/50\n",
            "0.0017704257043078542\n",
            "Imitation step 5/50\n",
            "0.0017722212942317128\n",
            "Imitation step 6/50\n",
            "0.0017697041621431708\n",
            "Imitation step 7/50\n",
            "0.0017700651660561562\n",
            "Imitation step 8/50\n",
            "0.0017701707547530532\n",
            "Imitation step 9/50\n",
            "0.0017697102157399058\n",
            "Imitation step 10/50\n",
            "0.0017699635354802012\n",
            "Imitation step 11/50\n",
            "0.0017729768296703696\n",
            "Imitation step 12/50\n",
            "0.0017719874158501625\n",
            "Imitation step 13/50\n",
            "0.0017706298967823386\n",
            "Imitation step 14/50\n",
            "0.0017703732009977102\n",
            "Imitation step 15/50\n",
            "0.0017710317624732852\n",
            "Imitation step 16/50\n",
            "0.0017689348896965384\n",
            "Imitation step 17/50\n",
            "0.0017717413138598204\n",
            "Imitation step 18/50\n",
            "0.0017688608495518565\n",
            "Imitation step 19/50\n",
            "0.0017700294265523553\n",
            "Imitation step 20/50\n",
            "0.0017712631961330771\n",
            "Imitation step 21/50\n",
            "0.0017704450292512774\n",
            "Imitation step 22/50\n",
            "0.0017716622678562999\n",
            "Imitation step 23/50\n",
            "0.001770293922163546\n",
            "Imitation step 24/50\n",
            "0.0017717503942549229\n",
            "Imitation step 25/50\n",
            "0.0017710872925817966\n",
            "Imitation step 26/50\n",
            "0.0017681614262983203\n",
            "Imitation step 27/50\n",
            "0.001768904854543507\n",
            "Imitation step 28/50\n",
            "0.001766334054991603\n",
            "Imitation step 29/50\n",
            "0.00177004502620548\n",
            "Imitation step 30/50\n",
            "0.0017674450064077973\n",
            "Imitation step 31/50\n",
            "0.0017699355958029628\n",
            "Imitation step 32/50\n",
            "0.001768347341567278\n",
            "Imitation step 33/50\n",
            "0.00176831497810781\n",
            "Imitation step 34/50\n",
            "0.0017685405910015106\n",
            "Imitation step 35/50\n",
            "0.001771362847648561\n",
            "Imitation step 36/50\n",
            "0.0017663498874753714\n",
            "Imitation step 37/50\n",
            "0.0017671729438006878\n",
            "Imitation step 38/50\n",
            "0.001767191686667502\n",
            "Imitation step 39/50\n",
            "0.001767137786373496\n",
            "Imitation step 40/50\n",
            "0.0017705617938190699\n",
            "Imitation step 41/50\n",
            "0.0017687629442662\n",
            "Imitation step 42/50\n",
            "0.0017675324343144894\n",
            "Imitation step 43/50\n",
            "0.0017657093703746796\n",
            "Imitation step 44/50\n",
            "0.0017669801600277424\n",
            "Imitation step 45/50\n",
            "0.0017681117169559002\n",
            "Imitation step 46/50\n",
            "0.0017674951814115047\n",
            "Imitation step 47/50\n",
            "0.0017680699238553643\n",
            "Imitation step 48/50\n",
            "0.0017668575746938586\n",
            "Imitation step 49/50\n",
            "0.0017650837544351816\n",
            "Generator training\n",
            "0.11823824793100357\n",
            "Iteration 70/120\n",
            "Imitation step 0/50\n",
            "0.0017657573334872723\n",
            "Imitation step 1/50\n",
            "0.0017662312602624297\n",
            "Imitation step 2/50\n",
            "0.0017658135620877147\n",
            "Imitation step 3/50\n",
            "0.001769320573657751\n",
            "Imitation step 4/50\n",
            "0.001765755470842123\n",
            "Imitation step 5/50\n",
            "0.0017665927298367023\n",
            "Imitation step 6/50\n",
            "0.001764880958944559\n",
            "Imitation step 7/50\n",
            "0.00176738400477916\n",
            "Imitation step 8/50\n",
            "0.0017651449888944626\n",
            "Imitation step 9/50\n",
            "0.001766942092217505\n",
            "Imitation step 10/50\n",
            "0.0017678776057437062\n",
            "Imitation step 11/50\n",
            "0.00176860427018255\n",
            "Imitation step 12/50\n",
            "0.001767264213413\n",
            "Imitation step 13/50\n",
            "0.001766307046636939\n",
            "Imitation step 14/50\n",
            "0.0017661439487710595\n",
            "Imitation step 15/50\n",
            "0.0017684344202280045\n",
            "Imitation step 16/50\n",
            "0.0017691096290946007\n",
            "Imitation step 17/50\n",
            "0.0017677140422165394\n",
            "Imitation step 18/50\n",
            "0.0017676405841484666\n",
            "Imitation step 19/50\n",
            "0.0017652319511398673\n",
            "Imitation step 20/50\n",
            "0.0017659662989899516\n",
            "Imitation step 21/50\n",
            "0.0017643460305407643\n",
            "Imitation step 22/50\n",
            "0.0017663323087617755\n",
            "Imitation step 23/50\n",
            "0.0017660876037552953\n",
            "Imitation step 24/50\n",
            "0.0017660845769569278\n",
            "Imitation step 25/50\n",
            "0.001765404362231493\n",
            "Imitation step 26/50\n",
            "0.0017640666337683797\n",
            "Imitation step 27/50\n",
            "0.0017662957543507218\n",
            "Imitation step 28/50\n",
            "0.0017652634996920824\n",
            "Imitation step 29/50\n",
            "0.0017646916676312685\n",
            "Imitation step 30/50\n",
            "0.0017646587220951915\n",
            "Imitation step 31/50\n",
            "0.0017650580266490579\n",
            "Imitation step 32/50\n",
            "0.0017676199786365032\n",
            "Imitation step 33/50\n",
            "0.0017672708490863442\n",
            "Imitation step 34/50\n",
            "0.0017692378023639321\n",
            "Imitation step 35/50\n",
            "0.001763904350809753\n",
            "Imitation step 36/50\n",
            "0.001766658271662891\n",
            "Imitation step 37/50\n",
            "0.0017634725663810968\n",
            "Imitation step 38/50\n",
            "0.0017643474275246263\n",
            "Imitation step 39/50\n",
            "0.0017658805008977652\n",
            "Imitation step 40/50\n",
            "0.0017652419628575444\n",
            "Imitation step 41/50\n",
            "0.0017650207737460732\n",
            "Imitation step 42/50\n",
            "0.001766300294548273\n",
            "Imitation step 43/50\n",
            "0.0017648914363235235\n",
            "Imitation step 44/50\n",
            "0.0017667892388999462\n",
            "Imitation step 45/50\n",
            "0.0017673582769930363\n",
            "Imitation step 46/50\n",
            "0.0017651008674874902\n",
            "Imitation step 47/50\n",
            "0.0017640902660787106\n",
            "Imitation step 48/50\n",
            "0.0017659440636634827\n",
            "Imitation step 49/50\n",
            "0.0017655735136941075\n",
            "Generator training\n",
            "0.11834899336099625\n",
            "Iteration 71/120\n",
            "Imitation step 0/50\n",
            "0.0017681323224678636\n",
            "Imitation step 1/50\n",
            "0.0017653427785262465\n",
            "Imitation step 2/50\n",
            "0.001763361506164074\n",
            "Imitation step 3/50\n",
            "0.001766022527590394\n",
            "Imitation step 4/50\n",
            "0.0017660199664533138\n",
            "Imitation step 5/50\n",
            "0.0017639750149101019\n",
            "Imitation step 6/50\n",
            "0.0017658924916759133\n",
            "Imitation step 7/50\n",
            "0.0017672055400907993\n",
            "Imitation step 8/50\n",
            "0.0017655215924605727\n",
            "Imitation step 9/50\n",
            "0.0017646513879299164\n",
            "Imitation step 10/50\n",
            "0.0017623241292312741\n",
            "Imitation step 11/50\n",
            "0.0017655170522630215\n",
            "Imitation step 12/50\n",
            "0.0017648228676989675\n",
            "Imitation step 13/50\n",
            "0.0017624406609684229\n",
            "Imitation step 14/50\n",
            "0.001763958134688437\n",
            "Imitation step 15/50\n",
            "0.0017638283316046\n",
            "Imitation step 16/50\n",
            "0.0017634691903367639\n",
            "Imitation step 17/50\n",
            "0.001763947424478829\n",
            "Imitation step 18/50\n",
            "0.0017648735083639622\n",
            "Imitation step 19/50\n",
            "0.001765839522704482\n",
            "Imitation step 20/50\n",
            "0.001762563711963594\n",
            "Imitation step 21/50\n",
            "0.0017659029690548778\n",
            "Imitation step 22/50\n",
            "0.001765332417562604\n",
            "Imitation step 23/50\n",
            "0.001767016132362187\n",
            "Imitation step 24/50\n",
            "0.0017621256411075592\n",
            "Imitation step 25/50\n",
            "0.0017640661681070924\n",
            "Imitation step 26/50\n",
            "0.0017651746748015285\n",
            "Imitation step 27/50\n",
            "0.001760766259394586\n",
            "Imitation step 28/50\n",
            "0.0017645249608904123\n",
            "Imitation step 29/50\n",
            "0.0017650705995038152\n",
            "Imitation step 30/50\n",
            "0.0017629635985940695\n",
            "Imitation step 31/50\n",
            "0.0017661231104284525\n",
            "Imitation step 32/50\n",
            "0.0017630544025450945\n",
            "Imitation step 33/50\n",
            "0.0017628895584493876\n",
            "Imitation step 34/50\n",
            "0.0017620583530515432\n",
            "Imitation step 35/50\n",
            "0.0017647489439696074\n",
            "Imitation step 36/50\n",
            "0.0017612649826332927\n",
            "Imitation step 37/50\n",
            "0.0017615733668208122\n",
            "Imitation step 38/50\n",
            "0.0017643485916778445\n",
            "Imitation step 39/50\n",
            "0.001762888510711491\n",
            "Imitation step 40/50\n",
            "0.0017622698796913028\n",
            "Imitation step 41/50\n",
            "0.0017649579094722867\n",
            "Imitation step 42/50\n",
            "0.0017627434572204947\n",
            "Imitation step 43/50\n",
            "0.0017602124717086554\n",
            "Imitation step 44/50\n",
            "0.0017635632539168\n",
            "Imitation step 45/50\n",
            "0.0017629081849008799\n",
            "Imitation step 46/50\n",
            "0.0017626509070396423\n",
            "Imitation step 47/50\n",
            "0.0017635670956224203\n",
            "Imitation step 48/50\n",
            "0.001765942550264299\n",
            "Imitation step 49/50\n",
            "0.0017587665934115648\n",
            "Generator training\n",
            "0.11827784031629562\n",
            "Iteration 72/120\n",
            "Imitation step 0/50\n",
            "0.001763240317814052\n",
            "Imitation step 1/50\n",
            "0.0017604627646505833\n",
            "Imitation step 2/50\n",
            "0.0017650139052420855\n",
            "Imitation step 3/50\n",
            "0.0017652112292125821\n",
            "Imitation step 4/50\n",
            "0.0017607968766242266\n",
            "Imitation step 5/50\n",
            "0.0017617145786061883\n",
            "Imitation step 6/50\n",
            "0.0017613425152376294\n",
            "Imitation step 7/50\n",
            "0.0017614476382732391\n",
            "Imitation step 8/50\n",
            "0.0017607946647331119\n",
            "Imitation step 9/50\n",
            "0.0017632367089390755\n",
            "Imitation step 10/50\n",
            "0.0017634992254897952\n",
            "Imitation step 11/50\n",
            "0.0017640782753005624\n",
            "Imitation step 12/50\n",
            "0.0017627234337851405\n",
            "Imitation step 13/50\n",
            "0.0017629613867029548\n",
            "Imitation step 14/50\n",
            "0.0017651960952207446\n",
            "Imitation step 15/50\n",
            "0.001764120301231742\n",
            "Imitation step 16/50\n",
            "0.0017623536987230182\n",
            "Imitation step 17/50\n",
            "0.0017632223898544908\n",
            "Imitation step 18/50\n",
            "0.0017636121483519673\n",
            "Imitation step 19/50\n",
            "0.0017626207554712892\n",
            "Imitation step 20/50\n",
            "0.001763802021741867\n",
            "Imitation step 21/50\n",
            "0.0017627933993935585\n",
            "Imitation step 22/50\n",
            "0.0017601988511160016\n",
            "Imitation step 23/50\n",
            "0.001759135164320469\n",
            "Imitation step 24/50\n",
            "0.0017628124915063381\n",
            "Imitation step 25/50\n",
            "0.0017635998083278537\n",
            "Imitation step 26/50\n",
            "0.0017609192291274667\n",
            "Imitation step 27/50\n",
            "0.0017605704488232732\n",
            "Imitation step 28/50\n",
            "0.0017626225017011166\n",
            "Imitation step 29/50\n",
            "0.0017623718595132232\n",
            "Imitation step 30/50\n",
            "0.0017633421812206507\n",
            "Imitation step 31/50\n",
            "0.001760110491886735\n",
            "Imitation step 32/50\n",
            "0.0017616561381146312\n",
            "Imitation step 33/50\n",
            "0.001760229584760964\n",
            "Imitation step 34/50\n",
            "0.0017614637035876513\n",
            "Imitation step 35/50\n",
            "0.0017616298282518983\n",
            "Imitation step 36/50\n",
            "0.00176154263317585\n",
            "Imitation step 37/50\n",
            "0.001763665466569364\n",
            "Imitation step 38/50\n",
            "0.0017593713710084558\n",
            "Imitation step 39/50\n",
            "0.0017643084283918142\n",
            "Imitation step 40/50\n",
            "0.0017611458897590637\n",
            "Imitation step 41/50\n",
            "0.0017612060764804482\n",
            "Imitation step 42/50\n",
            "0.001762660569511354\n",
            "Imitation step 43/50\n",
            "0.0017598215490579605\n",
            "Imitation step 44/50\n",
            "0.0017608744092285633\n",
            "Imitation step 45/50\n",
            "0.0017603000160306692\n",
            "Imitation step 46/50\n",
            "0.0017615171382203698\n",
            "Imitation step 47/50\n",
            "0.0017618954880163074\n",
            "Imitation step 48/50\n",
            "0.0017642247257754207\n",
            "Imitation step 49/50\n",
            "0.0017615769756957889\n",
            "Generator training\n",
            "0.11829345673322678\n",
            "Iteration 73/120\n",
            "Imitation step 0/50\n",
            "0.0017612167866900563\n",
            "Imitation step 1/50\n",
            "0.0017625888576731086\n",
            "Imitation step 2/50\n",
            "0.001761011895723641\n",
            "Imitation step 3/50\n",
            "0.0017612014198675752\n",
            "Imitation step 4/50\n",
            "0.0017628094647079706\n",
            "Imitation step 5/50\n",
            "0.001759071834385395\n",
            "Imitation step 6/50\n",
            "0.001758710714057088\n",
            "Imitation step 7/50\n",
            "0.0017613492673262954\n",
            "Imitation step 8/50\n",
            "0.0017591447103768587\n",
            "Imitation step 9/50\n",
            "0.0017618319252505898\n",
            "Imitation step 10/50\n",
            "0.0017607402987778187\n",
            "Imitation step 11/50\n",
            "0.0017594671808183193\n",
            "Imitation step 12/50\n",
            "0.0017577416729182005\n",
            "Imitation step 13/50\n",
            "0.0017616985132917762\n",
            "Imitation step 14/50\n",
            "0.0017616330878809094\n",
            "Imitation step 15/50\n",
            "0.0017601915169507265\n",
            "Imitation step 16/50\n",
            "0.001761145773343742\n",
            "Imitation step 17/50\n",
            "0.0017596380785107613\n",
            "Imitation step 18/50\n",
            "0.0017613201634958386\n",
            "Imitation step 19/50\n",
            "0.0017594320233911276\n",
            "Imitation step 20/50\n",
            "0.0017607512418180704\n",
            "Imitation step 21/50\n",
            "0.0017602939624339342\n",
            "Imitation step 22/50\n",
            "0.0017601127037778497\n",
            "Imitation step 23/50\n",
            "0.0017591598443686962\n",
            "Imitation step 24/50\n",
            "0.0017600769642740488\n",
            "Imitation step 25/50\n"
          ]
        }
      ],
      "source": [
        "kd = Knowledge_Distillation(student, teacher, gene)\n",
        "kd.train(10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcfqC14pUMe2sJPqbqVmHq",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}